{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37fa4fa4-d198-468e-a393-a047bdc9c784",
   "metadata": {},
   "source": [
    "# 1: Initial Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7ad1a82-a57b-48a3-821c-81e8f35b400c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 INITIALIZING COMPLETE F1 RACE STRATEGY ADVANCED ML PIPELINE...\n",
      "✅ All enhanced dependencies loaded successfully\n"
     ]
    }
   ],
   "source": [
    "print('🚀 INITIALIZING COMPLETE F1 RACE STRATEGY ADVANCED ML PIPELINE...')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from pandas import json_normalize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_any_dtype\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "import traceback\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit, GridSearchCV, learning_curve, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, mean_absolute_percentage_error, explained_variance_score, max_error\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, PolynomialFeatures, RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE, mutual_info_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import resample, class_weight\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import linregress, zscore, shapiro, normaltest, yeojohnson, median_abs_deviation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "print('✅ All enhanced dependencies loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75e09cd-5d70-4637-ab4c-fb5fae990d57",
   "metadata": {},
   "source": [
    "# 2: Comprehensive Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc6ab14d-6fc0-4c36-9b64-c812799da94a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ComprehensiveDataPreprocessor:\n",
    "    \"\"\"\n",
    "    COMPREHENSIVE DATA PREPROCESSING: Handling imbalance, outliers, missing values, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.preprocessing_steps = {}\n",
    "        self.scalers = {}\n",
    "        self.encoders = {}\n",
    "        self.imputer = None\n",
    "        self.outlier_detector = None\n",
    "        self.feature_selector = None\n",
    "        \n",
    "    def comprehensive_preprocessing_pipeline(self, X, y = None, problem_type = 'regression'):\n",
    "        'COMPREHENSIVE PREPROCESSING PIPELINE'\n",
    "        print(f'🔧 COMPREHENSIVE PREPROCESSING PIPELINE: {X.shape[1]} features')\n",
    "        \n",
    "        if X.empty:\n",
    "            return X, y\n",
    "            \n",
    "        X_processed = X.copy()\n",
    "        y_processed = y.copy() if y is not None else None\n",
    "        \n",
    "        # Step 1: Handle missing values\n",
    "        \n",
    "        X_processed = self.handle_missing_values_comprehensive(X_processed)\n",
    "        \n",
    "        # Step 2: Detect and handle outliers\n",
    "        \n",
    "        X_processed = self.handle_outliers_robust(X_processed)\n",
    "        \n",
    "        # Step 3: Handle data imbalance (for classification)\n",
    "        \n",
    "        if y_processed is not None and problem_type == 'classification':\n",
    "            X_processed, y_processed = self.handle_imbalance(X_processed, y_processed)\n",
    "        \n",
    "        # Step 4: Advanced feature engineering\n",
    "        \n",
    "        X_processed = self.advanced_feature_engineering(X_processed)\n",
    "        \n",
    "        # Step 5: Smart encoding\n",
    "        \n",
    "        X_processed = self.smart_encoding_advanced(X_processed)\n",
    "        \n",
    "        # Step 6: Advanced scaling\n",
    "        \n",
    "        X_processed = self.advanced_scaling_robust(X_processed)\n",
    "        \n",
    "        # Step 7: Feature selection\n",
    "        \n",
    "        if y_processed is not None:\n",
    "            X_processed = self.comprehensive_feature_selection(X_processed, y_processed, problem_type)\n",
    "        \n",
    "        # Step 8: Dimensionality reduction (if needed)\n",
    "        \n",
    "        if X_processed.shape[1] > 50:\n",
    "            X_processed = self.dimensionality_reduction(X_processed, y_processed)\n",
    "        \n",
    "        print(f'✅ COMPREHENSIVE PREPROCESSING COMPLETE: {X_processed.shape[1]} features')\n",
    "        return X_processed, y_processed\n",
    "    \n",
    "    def handle_missing_values_comprehensive(self, X):\n",
    "        'COMPREHENSIVE MISSING VALUE HANDLING'\n",
    "        print('   🧹 Handling missing values...')\n",
    "        \n",
    "        missing_summary = X.isnull().sum()\n",
    "        missing_percentage = (missing_summary / len(X)) * 100\n",
    "        \n",
    "        high_missing_columns = missing_percentage[missing_percentage > 50].index\n",
    "        if len(high_missing_columns) > 0:\n",
    "            X = X.drop(columns = high_missing_columns)\n",
    "            print(f'   Dropped {len(high_missing_columns)} columns with > 50% missing values')\n",
    "        \n",
    "        # Use advanced imputation strategies\n",
    "        \n",
    "        numeric_cols = X.select_dtypes(include = [np.number]).columns\n",
    "        categorical_cols = X.select_dtypes(include = ['object']).columns\n",
    "        \n",
    "        # Numeric imputation\n",
    "        \n",
    "        if len(numeric_cols) > 0:\n",
    "        \n",
    "            # Try KNN imputer for numeric columns\n",
    "            \n",
    "            try:\n",
    "                knn_imputer = KNNImputer(n_neighbors = 5)\n",
    "                X[numeric_cols] = knn_imputer.fit_transform(X[numeric_cols])\n",
    "                print('  Applied KNN imputation for numeric features')\n",
    "            except:\n",
    "                \n",
    "                # Fallback to median imputation\n",
    "                \n",
    "                imputer = SimpleImputer(strategy = 'median')\n",
    "                X[numeric_cols] = imputer.fit_transform(X[numeric_cols])\n",
    "                print('   Applied median imputation for numeric features')\n",
    "        \n",
    "        # Categorical imputation\n",
    "        \n",
    "        if len(categorical_cols) > 0:\n",
    "            for col in categorical_cols:\n",
    "                if X[col].isnull().sum() > 0:\n",
    "                    X[col] = X[col].fillna('Unknown')\n",
    "            print('  Applied mode imputation for categorical features')\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def handle_outliers_robust(self, X):\n",
    "        'ROBUST OUTLIER HANDLING USING MULTIPLE METHODS'\n",
    "        print('   📊 Detecting and handling outliers...')\n",
    "        \n",
    "        numeric_cols = X.select_dtypes(include = [np.number]).columns\n",
    "        outlier_report = {}\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            if X[col].nunique() > 10:                                 # Only for continuous variables\n",
    "                \n",
    "                # Method 1: IQR\n",
    "                \n",
    "                Q1 = X[col].quantile(0.25)\n",
    "                Q3 = X[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "                \n",
    "                # Method 2: Z-score (for normal distributions)\n",
    "                \n",
    "                z_scores = np.abs(stats.zscore(X[col].dropna()))\n",
    "                z_outliers = np.sum(z_scores > 3)\n",
    "                \n",
    "                # Method 3: Modified Z-score (more robust)\n",
    "                \n",
    "                median = X[col].median()\n",
    "                mad = stats.median_abs_deviation(X[col].dropna(), scale = 'normal')\n",
    "                modified_z_scores = 0.6745 * (X[col] - median) / mad\n",
    "                mod_z_outliers = np.sum(np.abs(modified_z_scores) > 3.5)\n",
    "                \n",
    "                # Use winsorization for extreme outliers\n",
    "                \n",
    "                if z_outliers > 0 or mod_z_outliers > 0:\n",
    "                \n",
    "                    # Cap outliers at 1st and 99th percentiles\n",
    "                    \n",
    "                    lower_cap = X[col].quantile(0.01)\n",
    "                    upper_cap = X[col].quantile(0.99)\n",
    "                    X[col] = np.where(X[col] < lower_cap, lower_cap, X[col])\n",
    "                    X[col] = np.where(X[col] > upper_cap, upper_cap, X[col])\n",
    "                    \n",
    "                    outlier_report[col] = {\n",
    "                        'iqr_outliers': np.sum((X[col] < lower_bound) | (X[col] > upper_bound)),\n",
    "                        'z_outliers': z_outliers,\n",
    "                        'modified_z_outliers': mod_z_outliers\n",
    "                    }\n",
    "        \n",
    "        if outlier_report:\n",
    "            print(f'  Handled outliers in {len(outlier_report)} features')\n",
    "            for col, report in list(outlier_report.items())[:5]:                                  # Show first 5\n",
    "                print(f'     {col}: IQR = {report['iqr_outliers']}, Z = {report['z_outliers']}, ModZ = {report['modified_z_outliers']}')\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def handle_imbalance(self, X, y):\n",
    "        'HANDLE IMBALANCED DATA USING ADVANCED TECHNIQUES'\n",
    "        print(' ⚖️ Handling class imbalance...')\n",
    "        \n",
    "        unique_classes, class_counts = np.unique(y, return_counts = True)\n",
    "        print(f'   Class distribution: {dict(zip(unique_classes, class_counts))}')\n",
    "        \n",
    "        # Calculate imbalance ratio\n",
    "        \n",
    "        imbalance_ratio = class_counts.max() / class_counts.min()\n",
    "        print(f'     Imbalance ratio: {imbalance_ratio:.2f}')\n",
    "        \n",
    "        if imbalance_ratio > 2:                                             # Significant imbalance\n",
    "            if len(unique_classes) == 2:                                    # Binary classification\n",
    "                \n",
    "                # Use SMOTE for oversampling\n",
    "                \n",
    "                smote = SMOTE(random_state = 42, k_neighbors = min(5, class_counts.min() - 1))\n",
    "                X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "                print('  Applied SMOTE for imbalance handling')\n",
    "            else:  # Multi-class\n",
    "                # Use RandomUnderSampler for multi-class\n",
    "                \n",
    "                rus = RandomUnderSampler(random_state = 42)\n",
    "                X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "                print('   Applied RandomUnderSampler for multi-class imbalance')\n",
    "            \n",
    "            unique_resampled, counts_resampled = np.unique(y_resampled, return_counts = True)\n",
    "            print(f'   Resampled distribution: {dict(zip(unique_resampled, counts_resampled))}')\n",
    "            return X_resampled, y_resampled\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def advanced_feature_engineering(self, X):\n",
    "        'ADVANCED FEATURE ENGINEERING - CORRECTED VERSION'\n",
    "        print(' 🔬 Advanced feature engineering...')\n",
    "        \n",
    "        numeric_cols = X.select_dtypes(include = [np.number]).columns\n",
    "        \n",
    "        # Create polynomial features for highly correlated numeric features\n",
    "        \n",
    "        if len(numeric_cols) >= 2:\n",
    "            try:\n",
    "                # Select top correlated features for polynomial features\n",
    "                \n",
    "                corr_matrix = X[numeric_cols].corr().abs()\n",
    "                \n",
    "                # Safely get high correlation pairs\n",
    "                \n",
    "                high_corr_pairs = []\n",
    "                for i in corr_matrix.columns:\n",
    "                    for j in corr_matrix.columns:\n",
    "                        if i != j and pd.notna(corr_matrix.loc[i, j]) and corr_matrix.loc[i, j] > 0.7:\n",
    "                            high_corr_pairs.append((i, j))\n",
    "                \n",
    "                if high_corr_pairs:\n",
    "                    for feat1, feat2 in high_corr_pairs[:3]:                       # Limit to top 3 pairs\n",
    "                        if feat1 in X.columns and feat2 in X.columns:\n",
    "                            \n",
    "                            # Check if columns are numeric and not empty\n",
    "                            \n",
    "                            if (X[feat1].dtype in [np.number] and \n",
    "                                X[feat2].dtype in [np.number] and \n",
    "                                len(X[feat1].dropna()) > 0 and \n",
    "                                len(X[feat2].dropna()) > 0):\n",
    "                                \n",
    "                                X[f'{feat1}_{feat2}_interaction'] = X[feat1] * X[feat2]\n",
    "                                \n",
    "                                # Avoid division by zero\n",
    "                                \n",
    "                                denominator = X[feat2].copy()\n",
    "                                denominator[denominator == 0] = 1e-8                   # Replace zeros with small value\n",
    "                                X[f'{feat1}_{feat2}_ratio'] = X[feat1] / denominator\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f'  ⚠️ Polynomial feature creation failed: {e}')\n",
    "        \n",
    "        # Create statistical features\n",
    "        \n",
    "        if len(numeric_cols) >= 3:\n",
    "            try:\n",
    "                X['feature_mean'] = X[numeric_cols].mean(axis = 1)\n",
    "                X['feature_std'] = X[numeric_cols].std(axis = 1)\n",
    "                X['feature_skew'] = X[numeric_cols].skew(axis = 1)\n",
    "            except Exception as e:\n",
    "                print(f'   ⚠️ Statistical feature creation failed: {e}')\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def smart_encoding_advanced(self, X):\n",
    "        'ADVANCED SMART ENCODING'\n",
    "        print('  🔠 Advanced feature encoding...')\n",
    "        \n",
    "        categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            unique_count = X[col].nunique()\n",
    "            \n",
    "            if unique_count <= 10:\n",
    "                \n",
    "                # One-hot encoding for low cardinality\n",
    "                \n",
    "                dummies = pd.get_dummies(X[col], prefix = col, drop_first = True)\n",
    "                X = pd.concat([X.drop(columns = [col]), dummies], axis = 1)\n",
    "                \n",
    "            elif unique_count <= 50:\n",
    "                \n",
    "                # Target encoding simulation (frequency encoding)\n",
    "                \n",
    "                freq_encoding = X[col].value_counts().to_dict()\n",
    "                X[col] = X[col].map(freq_encoding)\n",
    "                \n",
    "                # Normalize\n",
    "                \n",
    "                X[col] = (X[col] - X[col].mean()) / X[col].std()\n",
    "                \n",
    "            else:\n",
    "                # High cardinality - use clustering or hashing (simplified to frequency)\n",
    "                \n",
    "                top_categories = X[col].value_counts().head(20).index\n",
    "                X[col] = X[col].apply(lambda x: x if x in top_categories else 'Other')\n",
    "                \n",
    "                # Then use frequency encoding\n",
    "                \n",
    "                freq_encoding = X[col].value_counts().to_dict()\n",
    "                X[col] = X[col].map(freq_encoding)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def advanced_scaling_robust(self, X):\n",
    "        'ADVANCED ROBUST SCALING'\n",
    "        print('   ⚖️ Advanced robust scaling...')\n",
    "        \n",
    "        numeric_cols = X.select_dtypes(include = [np.number]).columns\n",
    "        \n",
    "        if len(numeric_cols) > 0:\n",
    "            \n",
    "            # Use RobustScaler for better outlier resistance\n",
    "            \n",
    "            self.scalers['robust'] = RobustScaler()\n",
    "            X[numeric_cols] = self.scalers['robust'].fit_transform(X[numeric_cols])\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def comprehensive_feature_selection(self, X, y, problem_type = 'regression'):\n",
    "        'COMPREHENSIVE FEATURE SELECTION USING MULTIPLE METHODS'\n",
    "        print('  🎯 Comprehensive feature selection...')\n",
    "        \n",
    "        if X.shape[1] <= 20:                                                      # Don't select if features are already few\n",
    "            return X\n",
    "        \n",
    "        # Method 1: Correlation-based\n",
    "        \n",
    "        if problem_type == 'regression':\n",
    "            selector = SelectKBest(score_func = f_regression, k = min(30, X.shape[1]))\n",
    "        else:\n",
    "            selector = SelectKBest(score_func = mutual_info_regression, k = min(30, X.shape[1]))\n",
    "        \n",
    "        try:\n",
    "            X_selected = selector.fit_transform(X, y)\n",
    "            selected_features = X.columns[selector.get_support()]\n",
    "            X = X[selected_features]\n",
    "            print(f'     Selected {len(selected_features)} features using statistical tests')\n",
    "        except:\n",
    "            print('   ⚠️ Statistical feature selection failed, using all features')\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def dimensionality_reduction(self, X, y = None):\n",
    "        'DIMENSIONALITY REDUCTION USING PCA'\n",
    "        print('  📉 Applying dimensionality reduction...')\n",
    "        \n",
    "        if X.shape[1] > 50:\n",
    "            self.pca = PCA(n_components = 0.95, random_state = 42)                          # Keep 95% variance\n",
    "            X_reduced = self.pca.fit_transform(X)\n",
    "            print(f'     Reduced from {X.shape[1]} to {X_reduced.shape[1]} components '\n",
    "                  f'({np.sum(self.pca.explained_variance_ratio_):.1%} variance)')\n",
    "            \n",
    "            return pd.DataFrame(X_reduced, columns = [f'PC_{i+1}' for i in range(X_reduced.shape[1])], \n",
    "                              index = X.index)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c91c8-52e7-4a10-a0fc-a76a0d21e539",
   "metadata": {},
   "source": [
    "# 3: Comprehensive EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9439d41b-4470-4010-a7b0-1cfafb7295b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ComprehensiveEDA:\n",
    "    \"\"\"\n",
    "    COMPREHENSIVE EDA: Univariate, Bivariate, and Multivariate Analysis with Caching\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir = 'eda_cache'):\n",
    "        self.eda_results = {}\n",
    "        self.correlation_matrix = None\n",
    "        self.feature_importance = None\n",
    "        self.cache_dir = cache_dir\n",
    "        os.makedirs(cache_dir, exist_ok = True)\n",
    "        self.cache_hits = 0\n",
    "        self.cache_misses = 0\n",
    "    \n",
    "    def perform_comprehensive_eda(self, df, target_column = None, save_plots = True, use_cache = True):\n",
    "        'PERFORM COMPREHENSIVE EDA WITH CACHING'\n",
    "        print(f'\\n📊 PERFORMING COMPREHENSIVE EDA ON {len(df)} RECORDS...')\n",
    "        \n",
    "        if df.empty:\n",
    "            print(' ⚠️ No data for EDA')\n",
    "            return\n",
    "        \n",
    "        # Create cache key\n",
    "        \n",
    "        cache_key = self._create_eda_cache_key(df, target_column)\n",
    "        cache_file = os.path.join(self.cache_dir, f'{cache_key}.pkl')\n",
    "        \n",
    "        if use_cache and os.path.exists(cache_file):\n",
    "            try:\n",
    "                with open(cache_file, 'rb') as f:\n",
    "                    cached_data = pickle.load(f)\n",
    "                \n",
    "                self.eda_results = cached_data.get('eda_results', {})\n",
    "                self.correlation_matrix = cached_data.get('correlation_matrix')\n",
    "                self.feature_importance = cached_data.get('feature_importance')\n",
    "                self.cache_hits += 1\n",
    "                \n",
    "                print(f'💾 Using cached EDA results: {cache_key}')\n",
    "                self.print_eda_summary()\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(f'⚠️ Could not load cached EDA: {e}')\n",
    "                self.cache_misses += 1\n",
    "        \n",
    "        self.cache_misses += 1\n",
    "        self.eda_results['dataset_info'] = self.get_dataset_info(df)\n",
    "        \n",
    "        # 1. Univariate Analysis\n",
    "        \n",
    "        print('   1. 📈 UNIVARIATE ANALYSIS...')\n",
    "        self.univariate_analysis(df, target_column, save_plots)\n",
    "        \n",
    "        # 2. Bivariate Analysis\n",
    "        \n",
    "        print('   2. 📊 BIVARIATE ANALYSIS...')\n",
    "        self.bivariate_analysis(df, target_column, save_plots)\n",
    "        \n",
    "        # 3. Multivariate Analysis\n",
    "        \n",
    "        print('   3. 🔍 MULTIVARIATE ANALYSIS...')\n",
    "        self.multivariate_analysis(df, target_column, save_plots)\n",
    "        \n",
    "        # 4. Statistical Analysis\n",
    "        \n",
    "        print('   4. 📋 STATISTICAL ANALYSIS...')\n",
    "        self.statistical_analysis(df, target_column)\n",
    "        \n",
    "        self.print_eda_summary()\n",
    "        \n",
    "        # Cache results\n",
    "        \n",
    "        if use_cache:\n",
    "            try:\n",
    "                cache_data = {\n",
    "                    'eda_results': self.eda_results,\n",
    "                    'correlation_matrix': self.correlation_matrix,\n",
    "                    'feature_importance': self.feature_importance\n",
    "                }\n",
    "                \n",
    "                with open(cache_file, 'wb') as f:\n",
    "                    pickle.dump(cache_data, f)\n",
    "                \n",
    "                print(f'💾 EDA results cached: {cache_key}')\n",
    "            except Exception as e:\n",
    "                print(f'⚠️ Could not cache EDA results: {e}')\n",
    "    \n",
    "    def _create_eda_cache_key(self, df, target_column):\n",
    "        'CREATE CACHE KEY FOR EDA RESULTS'\n",
    "        key_parts = [\n",
    "            f'rows_{len(df)}',\n",
    "            f'cols_{len(df.columns)}',\n",
    "            f'target_{target_column}',\n",
    "            f'hash_{hash(str(sorted(df.columns)))}'\n",
    "        ]\n",
    "        return hashlib.md5('_'.join(key_parts).encode()).hexdigest()\n",
    "    \n",
    "    def get_dataset_info(self, df):\n",
    "        'GET COMPREHENSIVE DATASET INFORMATION'\n",
    "        info = {\n",
    "            'shape': df.shape,\n",
    "            'data_types': df.dtypes.value_counts().to_dict(),\n",
    "            'missing_values': df.isnull().sum().sum(),\n",
    "            'missing_percentage': (df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100,\n",
    "            'duplicates': df.duplicated().sum(),\n",
    "            'memory_usage': df.memory_usage(deep = True).sum() / 1024**2,  # MB\n",
    "            'numeric_columns': len(df.select_dtypes(include = [np.number]).columns),\n",
    "            'categorical_columns': len(df.select_dtypes(include = ['object']).columns)\n",
    "        }\n",
    "        return info\n",
    "    \n",
    "    def univariate_analysis(self, df, target_column = None, save_plots = True):\n",
    "        'COMPREHENSIVE UNIVARIATE ANALYSIS'\n",
    "        numeric_cols = df.select_dtypes(include = [np.number]).columns\n",
    "        categorical_cols = df.select_dtypes(include = ['object']).columns\n",
    "        \n",
    "        # Create subplots for numeric features\n",
    "        \n",
    "        if len(numeric_cols) > 0:\n",
    "            n_cols = 3\n",
    "            n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
    "            \n",
    "            fig, axes = plt.subplots(n_rows, n_cols, figsize = (20, 5*n_rows))\n",
    "            axes = axes.flatten()\n",
    "            \n",
    "            for i, col in enumerate(numeric_cols):\n",
    "                if i < len(axes):\n",
    "                    \n",
    "                    # Histogram with KDE\n",
    "                    \n",
    "                    axes[i].hist(df[col].dropna(), bins = 30, alpha = 0.7, color = 'skyblue', edgecolor = 'black', density = True)\n",
    "                    df[col].dropna().plot.density(ax = axes[i], color = 'red', linewidth = 2)\n",
    "                    axes[i].set_title(f'Distribution of {col}', fontweight = 'bold')\n",
    "                    axes[i].set_xlabel(col)\n",
    "                    axes[i].set_ylabel('Density')\n",
    "                    \n",
    "                    # Add statistical annotations\n",
    "                    \n",
    "                    stats_text = f'Mean: {df[col].mean():.2f}\\nStd: {df[col].std():.2f}\\nSkew: {df[col].skew():.2f}'\n",
    "                    axes[i].text(0.05, 0.95, stats_text, transform = axes[i].transAxes, \n",
    "                                verticalalignment = 'top', bbox = dict(boxstyle = 'round', facecolor = 'white', alpha = 0.8))\n",
    "            \n",
    "            # Remove empty subplots\n",
    "            \n",
    "            for i in range(len(numeric_cols), len(axes)):\n",
    "                fig.delaxes(axes[i])\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            if save_plots:\n",
    "                plt.savefig('univariate_numeric_analysis.png', dpi = 300, bbox_inches = 'tight')\n",
    "            plt.close()\n",
    "        \n",
    "        # Categorical analysis\n",
    "            \n",
    "        if len(categorical_cols) > 0:\n",
    "            n_cols = 2\n",
    "            n_rows = (len(categorical_cols) + n_cols - 1) // n_cols\n",
    "            \n",
    "            fig, axes = plt.subplots(n_rows, n_cols, figsize = (15, 5*n_rows))\n",
    "            axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "            \n",
    "            for i, col in enumerate(categorical_cols):\n",
    "                if i < len(axes):\n",
    "                    value_counts = df[col].value_counts().head(10)                          # Top 10 categories\n",
    "                    axes[i].bar(value_counts.index, value_counts.values, color = 'lightcoral')\n",
    "                    axes[i].set_title(f'Top Categories in {col}', fontweight = 'bold')\n",
    "                    axes[i].set_xlabel(col)\n",
    "                    axes[i].set_ylabel('Count')\n",
    "                    axes[i].tick_params(axis = 'x', rotation = 45)\n",
    "            \n",
    "            # Remove empty subplots\n",
    "            \n",
    "            for i in range(len(categorical_cols), len(axes)):\n",
    "                fig.delaxes(axes[i])\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            if save_plots:\n",
    "                plt.savefig('univariate_categorical_analysis.png', dpi = 300, bbox_inches = 'tight')\n",
    "            plt.close()\n",
    "    \n",
    "    def bivariate_analysis(self, df, target_column = None, save_plots = True):\n",
    "        'COMPREHENSIVE BIVARIATE ANALYSIS'\n",
    "        if target_column is None or target_column not in df.columns:\n",
    "            print('  ⚠️ No target column specified for bivariate analysis')\n",
    "            return\n",
    "        \n",
    "        numeric_cols = df.select_dtypes(include = [np.number]).columns\n",
    "        \n",
    "        # Correlation with target\n",
    "        \n",
    "        if target_column in numeric_cols:\n",
    "            correlations = df[numeric_cols].corr()[target_column].sort_values(ascending = False)\n",
    "            self.correlation_matrix = df[numeric_cols].corr()\n",
    "            \n",
    "            # Plot top correlations\n",
    "            \n",
    "            top_correlations = correlations.head(10)[1:]                                   # Exclude target itself\n",
    "            \n",
    "            plt.figure(figsize = (12, 8))\n",
    "            y_pos = np.arange(len(top_correlations))\n",
    "            plt.barh(y_pos, top_correlations.values, color = 'lightseagreen')\n",
    "            plt.yticks(y_pos, top_correlations.index)\n",
    "            plt.xlabel('Correlation Coefficient')\n",
    "            plt.title(f'Top Features Correlated with {target_column}', fontweight = 'bold')\n",
    "            plt.grid(axis = 'x', alpha = 0.3)\n",
    "            \n",
    "            # Add correlation values on bars\n",
    "            \n",
    "            for i, v in enumerate(top_correlations.values):\n",
    "                plt.text(v + 0.01 if v >= 0 else v - 0.03, i, f'{v:.3f}', \n",
    "                        va = 'center', fontweight = 'bold')\n",
    "            \n",
    "            if save_plots:\n",
    "                plt.savefig('bivariate_correlations.png', dpi = 300, bbox_inches = 'tight')\n",
    "            plt.close()\n",
    "        \n",
    "        # Scatter plots for top 4 correlated features\n",
    "            \n",
    "        if target_column in numeric_cols and len(numeric_cols) > 1:\n",
    "            top_features = correlations.head(5).index[1:]                                  # Top 4 excluding target\n",
    "            \n",
    "            fig, axes = plt.subplots(2, 2, figsize = (15, 12))\n",
    "            axes = axes.flatten()\n",
    "            \n",
    "            for i, feature in enumerate(top_features[:4]):\n",
    "                if i < len(axes):\n",
    "                    axes[i].scatter(df[feature], df[target_column], alpha = 0.6, color = 'steelblue')\n",
    "                    axes[i].set_xlabel(feature)\n",
    "                    axes[i].set_ylabel(target_column)\n",
    "                    axes[i].set_title(f'{feature} vs {target_column}\\nCorr: {correlations[feature]:.3f}')\n",
    "                    \n",
    "                    # Add trend line\n",
    "                    \n",
    "                    z = np.polyfit(df[feature].dropna(), df[target_column].dropna(), 1)\n",
    "                    p = np.poly1d(z)\n",
    "                    axes[i].plot(df[feature].dropna(), p(df[feature].dropna()), 'r--', alpha = 0.8)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            if save_plots:\n",
    "                plt.savefig('bivariate_scatter_plots.png', dpi = 300, bbox_inches = 'tight')\n",
    "            plt.close()\n",
    "    \n",
    "    def multivariate_analysis(self, df, target_column = None, save_plots = True):\n",
    "        'COMPREHENSIVE MULTIVARIATE ANALYSIS'\n",
    "        numeric_cols = df.select_dtypes(include = [np.number]).columns\n",
    "        \n",
    "        if len(numeric_cols) > 1:\n",
    "            \n",
    "            # Correlation heatmap\n",
    "            \n",
    "            plt.figure(figsize = (16, 14))\n",
    "            correlation_matrix = df[numeric_cols].corr()\n",
    "            \n",
    "            # Create mask for upper triangle\n",
    "            \n",
    "            mask = np.triu(np.ones_like(correlation_matrix, dtype = bool))\n",
    "            \n",
    "            sns.heatmap(correlation_matrix, mask = mask, annot = True, fmt = '.2f', cmap = 'coolwarm',\n",
    "                       center = 0, square = True, linewidths = 0.5, cbar_kws = {'shrink': .8})\n",
    "            plt.title('Feature Correlation Heatmap', fontweight = 'bold', pad = 20)\n",
    "            plt.xticks(rotation = 45, ha = 'right')\n",
    "            plt.yticks(rotation = 0)\n",
    "            \n",
    "            if save_plots:\n",
    "                plt.savefig('multivariate_correlation_heatmap.png', dpi = 300, bbox_inches = 'tight')\n",
    "            plt.close()\n",
    "            \n",
    "            # Pairplot for top 5 features (if target specified)\n",
    "            \n",
    "            if target_column and target_column in numeric_cols and len(numeric_cols) >= 3:\n",
    "                top_features = correlation_matrix[target_column].abs().sort_values(ascending = False).head(6).index\n",
    "                pairplot_data = df[top_features].dropna()\n",
    "                \n",
    "                if len(pairplot_data) > 0:\n",
    "                    \n",
    "                    # Sample if too large for pairplot\n",
    "                    \n",
    "                    if len(pairplot_data) > 1000:\n",
    "                        pairplot_data = pairplot_data.sample(1000, random_state = 42)\n",
    "                    \n",
    "                    g = sns.pairplot(pairplot_data, diag_kind = 'hist', corner = True)\n",
    "                    g.fig.suptitle('Pairplot of Top Correlated Features', y = 1.02, fontweight = 'bold')\n",
    "                    \n",
    "                    if save_plots:\n",
    "                        plt.savefig('multivariate_pairplot.png', dpi = 300, bbox_inches = 'tight')\n",
    "                    plt.close()\n",
    "    \n",
    "    def statistical_analysis(self, df, target_column = None):\n",
    "        'COMPREHENSIVE STATISTICAL ANALYSIS'\n",
    "        numeric_cols = df.select_dtypes(include = [np.number]).columns\n",
    "        \n",
    "        statistical_summary = {}\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            statistical_summary[col] = {\n",
    "                'mean': df[col].mean(),\n",
    "                'median': df[col].median(),\n",
    "                'std': df[col].std(),\n",
    "                'skewness': df[col].skew(),\n",
    "                'kurtosis': df[col].kurtosis(),\n",
    "                'min': df[col].min(),\n",
    "                'max': df[col].max(),\n",
    "                'q1': df[col].quantile(0.25),\n",
    "                'q3': df[col].quantile(0.75),\n",
    "                'missing': df[col].isnull().sum(),\n",
    "                'zeros': (df[col] == 0).sum()\n",
    "            }\n",
    "        \n",
    "        self.eda_results['statistical_summary'] = statistical_summary\n",
    "        \n",
    "        # Normality tests for top numeric features\n",
    "        \n",
    "        normality_tests = {}\n",
    "        for col in list(numeric_cols)[:5]:                              # Test first 5 columns\n",
    "            data = df[col].dropna()\n",
    "            if len(data) > 3:\n",
    "                try:\n",
    "                    _, shapiro_p = shapiro(data)\n",
    "                    _, normaltest_p = normaltest(data)\n",
    "                    normality_tests[col] = {\n",
    "                        'shapiro_p': shapiro_p,\n",
    "                        'normaltest_p': normaltest_p,\n",
    "                        'is_normal': shapiro_p > 0.05 or normaltest_p > 0.05\n",
    "                    }\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        self.eda_results['normality_tests'] = normality_tests\n",
    "    \n",
    "    def print_eda_summary(self):\n",
    "        'PRINT COMPREHENSIVE EDA SUMMARY'\n",
    "        print('\\n' + '=' * 80)\n",
    "        print('COMPREHENSIVE EDA SUMMARY')\n",
    "        print('=' * 80)\n",
    "        \n",
    "        info = self.eda_results['dataset_info']\n",
    "        print(f'📁 DATASET OVERVIEW:')\n",
    "        print(f'   Shape: {info['shape'][0]:,} rows × {info['shape'][1]} columns')\n",
    "        print(f'   Memory Usage: {info['memory_usage']:.2f} MB')\n",
    "        print(f'   Numeric Features: {info['numeric_columns']}')\n",
    "        print(f'   Categorical Features: {info['categorical_columns']}')\n",
    "        print(f'   Missing Values: {info['missing_values']} ({info['missing_percentage']:.2f}%)')\n",
    "        print(f'   Duplicates: {info['duplicates']}')\n",
    "        \n",
    "        if 'statistical_summary' in self.eda_results:\n",
    "            stats = self.eda_results['statistical_summary']\n",
    "            print(f'\\n📊 STATISTICAL SUMMARY (Sample):')\n",
    "            for col in list(stats.keys())[:3]:\n",
    "                col_stats = stats[col]\n",
    "                print(f'   {col}:')\n",
    "                print(f'     Mean: {col_stats['mean']:.2f}, Std: {col_stats['std']:.2f}')\n",
    "                print(f'     Skewness: {col_stats['skewness']:.2f}, Kurtosis: {col_stats['kurtosis']:.2f}')\n",
    "        \n",
    "        if 'normality_tests' in self.eda_results:\n",
    "            normality = self.eda_results['normality_tests']\n",
    "            print(f'\\n📋 NORMALITY TESTS:')\n",
    "            for col, test in normality.items():\n",
    "                print(f'   {col}: Shapiro p = {test['shapiro_p']:.3f}, NormalTest p = {test['normaltest_p']:.3f}')\n",
    "                print(f'     Normally Distributed: {'Yes' if test['is_normal'] else 'No'}')\n",
    "        \n",
    "        # Cache statistics\n",
    "        \n",
    "        total_requests = self.cache_hits + self.cache_misses\n",
    "        hit_rate = (self.cache_hits / total_requests * 100) if total_requests > 0 else 0\n",
    "        print(f'\\n💾 EDA CACHE STATS: {self.cache_hits} hits, {self.cache_misses} misses ({hit_rate:.1f}% hit rate)')\n",
    "    \n",
    "    def clear_cache(self):\n",
    "        'CLEAR EDA CACHE'\n",
    "        try:\n",
    "            for filename in os.listdir(self.cache_dir):\n",
    "                file_path = os.path.join(self.cache_dir, filename)\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.remove(file_path)\n",
    "            print(f'🧹 EDA cache cleared: {self.cache_dir}')\n",
    "            self.cache_hits = 0\n",
    "            self.cache_misses = 0\n",
    "        except Exception as e:\n",
    "            print(f'⚠️ Error clearing EDA cache: {e}')\n",
    "    \n",
    "    def get_cache_stats(self):\n",
    "        'GET CACHE STATISTICS'\n",
    "        total_requests = self.cache_hits + self.cache_misses\n",
    "        hit_rate = (self.cache_hits / total_requests * 100) if total_requests > 0 else 0\n",
    "        return {\n",
    "            'hits': self.cache_hits,\n",
    "            'misses': self.cache_misses,\n",
    "            'total': total_requests,\n",
    "            'hit_rate': hit_rate,\n",
    "            'cache_dir': self.cache_dir\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c78ac0-9999-4082-b90b-574b6af33434",
   "metadata": {},
   "source": [
    "# 4: Advanced Learning Curves and Model Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c064550-e6a4-4a75-8586-c587b657c6c2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class AdvancedLearningCurves:\n",
    "    \"\"\"\n",
    "    ADVANCED LEARNING CURVES AND MODEL DIAGNOSTICS\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.learning_curves_data = {}\n",
    "        \n",
    "    def plot_advanced_learning_curves(self, model, X, y, model_name = 'Model', cv_folds = 5, scoring = None):\n",
    "        'PLOT ADVANCED LEARNING CURVES WITH MULTIPLE METRICS'\n",
    "        print(f'  📈 Generating advanced learning curves for {model_name}...')\n",
    "        \n",
    "        if scoring is None:\n",
    "            scoring = {'mae': 'neg_mean_absolute_error', 'mse': 'neg_mean_squared_error', 'r2': 'r2'}\n",
    "        \n",
    "        try:\n",
    "            train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "            learning_curves = {}\n",
    "            \n",
    "            for metric_name, metric_scorer in scoring.items():\n",
    "                train_sizes_abs, train_scores, test_scores = learning_curve(\n",
    "                    model, X, y, cv = cv_folds, train_sizes = train_sizes,\n",
    "                    scoring = metric_scorer, n_jobs = -1, random_state = 42\n",
    "                )\n",
    "                \n",
    "                # Convert scores (negative for some metrics)\n",
    "                \n",
    "                if metric_name in ['mae', 'mse']:\n",
    "                    train_scores = -train_scores\n",
    "                    test_scores = -test_scores\n",
    "                \n",
    "                learning_curves[metric_name] = {\n",
    "                    'train_sizes': train_sizes_abs,\n",
    "                    'train_scores_mean': np.mean(train_scores, axis = 1),\n",
    "                    'train_scores_std': np.std(train_scores, axis = 1),\n",
    "                    'test_scores_mean': np.mean(test_scores, axis = 1),\n",
    "                    'test_scores_std': np.std(test_scores, axis = 1)\n",
    "                }\n",
    "            \n",
    "            # Create subplots\n",
    "            \n",
    "            n_metrics = len(learning_curves)\n",
    "            fig, axes = plt.subplots(1, n_metrics, figsize = (6 * n_metrics, 5))\n",
    "            if n_metrics == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            for idx, (metric_name, curve_data) in enumerate(learning_curves.items()):\n",
    "                ax = axes[idx]\n",
    "                \n",
    "                # Plot learning curves\n",
    "                \n",
    "                ax.fill_between(curve_data['train_sizes'], \n",
    "                              curve_data['train_scores_mean'] - curve_data['train_scores_std'],\n",
    "                              curve_data['train_scores_mean'] + curve_data['train_scores_std'], \n",
    "                              alpha = 0.1, color = 'r')\n",
    "                ax.fill_between(curve_data['train_sizes'],\n",
    "                              curve_data['test_scores_mean'] - curve_data['test_scores_std'],\n",
    "                              curve_data['test_scores_mean'] + curve_data['test_scores_std'], \n",
    "                              alpha = 0.1, color = 'g')\n",
    "                \n",
    "                ax.plot(curve_data['train_sizes'], curve_data['train_scores_mean'], 'o-', \n",
    "                       color = 'r', label = 'Training score', linewidth = 2)\n",
    "                ax.plot(curve_data['train_sizes'], curve_data['test_scores_mean'], 'o-', \n",
    "                       color = 'g', label = 'Cross-validation score', linewidth = 2)\n",
    "                \n",
    "                ax.set_xlabel('Training examples')\n",
    "                ax.set_ylabel(metric_name.upper())\n",
    "                ax.set_title(f'Learning Curve - {metric_name.upper()}\\n{model_name}', fontweight = 'bold')\n",
    "                ax.legend(loc = 'best')\n",
    "                ax.grid(True, alpha = 0.3)\n",
    "                \n",
    "                # Add final score annotations\n",
    "                \n",
    "                final_train = curve_data['train_scores_mean'][-1]\n",
    "                final_test = curve_data['test_scores_mean'][-1]\n",
    "                gap = final_train - final_test\n",
    "                \n",
    "                ax.text(0.05, 0.15, f'Final Train: {final_train:.3f}\\nFinal CV: {final_test:.3f}\\nGap: {gap:.3f}', \n",
    "                       transform = ax.transAxes, bbox = dict(boxstyle = 'round', facecolor = 'white', alpha = 0.8))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'advanced_learning_curves_{model_name.replace(' ', '_').lower()}.png', \n",
    "                       dpi = 300, bbox_inches = 'tight')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f'   ✅ Advanced learning curves saved for {model_name}')\n",
    "            \n",
    "            # Bias-Variance Analysis\n",
    "            \n",
    "            self.analyze_bias_variance(learning_curves, model_name)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'  ⚠️  Could not generate advanced learning curves: {e}')\n",
    "    \n",
    "    def analyze_bias_variance(self, learning_curves, model_name):\n",
    "        'ANALYZE BIAS-VARIANCE TRADEOFF'\n",
    "        print(f'   📊 Bias-Variance Analysis for {model_name}:')\n",
    "        \n",
    "        # Use MAE for analysis (if available)\n",
    "        \n",
    "        if 'mae' in learning_curves:\n",
    "            curve_data = learning_curves['mae']\n",
    "            final_train_score = curve_data['train_scores_mean'][-1]\n",
    "            final_test_score = curve_data['test_scores_mean'][-1]\n",
    "            gap = final_train_score - final_test_score\n",
    "            \n",
    "            print(f'   Final Training MAE: {final_train_score:.3f}')\n",
    "            print(f'   Final CV MAE: {final_test_score:.3f}')\n",
    "            print(f'   Gap (Train - CV): {gap:.3f}')\n",
    "            \n",
    "            if gap > final_test_score * 0.5:\n",
    "                print('  ⚠️  HIGH VARIANCE DETECTED - Model is overfitting')\n",
    "                print('  Recommendations: Increase regularization, reduce model complexity, get more data')\n",
    "            elif final_test_score > final_train_score * 1.5:\n",
    "                print('  ⚠️  HIGH BIAS DETECTED - Model is underfitting')\n",
    "                print('     Recommendations: Increase model complexity, add more features, reduce regularization')\n",
    "            else:\n",
    "                print('  ✅ GOOD BIAS-VARIANCE TRADEOFF - Model is well-balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d9dd3-0e9a-4a08-adf0-1c27095dbf99",
   "metadata": {},
   "source": [
    "# 5: Comprehensive Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41675084-65c6-40ca-a9b7-8166715505d6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ComprehensiveHyperparameterTuner:\n",
    "    \"\"\"\n",
    "    COMPREHENSIVE HYPERPARAMETER TUNING WITH MULTIPLE STRATEGIES\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.best_params = {}\n",
    "        self.tuning_results = {}\n",
    "        self.best_models = {}\n",
    "        \n",
    "    def comprehensive_tuning(self, model, param_grid, X, y, problem_type = 'regression', \n",
    "                           tuning_method = 'randomized', cv_folds = 5, n_iter = 50):\n",
    "        'COMPREHENSIVE HYPERPARAMETER TUNING'\n",
    "        print(f' 🎯 Comprehensive hyperparameter tuning ({tuning_method})...')\n",
    "        \n",
    "        if problem_type == 'regression':\n",
    "            scoring = 'neg_mean_absolute_error'\n",
    "            refit = 'neg_mean_absolute_error'\n",
    "        else:\n",
    "            scoring = 'accuracy'\n",
    "            refit = 'accuracy'\n",
    "        \n",
    "        try:\n",
    "            if tuning_method == 'grid':\n",
    "                search = GridSearchCV(\n",
    "                    model, param_grid, cv = cv_folds, scoring = scoring, \n",
    "                    refit = refit, n_jobs = -1, verbose = 1\n",
    "                )\n",
    "            else:                                                               # randomized\n",
    "                search = RandomizedSearchCV(\n",
    "                    model, param_grid, cv = cv_folds, scoring = scoring,\n",
    "                    refit = refit, n_jobs = -1, verbose = 1, n_iter = n_iter, random_state = 42\n",
    "                )\n",
    "            \n",
    "            search.fit(X, y)\n",
    "            \n",
    "            # Store results\n",
    "            \n",
    "            model_name = type(model).__name__\n",
    "            self.best_params[model_name] = search.best_params_\n",
    "            self.best_models[model_name] = search.best_estimator_\n",
    "            self.tuning_results[model_name] = {\n",
    "                'best_score': search.best_score_,\n",
    "                'best_params': search.best_params_,\n",
    "                'cv_results': search.cv_results_\n",
    "            }\n",
    "            \n",
    "            print(f'  ✅ Tuning completed for {model_name}')\n",
    "            print(f'  Best Score: {search.best_score_:.4f}')\n",
    "            print(f'  Best Parameters: {search.best_params_}')\n",
    "            \n",
    "            # Plot tuning results\n",
    "            \n",
    "            self.plot_tuning_results(search, model_name)\n",
    "            \n",
    "            return search.best_estimator_\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'  ❌ Hyperparameter tuning failed: {e}')\n",
    "            return model\n",
    "    \n",
    "    def plot_tuning_results(self, search, model_name):\n",
    "        'PLOT HYPERPARAMETER TUNING RESULTS'\n",
    "        try:\n",
    "            results = pd.DataFrame(search.cv_results_)\n",
    "            \n",
    "            # Get the top 10 parameter combinations\n",
    "          \n",
    "            top_results = results.nlargest(10, 'mean_test_score')\n",
    "            \n",
    "            plt.figure(figsize = (12, 8))\n",
    "            y_pos = np.arange(len(top_results))\n",
    "            \n",
    "            plt.barh(y_pos, top_results['mean_test_score'], \n",
    "                    xerr = top_results['std_test_score'], \n",
    "                    alpha = 0.7, color = 'skyblue', ecolor = 'black', capsize = 5)\n",
    "            \n",
    "            plt.yticks(y_pos, [f'Config {i+1}' for i in range(len(top_results))])\n",
    "            plt.xlabel('Cross-Validation Score')\n",
    "            plt.title(f'Top 10 Hyperparameter Configurations - {model_name}', fontweight = 'bold')\n",
    "            plt.grid(axis = 'x', alpha = 0.3)\n",
    "            \n",
    "            # Add score values\n",
    "            \n",
    "            for i, v in enumerate(top_results['mean_test_score']):\n",
    "                plt.text(v + 0.01, i, f'{v:.4f}', va = 'center', fontweight = 'bold')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'hyperparameter_tuning_{model_name.replace(' ', '_').lower()}.png', \n",
    "                       dpi = 300, bbox_inches = 'tight')\n",
    "            plt.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'  ⚠️  Could not plot tuning results: {e}')\n",
    "    \n",
    "    def compare_models_comprehensive(self, models, X, y, problem_type = 'regression', cv_folds = 5):\n",
    "        'COMPREHENSIVE MODEL COMPARISON'\n",
    "        print(f'  🔄 Comprehensive model comparison...')\n",
    "        \n",
    "        model_comparison = {}\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            try:\n",
    "                if problem_type == 'regression':\n",
    "                    scores = cross_val_score(model, X, y, cv = cv_folds, scoring = 'neg_mean_absolute_error')\n",
    "                    scores = -scores                                              # Convert to positive\n",
    "                    mean_score = np.mean(scores)\n",
    "                    std_score = np.std(scores)\n",
    "                else:\n",
    "                    scores = cross_val_score(model, X, y, cv = cv_folds, scoring = 'accuracy')\n",
    "                    mean_score = np.mean(scores)\n",
    "                    std_score = np.std(scores)\n",
    "                \n",
    "                model_comparison[name] = {\n",
    "                    'mean_score': mean_score,\n",
    "                    'std_score': std_score,\n",
    "                    'scores': scores\n",
    "                }\n",
    "                \n",
    "                print(f'    {name}: {mean_score:.4f} ± {std_score:.4f}')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'   ⚠️  Error evaluating {name}: {e}')\n",
    "        \n",
    "        # Plot model comparison\n",
    "        \n",
    "        self.plot_model_comparison(model_comparison, problem_type)\n",
    "        \n",
    "        return model_comparison\n",
    "    \n",
    "    def plot_model_comparison(self, model_comparison, problem_type):\n",
    "        'PLOT MODEL COMPARISON RESULTS'\n",
    "        if not model_comparison:\n",
    "            return\n",
    "        \n",
    "        model_names = list(model_comparison.keys())\n",
    "        means = [model_comparison[name]['mean_score'] for name in model_names]\n",
    "        stds = [model_comparison[name]['std_score'] for name in model_names]\n",
    "        \n",
    "        plt.figure(figsize = (12, 8))\n",
    "        y_pos = np.arange(len(model_names))\n",
    "        \n",
    "        bars = plt.barh(y_pos, means, xerr = stds, alpha = 0.7, color = 'lightgreen', \n",
    "                       ecolor = 'black', capsize = 5)\n",
    "        \n",
    "        plt.yticks(y_pos, model_names)\n",
    "        if problem_type == 'regression':\n",
    "            plt.xlabel('Mean Absolute Error (Lower is Better)')\n",
    "        else:\n",
    "            plt.xlabel('Accuracy (Higher is Better)')\n",
    "        plt.title('Model Comparison - Cross-Validation Performance', fontweight = 'bold')\n",
    "        plt.grid(axis = 'x', alpha = 0.3)\n",
    "        \n",
    "        # Add values on bars\n",
    "        \n",
    "        for i, (mean, std) in enumerate(zip(means, stds)):\n",
    "            plt.text(mean + std + 0.01, i, f'{mean:.4f} ± {std:.4f}', \n",
    "                    va = 'center', fontweight = 'bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('model_comparison.png', dpi = 300, bbox_inches = 'tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd13d24-5957-4d90-8bc3-d993a8d56a69",
   "metadata": {},
   "source": [
    "# 6: Comprehensive Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2a7beb2-e065-4237-9e67-e249c275d9bd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Cell 6: Comprehensive Evaluation Metrics\n",
    "class ComprehensiveEvaluator:\n",
    "    \"\"\"\n",
    "    COMPREHENSIVE EVALUATION METRICS FOR REGRESSION AND CLASSIFICATION\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.evaluation_results = {}\n",
    "        \n",
    "    def comprehensive_regression_evaluation(self, model, X_train, X_test, y_train, y_test, model_name= 'Model'):\n",
    "        'COMPREHENSIVE REGRESSION EVALUATION'\n",
    "        print(f'  📊 Comprehensive regression evaluation for {model_name}...')\n",
    "        \n",
    "        # Predictions\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        \n",
    "        train_metrics = self.calculate_regression_metrics(y_train, y_train_pred, 'train')\n",
    "        test_metrics = self.calculate_regression_metrics(y_test, y_test_pred, 'test')\n",
    "        \n",
    "        # Store results\n",
    "        \n",
    "        self.evaluation_results[model_name] = {\n",
    "            'train': train_metrics,\n",
    "            'test': test_metrics,\n",
    "            'predictions': {\n",
    "                'train': y_train_pred,\n",
    "                'test': y_test_pred\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Print results\n",
    "        \n",
    "        self.print_regression_evaluation(train_metrics, test_metrics, model_name)\n",
    "        \n",
    "        # Plot results\n",
    "        \n",
    "        self.plot_regression_evaluation(y_train, y_train_pred, y_test, y_test_pred, model_name)\n",
    "        \n",
    "        return self.evaluation_results[model_name]\n",
    "    \n",
    "    def calculate_regression_metrics(self, y_true, y_pred, dataset_type):\n",
    "        'CALCULATE COMPREHENSIVE REGRESSION METRICS'\n",
    "        metrics = {\n",
    "            'mae': mean_absolute_error(y_true, y_pred),\n",
    "            'mse': mean_squared_error(y_true, y_pred),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "            'r2': r2_score(y_true, y_pred),\n",
    "            'mape': mean_absolute_percentage_error(y_true, y_pred),\n",
    "            'explained_variance': explained_variance_score(y_true, y_pred),\n",
    "            'max_error': max_error(y_true, y_pred)\n",
    "        }\n",
    "        \n",
    "        # Additional custom metrics\n",
    "        \n",
    "        absolute_errors = np.abs(y_true - y_pred)\n",
    "        metrics['mean_absolute_error'] = np.mean(absolute_errors)\n",
    "        metrics['median_absolute_error'] = np.median(absolute_errors)\n",
    "        metrics['std_absolute_error'] = np.std(absolute_errors)\n",
    "        \n",
    "        # Percentage within tolerance\n",
    "        \n",
    "        tolerance_5 = np.mean(absolute_errors <= 5) * 100\n",
    "        tolerance_3 = np.mean(absolute_errors <= 3) * 100\n",
    "        tolerance_1 = np.mean(absolute_errors <= 1) * 100\n",
    "        \n",
    "        metrics['within_5'] = tolerance_5\n",
    "        metrics['within_3'] = tolerance_3\n",
    "        metrics['within_1'] = tolerance_1\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def print_regression_evaluation(self, train_metrics, test_metrics, model_name):\n",
    "        'PRINT COMPREHENSIVE REGRESSION EVALUATION'\n",
    "        print(f'\\n     🎯 REGRESSION EVALUATION - {model_name}')\n",
    "        print('     ' + '=' * 50)\n",
    "        print('     Metric           |   Train   |   Test    |  Difference')\n",
    "        print('     ' + '-' * 50)\n",
    "        \n",
    "        metrics_to_display = ['mae', 'rmse', 'r2', 'mape']\n",
    "        \n",
    "        for metric in metrics_to_display:\n",
    "            train_val = train_metrics[metric]\n",
    "            test_val = test_metrics[metric]\n",
    "            diff = test_val - train_val\n",
    "            \n",
    "            if metric in ['r2']:                                        # Higher is better\n",
    "                diff_str = f'+{diff:.4f}' if diff > 0 else f'{diff:.4f}'\n",
    "            else:                                                        # Lower is better\n",
    "                diff_str = f'+{diff:.4f}' if diff > 0 else f'{diff:.4f}'\n",
    "            \n",
    "            print(f'     {metric.upper():<15} | {train_val:8.4f}  | {test_val:8.4f}  | {diff_str:>10}')\n",
    "        \n",
    "        print('     ' + '-' * 50)\n",
    "        print(f'     Within 1 position:  {test_metrics['within_1']:.1f}%')\n",
    "        print(f'     Within 3 positions: {test_metrics['within_3']:.1f}%')\n",
    "        print(f'     Within 5 positions: {test_metrics['within_5']:.1f}%')\n",
    "        \n",
    "        # Overfitting assessment\n",
    "        \n",
    "        mae_gap = test_metrics['mae'] - train_metrics['mae']\n",
    "        if mae_gap > train_metrics['mae'] * 0.3:\n",
    "            print('   ⚠️  SIGNIFICANT OVERFITTING DETECTED')\n",
    "        elif mae_gap < 0:\n",
    "            print('   ✅ Good generalization performance')\n",
    "        else:\n",
    "            print('   ℹ️  Moderate overfitting')\n",
    "    \n",
    "    def plot_regression_evaluation(self, y_train, y_train_pred, y_test, y_test_pred, model_name):\n",
    "        'PLOT COMPREHENSIVE REGRESSION EVALUATION VISUALIZATIONS'\n",
    "        fig, axes = plt.subplots(2, 2, figsize = (15, 12))\n",
    "        fig.suptitle(f'Regression Evaluation - {model_name}', fontsize = 16, fontweight = 'bold')\n",
    "        \n",
    "        # 1. Actual vs Predicted (Train)\n",
    "        \n",
    "        axes[0, 0].scatter(y_train, y_train_pred, alpha = 0.6, color = 'blue')\n",
    "        axes[0, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw = 2)\n",
    "        axes[0, 0].set_xlabel('Actual Values')\n",
    "        axes[0, 0].set_ylabel('Predicted Values')\n",
    "        axes[0, 0].set_title('Training Set: Actual vs Predicted')\n",
    "        axes[0, 0].grid(True, alpha = 0.3)\n",
    "        \n",
    "        # 2. Actual vs Predicted (Test)\n",
    "        \n",
    "        axes[0, 1].scatter(y_test, y_test_pred, alpha = 0.6, color = 'green')\n",
    "        axes[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw = 2)\n",
    "        axes[0, 1].set_xlabel('Actual Values')\n",
    "        axes[0, 1].set_ylabel('Predicted Values')\n",
    "        axes[0, 1].set_title('Test Set: Actual vs Predicted')\n",
    "        axes[0, 1].grid(True, alpha = 0.3)\n",
    "        \n",
    "        # 3. Residuals (Train)\n",
    "        \n",
    "        train_residuals = y_train - y_train_pred\n",
    "        axes[1, 0].scatter(y_train_pred, train_residuals, alpha = 0.6, color = 'blue')\n",
    "        axes[1, 0].axhline(y = 0, color = 'r', linestyle = '--')\n",
    "        axes[1, 0].set_xlabel('Predicted Values')\n",
    "        axes[1, 0].set_ylabel('Residuals')\n",
    "        axes[1, 0].set_title('Training Set: Residuals')\n",
    "        axes[1, 0].grid(True, alpha = 0.3)\n",
    "        \n",
    "        # 4. Residuals (Test)\n",
    "        \n",
    "        test_residuals = y_test - y_test_pred\n",
    "        axes[1, 1].scatter(y_test_pred, test_residuals, alpha = 0.6, color = 'green')\n",
    "        axes[1, 1].axhline(y = 0, color = 'r', linestyle = '--')\n",
    "        axes[1, 1].set_xlabel('Predicted Values')\n",
    "        axes[1, 1].set_ylabel('Residuals')\n",
    "        axes[1, 1].set_title('Test Set: Residuals')\n",
    "        axes[1, 1].grid(True, alpha = 0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'regression_evaluation_{model_name.replace('  ', '_').lower()}.png', \n",
    "                   dpi = 300, bbox_inches = 'tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def comprehensive_classification_evaluation(self, model, X_train, X_test, y_train, y_test, model_name = 'Classifier'):\n",
    "        'COMPREHENSIVE CLASSIFICATION EVALUATION'\n",
    "        print(f'   📊 Comprehensive classification evaluation for {model_name}...')\n",
    "        \n",
    "        # Predictions\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        y_train_proba = model.predict_proba(X_train) if hasattr(model, 'predict_proba') else None\n",
    "        y_test_proba = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Calculate metrics\n",
    "        \n",
    "        train_metrics = self.calculate_classification_metrics(y_train, y_train_pred, y_train_proba, 'train')\n",
    "        test_metrics = self.calculate_classification_metrics(y_test, y_test_pred, y_test_proba, 'test')\n",
    "        \n",
    "        # Store results\n",
    "        \n",
    "        self.evaluation_results[model_name] = {\n",
    "            'train': train_metrics,\n",
    "            'test': test_metrics,\n",
    "            'predictions': {\n",
    "                'train': y_train_pred,\n",
    "                'test': y_test_pred\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Print results\n",
    "        \n",
    "        self.print_classification_evaluation(train_metrics, test_metrics, model_name)\n",
    "        \n",
    "        # Plot results\n",
    "        \n",
    "        self.plot_classification_evaluation(y_test, y_test_pred, y_test_proba, model_name)\n",
    "        \n",
    "        return self.evaluation_results[model_name]\n",
    "    \n",
    "    def calculate_classification_metrics(self, y_true, y_pred, y_proba, dataset_type):\n",
    "        'CALCULATE COMPREHENSIVE CLASSIFICATION METRICS'\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision': precision_score(y_true, y_pred, average = 'weighted', zero_division = 0),\n",
    "            'recall': recall_score(y_true, y_pred, average = 'weighted', zero_division = 0),\n",
    "            'f1': f1_score(y_true, y_pred, average = 'weighted', zero_division = 0)\n",
    "        }\n",
    "        \n",
    "        # ROC-AUC if probabilities are available\n",
    "        \n",
    "        if y_proba is not None and len(np.unique(y_true)) == 2:                                         # Binary classification\n",
    "            metrics['roc_auc'] = roc_auc_score(y_true, y_proba[:, 1])\n",
    "        \n",
    "        # Additional metrics\n",
    "        \n",
    "        from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score\n",
    "        metrics['balanced_accuracy'] = balanced_accuracy_score(y_true, y_pred)\n",
    "        metrics['cohen_kappa'] = cohen_kappa_score(y_true, y_pred)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def print_classification_evaluation(self, train_metrics, test_metrics, model_name):\n",
    "        'PRINT COMPREHENSIVE CLASSIFICATION EVALUATION'\n",
    "        print(f'\\n     🎯 CLASSIFICATION EVALUATION - {model_name}')\n",
    "        print('     ' + '=' * 50)\n",
    "        print('     Metric           |   Train   |   Test    |  Difference')\n",
    "        print('     ' + '-' * 50)\n",
    "        \n",
    "        metrics_to_display = ['accuracy', 'precision', 'recall', 'f1']\n",
    "        if 'roc_auc' in test_metrics:\n",
    "            metrics_to_display.append('roc_auc')\n",
    "        \n",
    "        for metric in metrics_to_display:\n",
    "            train_val = train_metrics[metric]\n",
    "            test_val = test_metrics[metric]\n",
    "            diff = test_val - train_val\n",
    "            diff_str = f'+{diff:.4f}' if diff > 0 else f'{diff:.4f}'\n",
    "            \n",
    "            print(f'     {metric.upper():<15} | {train_val:8.4f}  | {test_val:8.4f}  | {diff_str:>10}')\n",
    "        \n",
    "        print('     ' + '-' * 50)\n",
    "        print(f'     Balanced Accuracy: {test_metrics['balanced_accuracy']:.4f}')\n",
    "        print(f'     Cohen's Kappa: {test_metrics['cohen_kappa']:.4f}')\n",
    "        \n",
    "        # Overfitting assessment\n",
    "        \n",
    "        accuracy_gap = train_metrics['accuracy'] - test_metrics['accuracy']\n",
    "        if accuracy_gap > 0.1:\n",
    "            print('     ⚠️  SIGNIFICANT OVERFITTING DETECTED')\n",
    "        elif accuracy_gap < 0.05:\n",
    "            print('     ✅ Good generalization performance')\n",
    "        else:\n",
    "            print('   ℹ️  Moderate overfitting')\n",
    "    \n",
    "    def plot_classification_evaluation(self, y_test, y_test_pred, y_test_proba, model_name):\n",
    "        'PLOT COMPREHENSIVE CLASSIFICATION EVALUATION VISUALIZATIONS'\n",
    "        fig, axes = plt.subplots(2, 2, figsize = (15, 12))\n",
    "        fig.suptitle(f'Classification Evaluation - {model_name}', fontsize = 16, fontweight = 'bold')\n",
    "        \n",
    "        # 1. Confusion Matrix\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_test_pred)\n",
    "        sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'Blues', ax = axes[0, 0])\n",
    "        axes[0, 0].set_xlabel('Predicted')\n",
    "        axes[0, 0].set_ylabel('Actual')\n",
    "        axes[0, 0].set_title('Confusion Matrix')\n",
    "        \n",
    "        # 2. Classification Report Heatmap\n",
    "        \n",
    "        cr = classification_report(y_test, y_test_pred, output_dict = True)\n",
    "        cr_df = pd.DataFrame(cr).iloc[:-1, :].T\n",
    "        sns.heatmap(cr_df, annot = True, cmap = 'viridis', ax = axes[0, 1])\n",
    "        axes[0, 1].set_title('Classification Report')\n",
    "        \n",
    "        # 3. ROC Curve (if binary classification and probabilities available)\n",
    "        \n",
    "        if y_test_proba is not None and len(np.unique(y_test)) == 2:\n",
    "            from sklearn.metrics import roc_curve\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_test_proba[:, 1])\n",
    "            axes[1, 0].plot(fpr, tpr, color = 'darkorange', lw = 2, label = f'ROC curve (AUC = {roc_auc_score(y_test, y_test_proba[:, 1]):.2f})')\n",
    "            axes[1, 0].plot([0, 1], [0, 1], color = 'navy', lw = 2, linestyle = '--')\n",
    "            axes[1, 0].set_xlabel('False Positive Rate')\n",
    "            axes[1, 0].set_ylabel('True Positive Rate')\n",
    "            axes[1, 0].set_title('ROC Curve')\n",
    "            axes[1, 0].legend(loc = 'lower right')\n",
    "            axes[1, 0].grid(True, alpha = 0.3)\n",
    "        \n",
    "        # 4. Feature Importance (if available)\n",
    "        \n",
    "        axes[1, 1].text(0.5, 0.5, 'Feature Importance\\nPlot Available\\nfor Tree-based Models', \n",
    "                       ha = 'center', va = 'center', transform = axes[1, 1].transAxes, fontsize = 12)\n",
    "        axes[1, 1].set_title('Feature Importance')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'classification_evaluation_{model_name.replace(' ', '_').lower()}.png', \n",
    "                   dpi = 300, bbox_inches = 'tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c21444-955c-4a84-a356-d48172f13286",
   "metadata": {},
   "source": [
    "# 7: MySQL Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b69203d2-b138-4b25-bde4-b0098231ac68",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class EnhancedMySQLF1Database:\n",
    "    \"\"\"\n",
    "    ENHANCED MYSQL DATABASE CONNECTION MANAGER WITH QUERY CACHING\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cache_ttl = 3600):                                # 1 hour default TTL\n",
    "        self.connection = None\n",
    "        self.config = {\n",
    "            'host': '127.0.0.1',\n",
    "            'port': 3306,\n",
    "            'user': 'hump-nduati',\n",
    "            'password': 'S0663072',\n",
    "            'database': 'F1--DB',\n",
    "            'charset': 'utf8mb4',\n",
    "            'collation': 'utf8mb4_unicode_ci',\n",
    "            'use_unicode': True\n",
    "        }\n",
    "        self.query_cache = {}\n",
    "        self.cache_ttl = cache_ttl\n",
    "        self.cache_enabled = True\n",
    "        self.cache_hits = 0\n",
    "        self.cache_misses = 0\n",
    "    \n",
    "    def connect(self):\n",
    "        'ESTABLISH MYSQL DATABASE CONNECTION'\n",
    "        try:\n",
    "            self.connection = mysql.connector.connect(**self.config)\n",
    "            if self.connection.is_connected():\n",
    "                print('✅ MySQL database connection established successfully')\n",
    "                return True\n",
    "        except Error as e:\n",
    "            print(f'❌ MySQL connection error: {e}')\n",
    "            return False\n",
    "    \n",
    "    def disconnect(self):\n",
    "        'CLOSE DATABASE CONNECTION'\n",
    "        if self.connection and self.connection.is_connected():\n",
    "            self.connection.close()\n",
    "            print('✅ MySQL database connection closed')\n",
    "    \n",
    "    def execute_query(self, query, params = None, use_cache = True, cache_ttl = None):\n",
    "        'EXECUTE SQL QUERY WITH OPTIONAL CACHING'\n",
    "        if cache_ttl is None:\n",
    "            cache_ttl = self.cache_ttl\n",
    "        \n",
    "        cache_key = self._create_cache_key(query, params)\n",
    "        \n",
    "        if use_cache and self.cache_enabled and cache_key in self.query_cache:\n",
    "            cached_data, timestamp = self.query_cache[cache_key]\n",
    "         \n",
    "            # Check if cache is still valid\n",
    "            \n",
    "            if time.time() - timestamp < cache_ttl:\n",
    "                self.cache_hits += 1\n",
    "                if self.cache_hits % 50 == 0:                                                 # Log every 50 cache hits\n",
    "                    print(f'  💾 Query cache hits: {self.cache_hits}, misses: {self.cache_misses}')\n",
    "                return cached_data\n",
    "        \n",
    "        try:\n",
    "            cursor = self.connection.cursor(dictionary = True)\n",
    "            cursor.execute(query, params or ())\n",
    "            result = cursor.fetchall()\n",
    "            cursor.close()\n",
    "            \n",
    "            # Cache the result\n",
    "            \n",
    "            if use_cache and self.cache_enabled:\n",
    "                self.query_cache[cache_key] = (result, time.time())\n",
    "                self.cache_misses += 1\n",
    "            \n",
    "            return result\n",
    "        except Error as e:\n",
    "            print(f'❌ MySQL query error: {e}')\n",
    "            print(f' Query: {query}')\n",
    "            return []\n",
    "    \n",
    "    def _create_cache_key(self, query, params):\n",
    "        'CREATE CACHE KEY FROM QUERY AND PARAMETERS'\n",
    "        key_string = f'{query}_{str(params)}'\n",
    "        return hashlib.md5(key_string.encode()).hexdigest()\n",
    "    \n",
    "    def load_table_data(self, table_name, columns = None, use_cache = True):\n",
    "        'LOAD TABLE DATA WITH SPECIFIC COLUMNS AND CACHING'\n",
    "        cache_key = f'table_{table_name}_{str(columns)}'\n",
    "        \n",
    "        if use_cache and self.cache_enabled and cache_key in self.query_cache:\n",
    "            cached_data, timestamp = self.query_cache[cache_key]\n",
    "            if time.time() - timestamp < self.cache_ttl:\n",
    "                self.cache_hits += 1\n",
    "                print(f'   💾 Using cached table data for {table_name}')\n",
    "                return cached_data.copy()  \n",
    "        \n",
    "        if columns:\n",
    "            columns_str = ', '.join([f'`{col}`' for col in columns])\n",
    "            query = f'SELECT {columns_str} FROM `{table_name}`'\n",
    "        else:\n",
    "            query = f'SELECT * FROM `{table_name}`'\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_sql(query, self.connection)\n",
    "            \n",
    "            # Cache the result\n",
    "           \n",
    "            if use_cache and self.cache_enabled:\n",
    "                self.query_cache[cache_key] = (df.copy(), time.time())\n",
    "                self.cache_misses += 1\n",
    "            \n",
    "            print(f'✅ Loaded {len(df)} records from {table_name}')\n",
    "            return df\n",
    "        except Error as e:\n",
    "            print(f'❌ Error loading table {table_name}: {e}')\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def clear_cache(self):\n",
    "        'CLEAR QUERY CACHE'\n",
    "        self.query_cache = {}\n",
    "        self.cache_hits = 0\n",
    "        self.cache_misses = 0\n",
    "        print('🧹 Database query cache cleared')\n",
    "    \n",
    "    def get_cache_stats(self):\n",
    "        'GET CACHE STATISTICS'\n",
    "        total_queries = self.cache_hits + self.cache_misses\n",
    "        hit_rate = (self.cache_hits / total_queries * 100) if total_queries > 0 else 0\n",
    "        return {\n",
    "            'hits': self.cache_hits,\n",
    "            'misses': self.cache_misses,\n",
    "            'total': total_queries,\n",
    "            'hit_rate': hit_rate,\n",
    "            'cached_queries': len(self.query_cache)\n",
    "        }\n",
    "    \n",
    "    def disable_caching(self):\n",
    "        'DISABLE QUERY CACHING'\n",
    "        self.cache_enabled = False\n",
    "        print('🚫 Database query caching disabled')\n",
    "    \n",
    "    def enable_caching(self):\n",
    "        'ENABLE QUERY CACHING'\n",
    "        self.cache_enabled = True\n",
    "        print('✅ Database query caching enabled')\n",
    "\n",
    "def load_enhanced_mysql_data(use_caching = True):\n",
    "    'LOAD COMPLETE F1 DATA FROM MYSQL DATABASE WITH CACHING'\n",
    "    print('🔄 LOADING COMPLETE F1 DATA FROM MYSQL DATABASE...')\n",
    "    \n",
    "    db = EnhancedMySQLF1Database()\n",
    "    \n",
    "    if not use_caching:\n",
    "        db.disable_caching()\n",
    "    \n",
    "    if not db.connect():\n",
    "        print('❌ Failed to connect to MySQL database')\n",
    "        return create_empty_datasets()\n",
    "    \n",
    "    dataframes = create_empty_datasets()\n",
    "    \n",
    "    # CORRECTED table mappings with actual column names from your schema\n",
    "    table_configs = {\n",
    "        'driver': {\n",
    "            'key': 'drivers',\n",
    "            'columns': ['id', 'name', 'first_name', 'last_name', 'full_name', 'abbreviation', \n",
    "                       'permanent_number', 'gender', 'date_of_birth', 'date_of_death',\n",
    "                       'place_of_birth', 'country_of_birth_country_id', 'nationality_country_id',\n",
    "                       'best_championship_position', 'best_starting_grid_position', 'best_race_result',\n",
    "                       'total_championship_wins', 'total_race_entries', 'total_race_starts',\n",
    "                       'total_race_wins', 'total_race_laps', 'total_podiums', 'total_points',\n",
    "                       'total_championship_points', 'total_pole_positions', 'total_fastest_laps']\n",
    "        },\n",
    "        'constructor': {\n",
    "            'key': 'constructors',\n",
    "            'columns': ['id', 'name', 'full_name', 'country_id', 'best_championship_position',\n",
    "                       'best_starting_grid_position', 'best_race_result', 'total_championship_wins',\n",
    "                       'total_race_entries', 'total_race_starts', 'total_race_wins', \n",
    "                       'total_1_and_2_finishes', 'total_race_laps', 'total_podiums',\n",
    "                       'total_podium_races', 'total_points', 'total_championship_points',\n",
    "                       'total_pole_positions', 'total_fastest_laps']\n",
    "        },\n",
    "        'circuit': {\n",
    "            'key': 'circuits', \n",
    "            'columns': ['id', 'name', 'full_name', 'previous_names', 'type', 'direction',\n",
    "                       'place_name', 'country_id', 'latitude', 'longitude', 'length', \n",
    "                       'turns', 'total_races_held']\n",
    "        },\n",
    "        'race': {\n",
    "            'key': 'races',\n",
    "            'columns': ['id', 'year', 'round', 'date', 'time', 'grand_prix_id', 'official_name',\n",
    "                       'qualifying_format', 'sprint_qualifying_format', 'circuit_id', 'circuit_type',\n",
    "                       'direction', 'course_length', 'turns', 'laps', 'distance', 'scheduled_laps',\n",
    "                       'scheduled_distance']\n",
    "        },\n",
    "        'race_data': {\n",
    "            'key': 'results',\n",
    "            'columns': ['race_id', 'type', 'position_display_order', 'position_number', 'position_text',\n",
    "                       'driver_number', 'driver_id', 'constructor_id', 'engine_manufacturer_id',\n",
    "                       'tyre_manufacturer_id', 'race_laps', 'race_time', 'race_time_millis',\n",
    "                       'race_points', 'race_grid_position_number', 'race_positions_gained',\n",
    "                       'race_pit_stops', 'race_fastest_lap']\n",
    "        },\n",
    "        'qualifying_result': {\n",
    "            'key': 'qualifying',\n",
    "            'columns': ['race_id', 'position_display_order', 'position_number', 'position_text',\n",
    "                       'driver_number', 'driver_id', 'constructor_id', 'time', 'time_millis', \n",
    "                       'q1', 'q1_millis', 'q2', 'q2_millis', 'q3', 'q3_millis']\n",
    "        },\n",
    "        'pit_stop': {\n",
    "            'key': 'pitStops',\n",
    "            'columns': ['race_id', 'driver_id', 'stop', 'lap', 'time', 'time_millis']\n",
    "        },\n",
    "        'grand_prix': {\n",
    "            'key': 'grandsPrix',\n",
    "            'columns': ['id', 'name', 'full_name', 'short_name', 'abbreviation', 'country_id']\n",
    "        },\n",
    "        'country': {\n",
    "            'key': 'countries',\n",
    "            'columns': ['id', 'alpha2_code', 'alpha3_code', 'name', 'demonym', 'continent_id']\n",
    "        },\n",
    "        'continent': {\n",
    "            'key': 'continents',\n",
    "            'columns': ['id', 'code', 'name', 'demonym']\n",
    "        },\n",
    "        'race_result': {\n",
    "            'key': 'race_results',\n",
    "            'columns': ['race_id', 'driver_id', 'constructor_id', 'position_number', 'position_text',\n",
    "                       'points', 'laps', 'time', 'time_millis', 'fastest_lap', 'grid_position_number']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Load all configured tables\n",
    "    for mysql_table, config in table_configs.items():\n",
    "        try:\n",
    "            dataframes[config['key']] = db.load_table_data(mysql_table, config.get('columns'), use_cache=use_caching)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error loading table {mysql_table}: {e}\")\n",
    "            dataframes[config['key']] = pd.DataFrame()\n",
    "    \n",
    "    # Load additional data with fallbacks\n",
    "    try:\n",
    "        dataframes['lapTimes'] = load_enhanced_lap_times_data(db, use_caching)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error loading lap times: {e}\")\n",
    "        dataframes['lapTimes'] = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        dataframes['fastestLaps'] = db.load_table_data('fastest_lap', ['race_id', 'driver_id', 'lap', 'time', 'time_millis'], use_cache = use_caching)\n",
    "    except Exception as e:\n",
    "        print(f'⚠️ Error loading fastest laps: {e}')\n",
    "        dataframes['fastestLaps'] = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        dataframes['startingGrid'] = db.load_table_data('starting_grid_position', ['race_id', 'driver_id', 'position_number'], use_cache = use_caching)\n",
    "    except Exception as e:\n",
    "        print(f'⚠️ Error loading starting grid: {e}')\n",
    "        dataframes['startingGrid'] = pd.DataFrame()\n",
    "    \n",
    "    dataframes['status'] = create_enhanced_status_codes()\n",
    "    \n",
    "    # Print cache statistics\n",
    "    \n",
    "    cache_stats = db.get_cache_stats()\n",
    "    print(f'📊 Database Cache Stats: {cache_stats['hits']} hits, {cache_stats['misses']} misses ({cache_stats['hit_rate']:.1f}% hit rate)')\n",
    "    \n",
    "    db.disconnect()\n",
    "    \n",
    "    # Print loaded data summary\n",
    "    \n",
    "    loaded_count = len([df for df in dataframes.values() if not df.empty])\n",
    "    total_records = sum([len(df) for df in dataframes.values() if not df.empty])\n",
    "    print(f'🎯 MYSQL DATA LOADING COMPLETE: {loaded_count} datasets with {total_records:,} total records')\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "def load_enhanced_lap_times_data(db, use_caching = True):\n",
    "    'LOAD ENHANCED LAP TIMES DATA FROM INTERACTIVE TABLES'\n",
    "    \n",
    "    # Try interactive lap performance matrix first\n",
    "    \n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            season_year as race_year,\n",
    "            round_number as race_round, \n",
    "            driver_code as driver_id,\n",
    "            driver_full_name,\n",
    "            constructor_name as constructor_id,\n",
    "            best_lap_time,\n",
    "            total_laps,\n",
    "            position,\n",
    "            session_date as race_date\n",
    "        FROM `interactive_lap_statistics_mat`\n",
    "        WHERE session_type = 'RACE'\n",
    "        LIMIT 10000\n",
    "        \"\"\"\n",
    "        lap_times = pd.read_sql(query, db.connection)\n",
    "        if not lap_times.empty:\n",
    "            print('✅ Loaded lap times from interactive_lap_statistics_mat')\n",
    "            return lap_times\n",
    "    except Exception as e:\n",
    "        print(f'⚠️ Could not load from interactive_lap_statistics_mat: {e}')\n",
    "    \n",
    "    # Fallback to fastest_lap table\n",
    "    \n",
    "    try:\n",
    "        fastest_laps = db.load_table_data('fastest_lap', ['race_id', 'driver_id', 'lap', 'time', 'time_millis'], use_cache = use_caching)\n",
    "        if not fastest_laps.empty:\n",
    "            print('✅ Created lap times from fastest_lap table')\n",
    "            return fastest_laps\n",
    "    except Exception as e:\n",
    "        print(f'⚠️ Could not load from fastest_lap: {e}')\n",
    "    \n",
    "    return pd.DataFrame()\n",
    "\n",
    "def create_enhanced_status_codes():\n",
    "    'CREATE ENHANCED STATUS CODES'\n",
    "    status_data = [\n",
    "        {'status_id': 1, 'status': 'Finished'},\n",
    "        {'status_id': 2, 'status': 'Disqualified'},\n",
    "        {'status_id': 3, 'status': 'Accident'},\n",
    "        {'status_id': 4, 'status': 'Collision'},\n",
    "        {'status_id': 5, 'status': 'Engine'},\n",
    "        {'status_id': 6, 'status': 'Gearbox'},\n",
    "        {'status_id': 7, 'status': 'Retired'},\n",
    "        {'status_id': 8, 'status': 'Technical'},\n",
    "        {'status_id': 9, 'status': 'Tyre'},\n",
    "        {'status_id': 10, 'status': 'Brakes'},\n",
    "        {'status_id': 11, 'status': 'Electrical'},\n",
    "        {'status_id': 12, 'status': 'Hydraulics'},\n",
    "        {'status_id': 13, 'status': 'Suspension'},\n",
    "        {'status_id': 14, 'status': 'Fuel System'},\n",
    "        {'status_id': 15, 'status': 'Wheel'}\n",
    "    ]\n",
    "    return pd.DataFrame(status_data)\n",
    "\n",
    "def create_empty_datasets():\n",
    "    'CREATE EMPTY DATASETS WITH ENHANCED STRUCTURE'\n",
    "    empty_dfs = {}\n",
    "    expected_keys = [\n",
    "        'drivers', 'constructors', 'circuits', 'races', 'countries', 'continents',\n",
    "        'grandsPrix', 'results', 'qualifying', 'pitStops', 'lapTimes', 'fastestLaps',\n",
    "        'startingGrid', 'status', 'engineManufacturers', 'tyreManufacturers', 'entrants',\n",
    "        'race_results'\n",
    "    ]\n",
    "    \n",
    "    for key in expected_keys:\n",
    "        empty_dfs[key] = pd.DataFrame()\n",
    "    \n",
    "    return empty_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc151e15-4c35-4bd1-834f-e405b659f154",
   "metadata": {},
   "source": [
    "# 8: Weather Data Integration with Enhanced Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c747ea8-30c6-4d46-a9db-24483ffa461e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class RealWeatherDataIntegrator:\n",
    "    \"\"\"\n",
    "    COMPREHENSIVE REAL WEATHER DATA INTEGRATION WITH ENHANCED CACHING\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, circuits_df, cache_file='weather_cache.json', cache_ttl_days=30):\n",
    "        self.base_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "        self.weather_cache = {}\n",
    "        self.cache_file = cache_file\n",
    "        self.cache_ttl_days = cache_ttl_days\n",
    "        self.request_delay = 1\n",
    "        self.circuits_df = circuits_df\n",
    "        self.circuit_coordinates = self.build_complete_circuit_coordinates()\n",
    "        self.load_weather_cache()  # Load existing cache\n",
    "    \n",
    "    def load_weather_cache(self):\n",
    "        \"\"\"LOAD PERSISTENT WEATHER CACHE FROM DISK WITH TTL VALIDATION\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(self.cache_file):\n",
    "                with open(self.cache_file, 'r') as f:\n",
    "                    cache_data = json.load(f)\n",
    "                \n",
    "                # Filter out expired cache entries\n",
    "                current_time = time.time()\n",
    "                self.weather_cache = {}\n",
    "                expired_count = 0\n",
    "                \n",
    "                for key, cache_entry in cache_data.items():\n",
    "                    if current_time - cache_entry.get('timestamp', 0) < self.cache_ttl_days * 24 * 3600:\n",
    "                        self.weather_cache[key] = cache_entry['data']\n",
    "                    else:\n",
    "                        expired_count += 1\n",
    "                \n",
    "                print(f\"✅ Loaded weather cache with {len(self.weather_cache)} valid entries ({expired_count} expired)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not load weather cache: {e}\")\n",
    "            self.weather_cache = {}\n",
    "    \n",
    "    def save_weather_cache(self):\n",
    "        \"\"\"SAVE WEATHER CACHE TO DISK WITH TIMESTAMP\"\"\"\n",
    "        try:\n",
    "            cache_data = {}\n",
    "            current_time = time.time()\n",
    "            \n",
    "            for key, data in self.weather_cache.items():\n",
    "                cache_data[key] = {\n",
    "                    'data': data,\n",
    "                    'timestamp': current_time\n",
    "                }\n",
    "            \n",
    "            with open(self.cache_file, 'w') as f:\n",
    "                json.dump(cache_data, f, indent=2)\n",
    "            \n",
    "            print(f\"💾 Weather cache saved with {len(self.weather_cache)} entries\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not save weather cache: {e}\")\n",
    "    \n",
    "    def build_complete_circuit_coordinates(self):\n",
    "        \"\"\"BUILD COMPLETE CIRCUIT COORDINATES DATABASE FROM MYSQL DATA\"\"\"\n",
    "        circuit_coordinates = {}\n",
    "        \n",
    "        if self.circuits_df.empty:\n",
    "            print(\"⚠️ No circuit data available, using fallback coordinates\")\n",
    "            return self.get_fallback_coordinates()\n",
    "        \n",
    "        for _, circuit in self.circuits_df.iterrows():\n",
    "            circuit_id = circuit['id']\n",
    "            circuit_name = circuit['name']\n",
    "            latitude = circuit.get('latitude')\n",
    "            longitude = circuit.get('longitude')\n",
    "            \n",
    "            if pd.notna(latitude) and pd.notna(longitude):\n",
    "                # Determine timezone based on coordinates\n",
    "                \n",
    "                timezone = self.estimate_timezone(latitude, longitude)\n",
    "                circuit_coordinates[circuit_id] = {\n",
    "                    'latitude': float(latitude),\n",
    "                    'longitude': float(longitude),\n",
    "                    'timezone': timezone,\n",
    "                    'name': circuit_name\n",
    "                }\n",
    "                print(f\"   📍 Loaded coordinates for {circuit_name}: ({latitude}, {longitude})\")\n",
    "            else:\n",
    "                # Use name-based lookup as fallback\n",
    "              \n",
    "                coords = self.lookup_circuit_by_name(circuit_name)\n",
    "                circuit_coordinates[circuit_id] = coords\n",
    "                print(f\"   📍 Estimated coordinates for {circuit_name}: {coords['latitude']}, {coords['longitude']}\")\n",
    "        \n",
    "        print(f\"✅ Loaded coordinates for {len(circuit_coordinates)} circuits\")\n",
    "        return circuit_coordinates\n",
    "    \n",
    "    def lookup_circuit_by_name(self, circuit_name):\n",
    "        \"\"\"LOOKUP CIRCUIT COORDINATES BY NAME PATTERN MATCHING\"\"\"\n",
    "        circuit_name_lower = circuit_name.lower()\n",
    "        \n",
    "        # Comprehensive F1 circuit coordinates database\n",
    "        known_circuits = {\n",
    "            'monza': {'latitude': 45.6156, 'longitude': 9.2811, 'timezone': 'Europe/Rome'},\n",
    "            'monaco': {'latitude': 43.7347, 'longitude': 7.4206, 'timezone': 'Europe/Monaco'},\n",
    "            'silverstone': {'latitude': 52.0786, 'longitude': -1.0169, 'timezone': 'Europe/London'},\n",
    "            'spa': {'latitude': 50.4372, 'longitude': 5.9714, 'timezone': 'Europe/Brussels'},\n",
    "            'hungaroring': {'latitude': 47.5819, 'longitude': 19.2486, 'timezone': 'Europe/Budapest'},\n",
    "            'red bull ring': {'latitude': 47.2197, 'longitude': 14.7647, 'timezone': 'Europe/Vienna'},\n",
    "            'zandvoort': {'latitude': 52.3886, 'longitude': 4.5408, 'timezone': 'Europe/Amsterdam'},\n",
    "            'barcelona': {'latitude': 41.57, 'longitude': 2.2611, 'timezone': 'Europe/Madrid'},\n",
    "            'imola': {'latitude': 44.3439, 'longitude': 11.7167, 'timezone': 'Europe/Rome'},\n",
    "            'bahrain': {'latitude': 26.0325, 'longitude': 50.5106, 'timezone': 'Asia/Bahrain'},\n",
    "            'yas marina': {'latitude': 24.4672, 'longitude': 54.6039, 'timezone': 'Asia/Dubai'},\n",
    "            'jeddah': {'latitude': 21.6319, 'longitude': 39.1044, 'timezone': 'Asia/Riyadh'},\n",
    "            'suzuka': {'latitude': 34.8431, 'longitude': 136.5411, 'timezone': 'Asia/Tokyo'},\n",
    "            'shanghai': {'latitude': 31.3389, 'longitude': 121.2200, 'timezone': 'Asia/Shanghai'},\n",
    "            'singapore': {'latitude': 1.2914, 'longitude': 103.8644, 'timezone': 'Asia/Singapore'},\n",
    "            'cota': {'latitude': 30.1339, 'longitude': -97.6406, 'timezone': 'America/Chicago'},\n",
    "            'interlagos': {'latitude': -23.7036, 'longitude': -46.6997, 'timezone': 'America/Sao_Paulo'},\n",
    "            'montreal': {'latitude': 45.5000, 'longitude': -73.5228, 'timezone': 'America/Montreal'},\n",
    "            'mexico city': {'latitude': 19.4042, 'longitude': -99.0907, 'timezone': 'America/Mexico_City'},\n",
    "            'miami': {'latitude': 25.9581, 'longitude': -80.2389, 'timezone': 'America/New_York'},\n",
    "            'las vegas': {'latitude': 36.1147, 'longitude': -115.1739, 'timezone': 'America/Los_Angeles'},\n",
    "            'melbourne': {'latitude': -37.8494, 'longitude': 144.9686, 'timezone': 'Australia/Melbourne'},\n",
    "            'albert park': {'latitude': -37.8494, 'longitude': 144.9686, 'timezone': 'Australia/Melbourne'},\n",
    "            'baku': {'latitude': 40.3725, 'longitude': 49.8533, 'timezone': 'Asia/Baku'},\n",
    "            'sochi': {'latitude': 43.4057, 'longitude': 39.9653, 'timezone': 'Europe/Moscow'},\n",
    "            'istanbul': {'latitude': 40.9517, 'longitude': 29.4050, 'timezone': 'Europe/Istanbul'},\n",
    "            'portimão': {'latitude': 37.2275, 'longitude': -8.6267, 'timezone': 'Europe/Lisbon'},\n",
    "            'nürburgring': {'latitude': 50.3356, 'longitude': 6.9475, 'timezone': 'Europe/Berlin'},\n",
    "            'hockenheim': {'latitude': 49.3303, 'longitude': 8.5653, 'timezone': 'Europe/Berlin'},\n",
    "            'sepang': {'latitude': 2.7611, 'longitude': 101.7383, 'timezone': 'Asia/Kuala_Lumpur'},\n",
    "            'fuji': {'latitude': 35.3717, 'longitude': 138.9272, 'timezone': 'Asia/Tokyo'},\n",
    "            'indianapolis': {'latitude': 39.7953, 'longitude': -86.2347, 'timezone': 'America/New_York'},\n",
    "            'rodriguez': {'latitude': 19.4042, 'longitude': -99.0907, 'timezone': 'America/Mexico_City'},\n",
    "            'kyalami': {'latitude': -25.9894, 'longitude': 28.0750, 'timezone': 'Africa/Johannesburg'},\n",
    "            'losail': {'latitude': 25.4903, 'longitude': 51.4525, 'timezone': 'Asia/Qatar'}\n",
    "        }\n",
    "        \n",
    "        # Try direct matches first\n",
    "        \n",
    "        for known_name, coords in known_circuits.items():\n",
    "            if known_name in circuit_name_lower:\n",
    "                return coords\n",
    "        \n",
    "        # Try partial matches\n",
    "        \n",
    "        partial_matches = {\n",
    "            'monza': ['monza', 'autodromo nazionale'],\n",
    "            'silverstone': ['silverstone', 'british grand prix'],\n",
    "            'spa': ['spa', 'spa-francorchamps', 'belgian grand prix'],\n",
    "            'monaco': ['monaco', 'monte carlo'],\n",
    "            'interlagos': ['interlagos', 'sao paulo', 'brazilian grand prix'],\n",
    "            'cota': ['cota', 'circuit of the americas', 'austin'],\n",
    "            'yas marina': ['yas marina', 'abu dhabi', 'yas island'],\n",
    "            'bahrain': ['bahrain', 'sakhir', 'bahrain international circuit'],\n",
    "            'red bull ring': ['red bull', 'spielberg', 'austrian grand prix'],\n",
    "            'hungaroring': ['hungaroring', 'hungarian grand prix'],\n",
    "            'zandvoort': ['zandvoort', 'dutch grand prix'],\n",
    "            'barcelona': ['barcelona', 'catalunya', 'spanish grand prix'],\n",
    "            'imola': ['imola', 'emilia romagna', 'san marino'],\n",
    "            'suzuka': ['suzuka', 'japanese grand prix'],\n",
    "            'melbourne': ['melbourne', 'albert park', 'australian grand prix']\n",
    "        }\n",
    "        \n",
    "        for standard_name, variations in partial_matches.items():\n",
    "            for variation in variations:\n",
    "                if variation in circuit_name_lower:\n",
    "                    return known_circuits[standard_name]\n",
    "        \n",
    "        print(f\"   ⚠️ Unknown circuit: {circuit_name}, using Monza coordinates\")\n",
    "        return known_circuits['monza']\n",
    "    \n",
    "    def estimate_timezone(self, latitude, longitude):\n",
    "        \"\"\"ESTIMATE TIMEZONE BASED ON COORDINATES\"\"\"\n",
    "        \n",
    "        # Simple timezone estimation based on longitude\n",
    "        \n",
    "        if -10 <= longitude <= 40:  # Europe/Africa\n",
    "            return 'Europe/London'\n",
    "        elif -80 <= longitude <= -30:  # Americas\n",
    "            return 'America/New_York'\n",
    "        elif 100 <= longitude <= 150:  # East Asia\n",
    "            return 'Asia/Tokyo'\n",
    "        elif 50 <= longitude <= 80:  # Middle East/India\n",
    "            return 'Asia/Dubai'\n",
    "        else:\n",
    "            return 'UTC'\n",
    "    \n",
    "    def get_fallback_coordinates(self):\n",
    "        \"\"\"GET FALLBACK COORDINATES WHEN NO CIRCUIT DATA IS AVAILABLE\"\"\"\n",
    "        return {\n",
    "            'default': {'latitude': 45.6156, 'longitude': 9.2811, 'timezone': 'Europe/Rome', 'name': 'Monza'}\n",
    "        }\n",
    "    \n",
    "    def fetch_real_weather_data(self, circuit_id, race_date, days_before = 3, days_after = 1):\n",
    "        'FETCH REAL HISTORICAL WEATHER DATA WITH ENHANCED CACHING'\n",
    "        cache_key = f\"{circuit_id}_{race_date}\"\n",
    "        \n",
    "        # Check memory cache first\n",
    "        \n",
    "        if cache_key in self.weather_cache:\n",
    "            print(f\"   📦 Using cached weather data for circuit {circuit_id}\")\n",
    "            return self.weather_cache[cache_key]\n",
    "        \n",
    "        # Check if we can use similar historical data (same circuit, similar date)\n",
    "        \n",
    "        similar_cache_key = self.find_similar_weather_data(circuit_id, race_date)\n",
    "        if similar_cache_key:\n",
    "            print(f\"   🔄 Using similar weather data from {similar_cache_key}\")\n",
    "            similar_data = self.weather_cache[similar_cache_key]\n",
    "            \n",
    "            # Store this as the new cache entry to avoid future lookups\n",
    "        \n",
    "            self.weather_cache[cache_key] = similar_data\n",
    "            self.save_weather_cache()\n",
    "            return similar_data\n",
    "        \n",
    "        # Get circuit coordinates\n",
    "        \n",
    "        if circuit_id not in self.circuit_coordinates:\n",
    "            print(f\"   ⚠️ Circuit {circuit_id} not found in coordinates database\")\n",
    "            return None\n",
    "        \n",
    "        coords = self.circuit_coordinates[circuit_id]\n",
    "        circuit_name = coords['name']\n",
    "        \n",
    "        try:\n",
    "            start_date = (pd.to_datetime(race_date) - timedelta(days=days_before)).strftime('%Y-%m-%d')\n",
    "            end_date = (pd.to_datetime(race_date) + timedelta(days=days_after)).strftime('%Y-%m-%d')\n",
    "            \n",
    "            params = {\n",
    "                'latitude': coords['latitude'],\n",
    "                'longitude': coords['longitude'],\n",
    "                'start_date': start_date,\n",
    "                'end_date': end_date,\n",
    "                'hourly': [\n",
    "                    'temperature_2m', 'relative_humidity_2m', 'dew_point_2m',\n",
    "                    'precipitation', 'rain', 'snowfall', 'weather_code',\n",
    "                    'pressure_msl', 'surface_pressure', 'cloud_cover',\n",
    "                    'cloud_cover_low', 'cloud_cover_mid', 'cloud_cover_high',\n",
    "                    'wind_speed_10m', 'wind_direction_10m', 'wind_gusts_10m',\n",
    "                    'visibility', 'is_day'\n",
    "                ],\n",
    "                'timezone': coords['timezone']\n",
    "            }\n",
    "            \n",
    "            print(f'   🌤️ Fetching real weather data for {circuit_name} ({start_date} to {end_date})...')\n",
    "            \n",
    "            response = requests.get(self.base_url, params = params, timeout = 30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                weather_data = response.json()\n",
    "                \n",
    "                # Cache the result\n",
    "                \n",
    "                self.weather_cache[cache_key] = weather_data\n",
    "                self.save_weather_cache()  \n",
    "                print(f'   ✅ Real weather data fetched and cached for {circuit_name}')\n",
    "                return weather_data\n",
    "            else:\n",
    "                print(f'   ❌ API request failed for {circuit_name}: HTTP {response.status_code}')\n",
    "                \n",
    "                # Return demo data that matches real conditions\n",
    "                \n",
    "                demo_data = self.generate_realistic_weather_data(race_date, coords)\n",
    "                self.weather_cache[cache_key] = demo_data\n",
    "                self.save_weather_cache()\n",
    "                return demo_data\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f'   ❌ Error fetching real weather for {circuit_name}: {str(e)}')\n",
    "            \n",
    "            # Return realistic demo data based on circuit location and season\n",
    "            \n",
    "            demo_data = self.generate_realistic_weather_data(race_date, coords)\n",
    "            self.weather_cache[cache_key] = demo_data\n",
    "            self.save_weather_cache()\n",
    "            return demo_data\n",
    "    \n",
    "    def find_similar_weather_data(self, circuit_id, target_date):\n",
    "        'FIND SIMILAR WEATHER DATA FOR THE SAME CIRCUIT AND SIMILAR DATE'\n",
    "        target_dt = pd.to_datetime(target_date)\n",
    "        \n",
    "        for cache_key in self.weather_cache.keys():\n",
    "            if circuit_id in cache_key:\n",
    "                \n",
    "                # Extract date from cache key\n",
    "                \n",
    "                try:\n",
    "                    cached_circuit, cached_date = cache_key.split('_', 1)\n",
    "                    if cached_circuit == circuit_id:\n",
    "                        cached_dt = pd.to_datetime(cached_date)\n",
    "                \n",
    "                        # Check if dates are close (within 2 weeks)\n",
    "                        \n",
    "                        date_diff = abs((cached_dt - target_dt).days)\n",
    "                        if date_diff <= 14:  # Same season period\n",
    "                            return cache_key\n",
    "                except:\n",
    "                    continue\n",
    "        return None\n",
    "    \n",
    "    def generate_realistic_weather_data(self, race_date, coords):\n",
    "        'GENERATE REALISTIC WEATHER DATA BASED ON LOCATION AND SEASON'\n",
    "        race_dt = pd.to_datetime(race_date)\n",
    "        month = race_dt.month\n",
    "        latitude = coords['latitude']\n",
    "        \n",
    "        # Seasonal patterns\n",
    "        \n",
    "        if latitude > 40:  # Northern hemisphere\n",
    "            if month in [12, 1, 2]:  # Winter\n",
    "                base_temp = 5 + np.random.normal(0, 3)\n",
    "                rain_prob = 0.4\n",
    "            elif month in [3, 4, 5]:  # Spring\n",
    "                base_temp = 15 + np.random.normal(0, 4)\n",
    "                rain_prob = 0.3\n",
    "            elif month in [6, 7, 8]:  # Summer\n",
    "                base_temp = 25 + np.random.normal(0, 5)\n",
    "                rain_prob = 0.2\n",
    "            else:  # Autumn\n",
    "                base_temp = 15 + np.random.normal(0, 4)\n",
    "                rain_prob = 0.35\n",
    "        elif latitude < -20:  # Southern hemisphere\n",
    "            if month in [12, 1, 2]:  # Summer\n",
    "                base_temp = 25 + np.random.normal(0, 5)\n",
    "                rain_prob = 0.2\n",
    "            elif month in [3, 4, 5]:  # Autumn\n",
    "                base_temp = 15 + np.random.normal(0, 4)\n",
    "                rain_prob = 0.35\n",
    "            elif month in [6, 7, 8]:  # Winter\n",
    "                base_temp = 5 + np.random.normal(0, 3)\n",
    "                rain_prob = 0.4\n",
    "            else:  # Spring\n",
    "                base_temp = 15 + np.random.normal(0, 4)\n",
    "                rain_prob = 0.3\n",
    "        else:  # Tropical regions\n",
    "            base_temp = 28 + np.random.normal(0, 3)\n",
    "            rain_prob = 0.25\n",
    "        \n",
    "        # Adjust for specific circuit characteristics\n",
    "        \n",
    "        if 'monaco' in coords['name'].lower() or 'monte carlo' in coords['name'].lower():\n",
    "            base_temp += 2  # Mediterranean climate\n",
    "            rain_prob = 0.15\n",
    "        elif 'bahrain' in coords['name'].lower() or 'abu dhabi' in coords['name'].lower():\n",
    "            base_temp = 35 + np.random.normal(0, 2)  # Desert climate\n",
    "            rain_prob = 0.01\n",
    "        elif 'silverstone' in coords['name'].lower():\n",
    "            rain_prob = 0.5  # UK climate\n",
    "        elif 'spa' in coords['name'].lower():\n",
    "            rain_prob = 0.4  # Belgian climate\n",
    "        \n",
    "        # Generate realistic hourly data\n",
    "        \n",
    "        hours = 24 * 4  # 4 days of data\n",
    "        time_index = [race_dt - timedelta(days = 2) + timedelta(hours = i) for i in range(hours)]\n",
    "        \n",
    "        demo_data = {\n",
    "            'hourly': {\n",
    "                'time': [t.isoformat() for t in time_index],\n",
    "                'temperature_2m': [max(base_temp + np.random.normal(0, 2), -5) for _ in range(hours)],\n",
    "                'precipitation': [np.random.exponential(0.5) if np.random.random() < rain_prob else 0 for _ in range(hours)],\n",
    "                'rain': [np.random.exponential(0.3) if np.random.random() < rain_prob else 0 for _ in range(hours)],\n",
    "                'wind_speed_10m': [max(np.random.weibull(1.5) * 5, 0) for _ in range(hours)],\n",
    "                'pressure_msl': [1013 + np.random.normal(0, 5) for _ in range(hours)],\n",
    "                'relative_humidity_2m': [max(min(np.random.normal(60, 15), 100), 20) for _ in range(hours)],\n",
    "                'cloud_cover': [min(np.random.beta(2, 2) * 100, 100) for _ in range(hours)]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(f'   🌤️ Generated realistic weather data for {coords['name']}')\n",
    "        return demo_data\n",
    "    \n",
    "    def process_weather_features(self, weather_data, race_date):\n",
    "        'PROCESS REAL WEATHER DATA INTO STRATEGY-RELEVANT FEATURES'\n",
    "        if not weather_data or 'hourly' not in weather_data:\n",
    "            print(f'   ⚠️ No weather data available, using realistic defaults')\n",
    "            return self.get_realistic_default_weather_features(race_date)\n",
    "        \n",
    "        hourly_data = weather_data['hourly']\n",
    "        df_weather = pd.DataFrame(hourly_data)\n",
    "        \n",
    "        df_weather['time'] = pd.to_datetime(df_weather['time'])\n",
    "        race_datetime = pd.to_datetime(race_date)\n",
    "        \n",
    "        race_day = race_datetime.date()\n",
    "        df_race_day = df_weather[df_weather['time'].dt.date == race_day]\n",
    "        \n",
    "        if df_race_day.empty:\n",
    "            print(f'   ⚠️ No race day weather data, using weekend averages')\n",
    "            return self.process_weekend_weather(df_weather, race_date)\n",
    "        \n",
    "        # Focus on race window (typically 14:00-16:00 local time)\n",
    "        \n",
    "        race_start = race_datetime.replace(hour = 14, minute = 0, second = 0)\n",
    "        race_end = race_start + timedelta(hours = 2)\n",
    "        \n",
    "        df_race_window = df_weather[\n",
    "            (df_weather['time'] >= race_start) & \n",
    "            (df_weather['time'] <= race_end)\n",
    "        ]\n",
    "        \n",
    "        if df_race_window.empty:\n",
    "            df_race_window = df_race_day\n",
    "            print(f'   ⚠️ No race window data, using full day data')\n",
    "        \n",
    "        weather_features = {}\n",
    "        \n",
    "        # Temperature analysis\n",
    "        \n",
    "        if 'temperature_2m' in df_race_window.columns:\n",
    "            temp_data = df_race_window['temperature_2m'].dropna()\n",
    "            if len(temp_data) > 0:\n",
    "                weather_features.update({\n",
    "                    'temperature_avg': float(temp_data.mean()),\n",
    "                    'temperature_max': float(temp_data.max()),\n",
    "                    'temperature_min': float(temp_data.min()),\n",
    "                    'temperature_range': float(temp_data.max() - temp_data.min()),\n",
    "                    'temperature_std': float(temp_data.std())\n",
    "                })\n",
    "        \n",
    "        # Precipitation analysis\n",
    "        \n",
    "        if 'precipitation' in df_race_window.columns:\n",
    "            precip_data = df_race_window['precipitation'].dropna()\n",
    "            if len(precip_data) > 0:\n",
    "                weather_features.update({\n",
    "                    'precipitation_total': float(precip_data.sum()),\n",
    "                    'precipitation_max': float(precip_data.max()),\n",
    "                    'rain_probability': float((precip_data > 0).mean()),\n",
    "                    'heavy_rain_probability': float((precip_data > 2.5).mean())\n",
    "                })\n",
    "        \n",
    "        # Wind analysis\n",
    "        \n",
    "        if 'wind_speed_10m' in df_race_window.columns:\n",
    "            wind_data = df_race_window['wind_speed_10m'].dropna()\n",
    "            if len(wind_data) > 0:\n",
    "                weather_features.update({\n",
    "                    'wind_speed_avg': float(wind_data.mean()),\n",
    "                    'wind_speed_max': float(wind_data.max())\n",
    "                })\n",
    "        \n",
    "        # Pressure analysis\n",
    "        \n",
    "        if 'pressure_msl' in df_race_window.columns:\n",
    "            pressure_data = df_race_window['pressure_msl'].dropna()\n",
    "            if len(pressure_data) > 0:\n",
    "                weather_features.update({\n",
    "                    'pressure_avg': float(pressure_data.mean()),\n",
    "                    'pressure_trend': float(self.calculate_pressure_trend(pressure_data))\n",
    "                })\n",
    "        \n",
    "        # Humidity analysis\n",
    "        \n",
    "        if 'relative_humidity_2m' in df_race_window.columns:\n",
    "            humidity_data = df_race_window['relative_humidity_2m'].dropna()\n",
    "            if len(humidity_data) > 0:\n",
    "                weather_features.update({\n",
    "                    'humidity_avg': float(humidity_data.mean()),\n",
    "                    'humidity_max': float(humidity_data.max())\n",
    "                })\n",
    "        \n",
    "        # Cloud cover analysis\n",
    "        \n",
    "        cloud_columns = ['cloud_cover', 'cloud_cover_low', 'cloud_cover_mid', 'cloud_cover_high']\n",
    "        for col in cloud_columns:\n",
    "            if col in df_race_window.columns:\n",
    "                cloud_data = df_race_window[col].dropna()\n",
    "                if len(cloud_data) > 0:\n",
    "                    weather_features[f'{col}_avg'] = float(cloud_data.mean())\n",
    "        \n",
    "        # Derived features\n",
    "        \n",
    "        weather_features['weather_condition'] = self.classify_weather_condition(df_race_window)\n",
    "        weather_features['estimated_track_temp'] = self.estimate_track_temperature(weather_features)\n",
    "        weather_features['tire_degradation_factor'] = self.calculate_tire_degradation_factor(weather_features)\n",
    "        \n",
    "        print(f'   ✅ Processed {len(weather_features)} real weather features')\n",
    "        return weather_features\n",
    "    \n",
    "    def calculate_pressure_trend(self, pressure_data):\n",
    "        'Calculate pressure trend for weather prediction'\n",
    "        if len(pressure_data) < 2:\n",
    "            return 0\n",
    "        \n",
    "        x = np.arange(len(pressure_data))\n",
    "        slope, _, _, _, _ = linregress(x, pressure_data)\n",
    "        return slope\n",
    "    \n",
    "    def classify_weather_condition(self, df_weather_window):\n",
    "        'Classify weather condition based on multiple factors'\n",
    "        if df_weather_window.empty:\n",
    "            return 'dry'\n",
    "        \n",
    "        condition = 'dry'\n",
    "        \n",
    "        # Check for rain\n",
    "        \n",
    "        if 'precipitation' in df_weather_window.columns:\n",
    "            max_precip = df_weather_window['precipitation'].max()\n",
    "            if max_precip > 5.0:\n",
    "                condition = 'heavy_rain'\n",
    "            elif max_precip > 0.5:\n",
    "                condition = 'light_rain'\n",
    "        \n",
    "        # Check for extreme temperatures\n",
    "        \n",
    "        if 'temperature_2m' in df_weather_window.columns:\n",
    "            avg_temp = df_weather_window['temperature_2m'].mean()\n",
    "            if avg_temp > 35:\n",
    "                condition = 'very_hot'\n",
    "            elif avg_temp < 10:\n",
    "                condition = 'very_cold'\n",
    "        \n",
    "        return condition\n",
    "    \n",
    "    def estimate_track_temperature(self, weather_features):\n",
    "        'Estimate track temperature based on weather conditions'\n",
    "        air_temp = weather_features.get('temperature_avg', 20)\n",
    "        cloud_cover = weather_features.get('cloud_cover_avg', 50)\n",
    "        \n",
    "        # Track is typically 10-20°C hotter than air temperature\n",
    "        \n",
    "        base_track_temp = air_temp + 15\n",
    "        \n",
    "        # Cloud cover reduces track temperature\n",
    "        \n",
    "        cloud_adjustment = (100 - cloud_cover) * 0.15\n",
    "        track_temp = base_track_temp + cloud_adjustment\n",
    "        \n",
    "        return max(air_temp + 5, min(track_temp, air_temp + 40))\n",
    "    \n",
    "    def calculate_tire_degradation_factor(self, weather_features):\n",
    "        'Calculate tire degradation factor based on weather conditions'\n",
    "        degradation = 1.0\n",
    "        \n",
    "        temp = weather_features.get('temperature_avg', 20)\n",
    "        if temp > 30:\n",
    "            degradation *= 1.3  # High temperatures increase degradation\n",
    "        elif temp < 15:\n",
    "            degradation *= 0.8  # Low temperatures reduce degradation\n",
    "        \n",
    "        track_temp = weather_features.get('estimated_track_temp', temp + 15)\n",
    "        if track_temp > 45:\n",
    "            degradation *= 1.5  # Very hot track significantly increases degradation\n",
    "        elif track_temp < 25:\n",
    "            degradation *= 0.7  # Cold track reduces degradation\n",
    "        \n",
    "        return degradation\n",
    "    \n",
    "    def process_weekend_weather(self, df_weather, race_date):\n",
    "        'Process weekend weather when race day data is unavailable'\n",
    "        weather_features = {}\n",
    "        \n",
    "        if 'temperature_2m' in df_weather.columns:\n",
    "            temp_data = df_weather['temperature_2m'].dropna()\n",
    "            if len(temp_data) > 0:\n",
    "                weather_features['temperature_avg'] = float(temp_data.mean())\n",
    "        \n",
    "        if 'precipitation' in df_weather.columns:\n",
    "            precip_data = df_weather['precipitation'].dropna()\n",
    "            if len(precip_data) > 0:\n",
    "                weather_features['rain_probability'] = float((precip_data > 0).mean())\n",
    "        \n",
    "        # Fill missing features with realistic defaults\n",
    "        \n",
    "        default_features = self.get_realistic_default_weather_features(race_date)\n",
    "        for key, value in default_features.items():\n",
    "            if key not in weather_features:\n",
    "                weather_features[key] = value\n",
    "        \n",
    "        return weather_features\n",
    "    \n",
    "    def get_realistic_default_weather_features(self, race_date):\n",
    "        'Get realistic default weather features based on season and location'\n",
    "        race_dt = pd.to_datetime(race_date)\n",
    "        month = race_dt.month\n",
    "        \n",
    "        # Seasonal defaults\n",
    "        \n",
    "        if month in [12, 1, 2]:  # Winter\n",
    "            base_temp = 8\n",
    "            rain_prob = 0.3\n",
    "        elif month in [3, 4, 5]:  # Spring\n",
    "            base_temp = 16\n",
    "            rain_prob = 0.25\n",
    "        elif month in [6, 7, 8]:  # Summer\n",
    "            base_temp = 24\n",
    "            rain_prob = 0.15\n",
    "        else:  # Autumn\n",
    "            base_temp = 15\n",
    "            rain_prob = 0.28\n",
    "        \n",
    "        return {\n",
    "            'temperature_avg': base_temp,\n",
    "            'temperature_max': base_temp + 5,\n",
    "            'temperature_min': base_temp - 5,\n",
    "            'temperature_range': 10.0,\n",
    "            'precipitation_total': rain_prob * 10,\n",
    "            'precipitation_max': rain_prob * 5,\n",
    "            'rain_probability': rain_prob,\n",
    "            'heavy_rain_probability': rain_prob * 0.3,\n",
    "            'wind_speed_avg': 3.0,\n",
    "            'wind_speed_max': 6.0,\n",
    "            'pressure_avg': 1013.0,\n",
    "            'pressure_trend': 0.0,\n",
    "            'humidity_avg': 65.0,\n",
    "            'humidity_max': 85.0,\n",
    "            'cloud_cover_avg': 50.0,\n",
    "            'weather_condition': 'dry' if rain_prob < 0.2 else 'light_rain',\n",
    "            'estimated_track_temp': base_temp + 15,\n",
    "            'tire_degradation_factor': 1.0\n",
    "        }\n",
    "    \n",
    "    def clear_cache(self):\n",
    "        'CLEAR WEATHER CACHE'\n",
    "        self.weather_cache = {}\n",
    "        if os.path.exists(self.cache_file):\n",
    "            os.remove(self.cache_file)\n",
    "        print('🧹 Weather cache cleared')\n",
    "\n",
    "def integrate_real_weather_data(df, circuits, use_caching = True):\n",
    "    'INTEGRATE REAL WEATHER DATA INTO THE MAIN DATASET WITH CACHING'\n",
    "    print(f'\\n🌤️ INTEGRATING REAL WEATHER DATA INTO DATASET...')\n",
    "    \n",
    "    if df.empty or circuits.empty:\n",
    "        print('   ⚠️ No data available for weather integration')\n",
    "        return df\n",
    "    \n",
    "    if 'circuit_id' not in df.columns or 'date' not in df.columns:\n",
    "        print('   ⚠️ Missing circuit_id or date columns for weather integration')\n",
    "        return df\n",
    "    \n",
    "    weather_integrator = RealWeatherDataIntegrator(circuits)\n",
    "    \n",
    "    if not use_caching:\n",
    "        weather_integrator.clear_cache()\n",
    "        print('   🚫 Caching disabled for weather data')\n",
    "    \n",
    "    unique_races = df[['race_id', 'circuit_id', 'date']].drop_duplicates()\n",
    "    weather_data_list = []\n",
    "    \n",
    "    print(f'   Processing {len(unique_races)} unique races for real weather data...')\n",
    "    \n",
    "    for idx, race in unique_races.iterrows():\n",
    "        race_id = race['race_id']\n",
    "        circuit_id = race['circuit_id']\n",
    "        race_date = race['date']\n",
    "        \n",
    "        # Skip if we already have weather for this race\n",
    "        \n",
    "        existing_weather = [w for w in weather_data_list if w['race_id'] == race_id]\n",
    "        if existing_weather:\n",
    "            continue\n",
    "        \n",
    "        # Fetch real weather data\n",
    "        \n",
    "        weather_data = weather_integrator.fetch_real_weather_data(circuit_id, race_date)\n",
    "        weather_features = weather_integrator.process_weather_features(weather_data, race_date)\n",
    "        weather_features['race_id'] = race_id\n",
    "        \n",
    "        weather_data_list.append(weather_features)\n",
    "        \n",
    "        # Respectful API delay\n",
    "        \n",
    "        time.sleep(weather_integrator.request_delay)\n",
    "        \n",
    "        if (idx + 1) % 5 == 0:\n",
    "            print(f'   Processed {idx + 1}/{len(unique_races)} races...')\n",
    "    \n",
    "    if weather_data_list:\n",
    "        weather_df = pd.DataFrame(weather_data_list)\n",
    "        df_with_weather = df.merge(weather_df, on = 'race_id', how = 'left')\n",
    "        \n",
    "        print(f'   ✅ Real weather data integrated for {len(weather_data_list)} races')\n",
    "        print(f'   📊 Added {len(weather_df.columns) - 1} weather features')\n",
    "        \n",
    "        return df_with_weather\n",
    "    else:\n",
    "        print('   ⚠️ No weather data could be fetched, using realistic defaults')\n",
    "        \n",
    "        # Add realistic default weather features based on race dates\n",
    "        \n",
    "        default_weather = weather_integrator.get_realistic_default_weather_features(df['date'].iloc[0])\n",
    "        for key, value in default_weather.items():\n",
    "            df[key] = value\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa02797a-9786-4d05-b726-98fe9bf88390",
   "metadata": {},
   "source": [
    "#  9: Data Processing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b95a980-e54e-4131-bbd3-79d92d16bc4b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class AdvancedDataCleaner:\n",
    "    'Advanced data cleaning for F1 datasets'\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cleaning_report = {}\n",
    "    \n",
    "    def comprehensive_clean(self, df, dataset_name):\n",
    "        'Comprehensive cleaning for different dataset types'\n",
    "        if df.empty:\n",
    "            return df\n",
    "            \n",
    "        original_shape = df.shape\n",
    "        df_clean = df.copy()\n",
    "        \n",
    "        # Dataset-specific cleaning\n",
    "        \n",
    "        if dataset_name == 'drivers':\n",
    "            df_clean = self.clean_driver_data(df_clean)\n",
    "        elif dataset_name == 'constructors':\n",
    "            df_clean = self.clean_constructor_data(df_clean)\n",
    "        elif dataset_name == 'circuits':\n",
    "            df_clean = self.clean_circuit_data(df_clean)\n",
    "        elif dataset_name == 'races':\n",
    "            df_clean = self.clean_race_data(df_clean)\n",
    "        elif dataset_name == 'results':\n",
    "            df_clean = self.clean_results_data(df_clean)\n",
    "        \n",
    "        # General cleaning for all datasets\n",
    "        \n",
    "        df_clean = self.clean_general_data(df_clean)\n",
    "        \n",
    "        \n",
    "        # Store cleaning report\n",
    "        \n",
    "        self.cleaning_report[dataset_name] = {\n",
    "            'original_rows': original_shape[0],\n",
    "            'cleaned_rows': df_clean.shape[0],\n",
    "            'original_cols': original_shape[1],\n",
    "            'cleaned_cols': df_clean.shape[1],\n",
    "            'rows_removed': original_shape[0] - df_clean.shape[0],\n",
    "            'cols_removed': original_shape[1] - df_clean.shape[1]\n",
    "        }\n",
    "        \n",
    "        return df_clean\n",
    "    \n",
    "    def clean_driver_data(self, df):\n",
    "        'Clean driver-specific data'\n",
    "        \n",
    "        # Remove drivers with no race entries\n",
    "        \n",
    "        if 'total_race_entries' in df.columns:\n",
    "            df = df[df['total_race_entries'] > 0]\n",
    "        return df\n",
    "    \n",
    "    def clean_constructor_data(self, df):\n",
    "        'Clean constructor-specific data'\n",
    "        \n",
    "        # Remove constructors with no race entries\n",
    "        \n",
    "        if 'total_race_entries' in df.columns:\n",
    "            df = df[df['total_race_entries'] > 0]\n",
    "        return df\n",
    "    \n",
    "    def clean_circuit_data(self, df):\n",
    "        'Clean circuit-specific data'\n",
    "        # Remove circuits with no races held\n",
    "        \n",
    "        if 'total_races_held' in df.columns:\n",
    "            df = df[df['total_races_held'] > 0]\n",
    "        return df\n",
    "    \n",
    "    def clean_race_data(self, df):\n",
    "        'Clean race-specific data'\n",
    "        \n",
    "        # Remove races without dates\n",
    "        \n",
    "        if 'date' in df.columns:\n",
    "            df = df[df['date'].notna()]\n",
    "        return df\n",
    "    \n",
    "    def clean_results_data(self, df):\n",
    "        'Clean results-specific data'\n",
    "        \n",
    "        # Remove results without position data\n",
    "        \n",
    "        if 'position_number' in df.columns:\n",
    "            df = df[df['position_number'].notna()]\n",
    "        return df\n",
    "    \n",
    "    def clean_general_data(self, df):\n",
    "        'General data cleaning for all datasets'\n",
    "        \n",
    "        # Remove completely empty columns\n",
    "        \n",
    "        df = df.dropna(axis = 1, how = 'all')\n",
    "        \n",
    "        # Remove duplicate rows\n",
    "        \n",
    "        df = df.drop_duplicates()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def print_cleaning_report(self):\n",
    "        'Print comprehensive cleaning report'\n",
    "        print('\\n🧹 DATA CLEANING REPORT:')\n",
    "        print('=' * 50)\n",
    "        for dataset, report in self.cleaning_report.items():\n",
    "            print(f'📊 {dataset.upper():<15} | Rows: {report['original_rows']:>4} → {report['cleaned_rows']:<4} | '\n",
    "                  f'Cols: {report['original_cols']:>2} → {report['cleaned_cols']:<2} | '\n",
    "                  f'Removed: {report['rows_removed']:>2} rows, {report['cols_removed']:>1} cols')\n",
    "\n",
    "def build_enhanced_merged_dataset(results, races, circuits, drivers, constructors, qualifying, pit_stops, race_results):\n",
    "    'BUILD ENHANCED MERGED DATASET WITH CORRECTED COLUMN NAMES'\n",
    "    print(f'\\n🔄 BUILDING ENHANCED MERGED DATASET FROM MYSQL...')\n",
    "    \n",
    "    # Use race_results as base if available, otherwise use results\n",
    "    \n",
    "    if not race_results.empty:\n",
    "        df_merged = race_results.copy()\n",
    "        print(f'   Base race_results: {len(df_merged)} records')\n",
    "    elif not results.empty:\n",
    "        df_merged = results.copy()\n",
    "        print(f'   Base results: {len(df_merged)} records')\n",
    "    else:\n",
    "        print('❌ No results or race_results data available - cannot build dataset')\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Merge with races using MySQL column names\n",
    "    \n",
    "    if not races.empty and 'race_id' in df_merged.columns and 'id' in races.columns:\n",
    "        df_merged = df_merged.merge(\n",
    "            races, \n",
    "            left_on = 'race_id', \n",
    "            right_on = 'id',\n",
    "            how = 'left',\n",
    "            suffixes = ('', '_race')\n",
    "        )\n",
    "        print(f'   ✅ Merged races: {len(df_merged)} records')\n",
    "    \n",
    "    # Merge with circuits\n",
    "    \n",
    "    if not circuits.empty and 'circuit_id' in df_merged.columns and 'id' in circuits.columns:\n",
    "        df_merged = df_merged.merge(\n",
    "            circuits,\n",
    "            left_on = 'circuit_id',\n",
    "            right_on = 'id',\n",
    "            how = 'left',\n",
    "            suffixes = ('', '_circuit')\n",
    "        )\n",
    "        print(f'   ✅ Merged circuits: {len(df_merged)} records')\n",
    "    \n",
    "    # Merge with drivers\n",
    "    \n",
    "    if not drivers.empty and 'driver_id' in df_merged.columns and 'id' in drivers.columns:\n",
    "        df_merged = df_merged.merge(\n",
    "            drivers,\n",
    "            left_on = 'driver_id',\n",
    "            right_on = 'id',\n",
    "            how = 'left',\n",
    "            suffixes = ('', '_driver')\n",
    "        )\n",
    "        print(f'   ✅ Merged drivers: {len(df_merged)} records')\n",
    "    \n",
    "    # Merge with constructors\n",
    "    \n",
    "    if not constructors.empty and 'constructor_id' in df_merged.columns and 'id' in constructors.columns:\n",
    "        df_merged = df_merged.merge(\n",
    "            constructors,\n",
    "            left_on = 'constructor_id',\n",
    "            right_on = 'id',\n",
    "            how = 'left',\n",
    "            suffixes = ('', '_constructor')\n",
    "        )\n",
    "        print(f'   ✅ Merged constructors: {len(df_merged)} records')\n",
    "    \n",
    "    # Add qualifying data\n",
    "    \n",
    "    if not qualifying.empty and 'race_id' in df_merged.columns and 'driver_id' in df_merged.columns:\n",
    "        try:\n",
    "            \n",
    "            # Use position_number from qualifying as qualifying position\n",
    "            \n",
    "            qualifying_positions = qualifying[['race_id', 'driver_id', 'position_number']].copy()\n",
    "            qualifying_positions = qualifying_positions.rename(columns = {'position_number': 'qualifying_position'})\n",
    "            \n",
    "            df_merged = df_merged.merge(\n",
    "                qualifying_positions, \n",
    "                on = ['race_id', 'driver_id'], \n",
    "                how = 'left'\n",
    "            )\n",
    "            print(f'   ✅ Added qualifying data: {len(df_merged)} records')\n",
    "        except Exception as e:\n",
    "            print(f'   ⚠️  Error merging qualifying data: {e}')\n",
    "    \n",
    "    # Add pit stop data\n",
    "    \n",
    "    if not pit_stops.empty and 'race_id' in df_merged.columns and 'driver_id' in df_merged.columns:\n",
    "        try:\n",
    "            pit_stops_agg = pit_stops.groupby(['race_id', 'driver_id']).agg(\n",
    "                total_pit_stops = ('stop', 'count')\n",
    "            ).reset_index()\n",
    "            \n",
    "            df_merged = df_merged.merge(\n",
    "                pit_stops_agg, \n",
    "                on = ['race_id', 'driver_id'], \n",
    "                how = 'left'\n",
    "            )\n",
    "            print(f'   ✅ Added pit stop data: {len(df_merged)} records')\n",
    "        except Exception as e:\n",
    "            print(f'   ⚠️  Error merging pit stop data: {e}')\n",
    "    \n",
    "    # Clean up any duplicate columns\n",
    "    \n",
    "    df_merged = df_merged.loc[:, ~df_merged.columns.duplicated()]\n",
    "    \n",
    "    print(f''🎯 ENHANCED MERGED DATASET: {len(df_merged)} records with {len(df_merged.columns)} columns')\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f4bb14-2a76-4ad8-b8f4-8c3040653e8e",
   "metadata": {},
   "source": [
    "# 10: Enhanced Feature Engineering with Real Weather and Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5973677-cd32-4469-bdb5-03232f4859aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_enhanced_strategy_features_with_weather(df, drivers, constructors, circuits, \n",
    "                                                  cache_file = 'features_cache.pkl', \n",
    "                                                  use_caching = True):\n",
    "    'CREATE ENHANCED STRATEGY FEATURES WITH REAL WEATHER DATA AND CACHING'\n",
    "    \n",
    "    # Try to load from cache first\n",
    "   \n",
    "    if use_caching:\n",
    "        cache_key = f'features_{len(df)}_{df['race_id'].nunique() if 'race_id' in df.columns else 'unknown'}_{hash(str(sorted(df.columns)))}'\n",
    "        \n",
    "        try:\n",
    "            if os.path.exists(cache_file):\n",
    "                with open(cache_file, 'rb') as f:\n",
    "                    cache_data = pickle.load(f)\n",
    "                    if cache_key in cache_data:\n",
    "                        print(f'💾 Using cached features: {cache_key}')\n",
    "                        return cache_data[cache_key].copy()\n",
    "        except Exception as e:\n",
    "            print(f'⚠️ Could not load feature cache: {e}')\n",
    "    \n",
    "    print('\\n🔄 CREATING ENHANCED STRATEGY FEATURES WITH REAL WEATHER...')\n",
    "    \n",
    "    if df.empty:\n",
    "        print('❌ No data available for feature engineering')\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    strategy_features = []\n",
    "    processed_count = 0\n",
    "    \n",
    "    for idx, race in df.iterrows():\n",
    "        try:\n",
    "            race_id = race.get('race_id') or f'race_{idx}'\n",
    "            driver_id = race.get('driver_id') or f'driver_{idx}'\n",
    "            constructor_id = race.get('constructor_id') or f'constructor_{idx}'\n",
    "            circuit_id = race.get('circuit_id') or f'circuit_{idx}'\n",
    "            \n",
    "            feature_set = {\n",
    "                'race_id': race_id,\n",
    "                'driver_id': driver_id,\n",
    "                'constructor_id': constructor_id,\n",
    "                'circuit_id': circuit_id\n",
    "            }\n",
    "            \n",
    "            # Extract race performance data\n",
    "            \n",
    "            position = race.get('position_number') or 20\n",
    "            points = race.get('race_points') or race.get('points') or 0\n",
    "            grid = race.get('qualifying_position') or race.get('race_grid_position_number') or race.get('grid_position_number') or 20\n",
    "            \n",
    "            feature_set.update({\n",
    "                'final_position': position,\n",
    "                'points_scored': points,\n",
    "                'qualifying_position': grid,\n",
    "                'finished': 1 if position and position > 0 else 0,\n",
    "                'position_gain': max(0, (grid or 20) - position) if grid and position else 0\n",
    "            })\n",
    "            \n",
    "            # Extract driver statistics\n",
    "            \n",
    "            driver_data = extract_enhanced_driver_stats(drivers, driver_id)\n",
    "            feature_set.update(driver_data)\n",
    "            \n",
    "            # Extract constructor statistics\n",
    "            \n",
    "            constructor_data = extract_enhanced_constructor_stats(constructors, constructor_id)\n",
    "            feature_set.update(constructor_data)\n",
    "            \n",
    "            # Extract circuit characteristics\n",
    "            \n",
    "            circuit_data = extract_enhanced_circuit_stats(circuits, circuit_id)\n",
    "            feature_set.update(circuit_data)\n",
    "            \n",
    "            # Calculate qualifying performance\n",
    "            \n",
    "            qualifying_gap = max(0, (grid - 1) * 0.15)\n",
    "            feature_set['qualifying_gap_to_pole'] = qualifying_gap\n",
    "            \n",
    "            # Extract pit stop data\n",
    "            \n",
    "            pit_stops = race.get('total_pit_stops') or race.get('race_pit_stops') or 1\n",
    "            feature_set['total_pit_stops'] = pit_stops\n",
    "            \n",
    "            # Extract weather features\n",
    "            \n",
    "            weather_features = extract_enhanced_weather_features(race)\n",
    "            feature_set.update(weather_features)\n",
    "            \n",
    "            # Create weather-driver interaction features\n",
    "            \n",
    "            interaction_features = create_weather_interaction_features(feature_set, driver_data, constructor_data)\n",
    "            feature_set.update(interaction_features)\n",
    "            \n",
    "            strategy_features.append(feature_set)\n",
    "            processed_count += 1\n",
    "            \n",
    "            if processed_count % 100 == 0:\n",
    "                print(f'   Processed {processed_count} records...')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f'⚠️ Error processing record {idx}: {e}')\n",
    "            continue\n",
    "    \n",
    "    result_df = pd.DataFrame(strategy_features)\n",
    "    result_df = fill_missing_features_with_enhanced_defaults(result_df)\n",
    "    \n",
    "    # Cache the results if caching is enabled\n",
    "    \n",
    "    if use_caching:\n",
    "        try:\n",
    "            if os.path.exists(cache_file):\n",
    "                with open(cache_file, 'rb') as f:\n",
    "                    cache_data = pickle.load(f)\n",
    "            else:\n",
    "                cache_data = {}\n",
    "            \n",
    "            cache_data[cache_key] = result_df.copy()\n",
    "            \n",
    "            with open(cache_file, 'wb') as f:\n",
    "                pickle.dump(cache_data, f)\n",
    "            \n",
    "            print(f'💾 Features cached: {cache_key}')\n",
    "        except Exception as e:\n",
    "            print(f'⚠️ Could not cache features: {e}')\n",
    "    \n",
    "    print(f'✅ ENHANCED FEATURE ENGINEERING COMPLETE: {len(result_df)} records')\n",
    "    print(f'📊 Total features created: {len(result_df.columns)}')\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def extract_enhanced_driver_stats(drivers, driver_id):\n",
    "    'EXTRACT ENHANCED DRIVER STATISTICS FROM MYSQL DATA'\n",
    "    stats = {}\n",
    "    \n",
    "    if drivers.empty:\n",
    "        return get_default_driver_stats()\n",
    "    \n",
    "    driver_match = drivers[drivers['id'] == driver_id]\n",
    "    if driver_match.empty:\n",
    "        return get_default_driver_stats()\n",
    "    \n",
    "    driver = driver_match.iloc[0]\n",
    "    \n",
    "    # Extract driver statistics\n",
    "    \n",
    "    driver_races = driver.get('total_race_entries', 1)\n",
    "    driver_wins = driver.get('total_race_wins', 0)\n",
    "    driver_podiums = driver.get('total_podiums', 0)\n",
    "    driver_points = driver.get('total_points', 0)\n",
    "    \n",
    "    # Calculate driver age\n",
    "    \n",
    "    driver_age = 28\n",
    "    if 'date_of_birth' in driver and pd.notna(driver['date_of_birth']):\n",
    "        try:\n",
    "            birth_date = pd.to_datetime(driver['date_of_birth'])\n",
    "            today = pd.to_datetime('today')\n",
    "            driver_age = today.year - birth_date.year\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    stats.update({\n",
    "        'driver_experience': driver_races,\n",
    "        'driver_win_rate': driver_wins / max(driver_races, 1),\n",
    "        'driver_podium_rate': driver_podiums / max(driver_races, 1),\n",
    "        'driver_points_per_race': driver_points / max(driver_races, 1),\n",
    "        'driver_age': driver_age,\n",
    "        'driver_fastest_laps': driver.get('total_fastest_laps', 0),\n",
    "        'driver_pole_positions': driver.get('total_pole_positions', 0)\n",
    "    })\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def extract_enhanced_constructor_stats(constructors, constructor_id):\n",
    "    'EXTRACT ENHANCED CONSTRUCTOR STATISTICS FROM MYSQL DATA'\n",
    "    stats = {}\n",
    "    \n",
    "    if constructors.empty:\n",
    "        return get_default_constructor_stats()\n",
    "    \n",
    "    constructor_match = constructors[constructors['id'] == constructor_id]\n",
    "    if constructor_match.empty:\n",
    "        return get_default_constructor_stats()\n",
    "    \n",
    "    constructor = constructor_match.iloc[0]\n",
    "    \n",
    "    const_races = constructor.get('total_race_entries', 1)\n",
    "    const_wins = constructor.get('total_race_wins', 0)\n",
    "    const_podiums = constructor.get('total_podiums', 0)\n",
    "    \n",
    "    # Calculate reliability from race starts vs entries\n",
    "    \n",
    "    reliability = 0.85\n",
    "    if 'total_race_starts' in constructor and 'total_race_entries' in constructor:\n",
    "        if constructor['total_race_entries'] > 0:\n",
    "            reliability = constructor['total_race_starts'] / constructor['total_race_entries']\n",
    "    \n",
    "    stats.update({\n",
    "        'constructor_experience': const_races,\n",
    "        'constructor_win_rate': const_wins / max(const_races, 1),\n",
    "        'constructor_podium_rate': const_podiums / max(const_races, 1),\n",
    "        'constructor_reliability': reliability,\n",
    "        'constructor_points_per_race': constructor.get('total_points', 0) / max(const_races, 1),\n",
    "        'constructor_fastest_laps': constructor.get('total_fastest_laps', 0)\n",
    "    })\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def extract_enhanced_circuit_stats(circuits, circuit_id):\n",
    "    'EXTRACT ENHANCED CIRCUIT CHARACTERISTICS FROM MYSQL DATA'\n",
    "    stats = {}\n",
    "    \n",
    "    if circuits.empty:\n",
    "        return get_default_circuit_stats()\n",
    "    \n",
    "    circuit_match = circuits[circuits['id'] == circuit_id]\n",
    "    if circuit_match.empty:\n",
    "        return get_default_circuit_stats()\n",
    "    \n",
    "    circuit = circuit_match.iloc[0]\n",
    "    \n",
    "    stats.update({\n",
    "        'circuit_length': circuit.get('length', 5.0),\n",
    "        'circuit_corners': circuit.get('turns', 12),\n",
    "        'circuit_altitude': circuit.get('altitude', 100) if 'altitude' in circuit else 100,\n",
    "        'circuit_races_held': circuit.get('total_races_held', 1),\n",
    "        'circuit_type': circuit.get('type', 'permanent'),\n",
    "        'circuit_direction': circuit.get('direction', 'clockwise')\n",
    "    })\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def extract_enhanced_weather_features(race):\n",
    "    'EXTRACT ENHANCED WEATHER FEATURES FROM RACE DATA'\n",
    "    weather_features = {}\n",
    "    \n",
    "    weather_metrics = [\n",
    "        'temperature_avg', 'temperature_max', 'temperature_min', 'temperature_range',\n",
    "        'precipitation_total', 'rain_probability', 'heavy_rain_probability',\n",
    "        'wind_speed_avg', 'wind_speed_max', 'pressure_avg', 'humidity_avg',\n",
    "        'estimated_track_temp', 'tire_degradation_factor', 'weather_condition'\n",
    "    ]\n",
    "    \n",
    "    for metric in weather_metrics:\n",
    "        if metric in race:\n",
    "            weather_features[metric] = race[metric]\n",
    "    \n",
    "    return weather_features\n",
    "\n",
    "def create_weather_interaction_features(feature_set, driver_data, constructor_data):\n",
    "    'CREATE WEATHER INTERACTION FEATURES FOR ENHANCED STRATEGY'\n",
    "    interaction_features = {}\n",
    "    \n",
    "    driver_experience = driver_data.get('driver_experience', 50)\n",
    "    rain_probability = feature_set.get('rain_probability', 0)\n",
    "    interaction_features['driver_wet_experience'] = driver_experience * rain_probability\n",
    "    \n",
    "    constructor_reliability = constructor_data.get('constructor_reliability', 0.85)\n",
    "    temperature = feature_set.get('temperature_avg', 20)\n",
    "    temp_extremeness = abs(temperature - 20) / 20\n",
    "    interaction_features['team_extreme_temp_performance'] = constructor_reliability * (1 - temp_extremeness)\n",
    "    \n",
    "    circuit_corners = feature_set.get('circuit_corners', 12)\n",
    "    wind_speed = feature_set.get('wind_speed_avg', 3)\n",
    "    interaction_features['wind_circuit_impact'] = circuit_corners * wind_speed / 100\n",
    "    \n",
    "    # New interaction features\n",
    "    \n",
    "    track_temp = feature_set.get('estimated_track_temp', 35)\n",
    "    driver_win_rate = driver_data.get('driver_win_rate', 0.05)\n",
    "    interaction_features['hot_track_winning_chance'] = driver_win_rate * (track_temp / 30)\n",
    "    \n",
    "    return interaction_features\n",
    "\n",
    "def get_default_driver_stats():\n",
    "    'GET DEFAULT DRIVER STATISTICS'\n",
    "    return {\n",
    "        'driver_experience': 50,\n",
    "        'driver_win_rate': 0.05,\n",
    "        'driver_podium_rate': 0.15,\n",
    "        'driver_points_per_race': 5.0,\n",
    "        'driver_age': 28,\n",
    "        'driver_fastest_laps': 2,\n",
    "        'driver_pole_positions': 1\n",
    "    }\n",
    "\n",
    "def get_default_constructor_stats():\n",
    "    'GET DEFAULT CONSTRUCTOR STATISTICS'\n",
    "    return {\n",
    "        'constructor_experience': 300,\n",
    "        'constructor_win_rate': 0.08,\n",
    "        'constructor_podium_rate': 0.25,\n",
    "        'constructor_reliability': 0.85,\n",
    "        'constructor_points_per_race': 8.0,\n",
    "        'constructor_fastest_laps': 15\n",
    "    }\n",
    "\n",
    "def get_default_circuit_stats():\n",
    "    'GET DEFAULT CIRCUIT STATISTICS'\n",
    "    return {\n",
    "        'circuit_length': 5.0,\n",
    "        'circuit_corners': 12,\n",
    "        'circuit_altitude': 100,\n",
    "        'circuit_races_held': 10,\n",
    "        'circuit_type': 'permanent',\n",
    "        'circuit_direction': 'clockwise'\n",
    "    }\n",
    "\n",
    "def fill_missing_features_with_enhanced_defaults(df):\n",
    "    'FILL MISSING FEATURES WITH ENHANCED DEFAULTS'\n",
    "    feature_defaults = {\n",
    "        'driver_experience': 50,\n",
    "        'driver_win_rate': 0.05,\n",
    "        'driver_podium_rate': 0.15,\n",
    "        'driver_points_per_race': 5.0,\n",
    "        'driver_age': 28,\n",
    "        'driver_fastest_laps': 2,\n",
    "        'driver_pole_positions': 1,\n",
    "        'constructor_experience': 300,\n",
    "        'constructor_win_rate': 0.08,\n",
    "        'constructor_podium_rate': 0.25,\n",
    "        'constructor_reliability': 0.85,\n",
    "        'constructor_points_per_race': 8.0,\n",
    "        'constructor_fastest_laps': 15,\n",
    "        'circuit_length': 5.0,\n",
    "        'circuit_corners': 12,\n",
    "        'circuit_altitude': 100,\n",
    "        'circuit_races_held': 10,\n",
    "        'qualifying_position': 20,\n",
    "        'qualifying_gap_to_pole': 2.0,\n",
    "        'total_pit_stops': 1,\n",
    "        'final_position': 20,\n",
    "        'points_scored': 0,\n",
    "        'finished': 1,\n",
    "        'position_gain': 0,\n",
    "        'temperature_avg': 20.0,\n",
    "        'temperature_max': 25.0,\n",
    "        'temperature_min': 15.0,\n",
    "        'temperature_range': 10.0,\n",
    "        'precipitation_total': 0.0,\n",
    "        'rain_probability': 0.0,\n",
    "        'heavy_rain_probability': 0.0,\n",
    "        'wind_speed_avg': 3.0,\n",
    "        'wind_speed_max': 6.0,\n",
    "        'pressure_avg': 1013.0,\n",
    "        'humidity_avg': 60.0,\n",
    "        'estimated_track_temp': 35.0,\n",
    "        'tire_degradation_factor': 1.0,\n",
    "        'weather_condition': 'dry',\n",
    "        'driver_wet_experience': 0.0,\n",
    "        'team_extreme_temp_performance': 0.85,\n",
    "        'wind_circuit_impact': 0.36,\n",
    "        'hot_track_winning_chance': 0.05\n",
    "    }\n",
    "    \n",
    "    for feature, default in feature_defaults.items():\n",
    "        if feature in df.columns and df[feature].isnull().any():\n",
    "            df[feature] = df[feature].fillna(default)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clear_feature_cache(cache_file = 'features_cache.pkl'):\n",
    "    'CLEAR FEATURE ENGINEERING CACHE'\n",
    "    try:\n",
    "        if os.path.exists(cache_file):\n",
    "            os.remove(cache_file)\n",
    "            print(f'🧹 Feature cache cleared: {cache_file}')\n",
    "        else:\n",
    "            print(f'ℹ️ No feature cache found: {cache_file}')\n",
    "    except Exception as e:\n",
    "        print(f'⚠️ Error clearing feature cache: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa1843e-ca87-44ac-ba72-bae0fdfed6e9",
   "metadata": {},
   "source": [
    "# 11: Strategy Optimization Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1b8c98a-5fd8-4469-b049-e8b5523b7d42",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def optimize_complete_race_strategy(predictor, driver_profile, constructor_profile, circuit_profile, qualifying_pos, weather_conditions):\n",
    "    'OPTIMIZE COMPLETE RACE STRATEGY WITH REAL WEATHER INTEGRATION'\n",
    "    input_features = {\n",
    "        'driver_experience': driver_profile.get('experience', 50),\n",
    "        'driver_win_rate': driver_profile.get('win_rate', 0.05),\n",
    "        'driver_podium_rate': driver_profile.get('podium_rate', 0.15),\n",
    "        'driver_points_per_race': driver_profile.get('points_per_race', 5.0),\n",
    "        'driver_age': driver_profile.get('age', 28),\n",
    "        'constructor_experience': constructor_profile.get('experience', 300),\n",
    "        'constructor_win_rate': constructor_profile.get('win_rate', 0.08),\n",
    "        'constructor_reliability': constructor_profile.get('reliability', 0.85),\n",
    "        'circuit_length': circuit_profile.get('length', 5.0),\n",
    "        'circuit_corners': circuit_profile.get('corners', 12),\n",
    "        'circuit_altitude': circuit_profile.get('altitude', 100),\n",
    "        'qualifying_position': qualifying_pos,\n",
    "        'qualifying_gap_to_pole': max(0, (qualifying_pos - 1) * 0.1)\n",
    "    }\n",
    "    \n",
    "    # Add all weather features\n",
    "    \n",
    "    input_features.update(weather_conditions)\n",
    "    \n",
    "    # Create interaction features\n",
    "    \n",
    "    input_features['driver_wet_experience'] = input_features['driver_experience'] * input_features.get('rain_probability', 0)\n",
    "    input_features['team_extreme_temp_performance'] = input_features['constructor_reliability'] * (1 - (abs(input_features.get('temperature_avg', 20) - 20) / 20))\n",
    "    \n",
    "    input_df = pd.DataFrame([input_features])\n",
    "    \n",
    "    # Use only available features that the model was trained on\n",
    "    \n",
    "    available_features = {k: v for k, v in input_features.items() if k in predictor.feature_columns}\n",
    "    input_df_available = pd.DataFrame([available_features])\n",
    "    \n",
    "    predicted_position = predictor.predict_enhanced_position(input_df_available)[0]\n",
    "    \n",
    "    # Generate comprehensive strategy recommendation\n",
    "    \n",
    "    recommendation = generate_comprehensive_strategy_recommendation(\n",
    "        predicted_position, qualifying_pos, weather_conditions, \n",
    "        driver_profile, constructor_profile, circuit_profile\n",
    "    )\n",
    "    \n",
    "    return recommendation\n",
    "\n",
    "def generate_comprehensive_strategy_recommendation(predicted_position, qualifying_pos, weather_conditions, driver_profile, constructor_profile, circuit_profile):\n",
    "    'GENERATE COMPREHENSIVE STRATEGY RECOMMENDATION'\n",
    "    \n",
    "    position_gain = max(0, qualifying_pos - predicted_position)\n",
    "    \n",
    "    # Calculate confidence based on multiple factors\n",
    "    \n",
    "    confidence_factors = []\n",
    "    \n",
    "    # Position consistency\n",
    "    \n",
    "    position_diff = abs(predicted_position - qualifying_pos)\n",
    "    if position_diff <= 2:\n",
    "        confidence_factors.append(1.0)\n",
    "    elif position_diff <= 5:\n",
    "        confidence_factors.append(0.7)\n",
    "    else:\n",
    "        confidence_factors.append(0.4)\n",
    "    \n",
    "    # Weather stability\n",
    "    \n",
    "    rain_prob = weather_conditions.get('rain_probability', 0)\n",
    "    if rain_prob < 0.1:\n",
    "        confidence_factors.append(1.0)\n",
    "    elif rain_prob < 0.3:\n",
    "        confidence_factors.append(0.8)\n",
    "    else:\n",
    "        confidence_factors.append(0.5)\n",
    "    \n",
    "    # Driver experience\n",
    "    \n",
    "    driver_exp = driver_profile.get('experience', 50)\n",
    "    if driver_exp > 100:\n",
    "        confidence_factors.append(1.0)\n",
    "    elif driver_exp > 50:\n",
    "        confidence_factors.append(0.8)\n",
    "    else:\n",
    "        confidence_factors.append(0.6)\n",
    "    \n",
    "    confidence_score = np.mean(confidence_factors)\n",
    "    if confidence_score > 0.8:\n",
    "        confidence = 'High'\n",
    "    elif confidence_score > 0.6:\n",
    "        confidence = 'Medium'\n",
    "    else:\n",
    "        confidence = 'Low'\n",
    "    \n",
    "    # Risk assessment\n",
    "    \n",
    "    risk_factors = []\n",
    "    if position_gain > 5:\n",
    "        risk_factors.append('Aggressive position gain predicted')\n",
    "    if rain_prob > 0.5:\n",
    "        risk_factors.append('High probability of rain')\n",
    "    if weather_conditions.get('temperature_avg', 20) > 35:\n",
    "        risk_factors.append('Extreme temperatures expected')\n",
    "    \n",
    "    risk_level = 'High' if len(risk_factors) > 1 else 'Medium' if len(risk_factors) == 1 else 'Low'\n",
    "    \n",
    "    # Pit stop strategy\n",
    "    \n",
    "    pit_stop_strategy = calculate_pit_stop_strategy(weather_conditions, circuit_profile)\n",
    "    \n",
    "    # Tire strategy\n",
    "    \n",
    "    tire_strategy = calculate_tire_strategy(weather_conditions, circuit_profile)\n",
    "    \n",
    "    # Overtaking opportunities\n",
    "    \n",
    "    overtaking_advice = calculate_overtaking_opportunities(circuit_profile, predicted_position, qualifying_pos)\n",
    "    \n",
    "    recommendation = {\n",
    "        'predicted_finish': round(predicted_position),\n",
    "        'qualifying_gain': position_gain,\n",
    "        'confidence': confidence,\n",
    "        'confidence_score': round(confidence_score, 2),\n",
    "        'risk_level': risk_level,\n",
    "        'risk_factors': risk_factors,\n",
    "        'recommended_pit_stops': pit_stop_strategy['stops'],\n",
    "        'pit_stop_laps': pit_stop_strategy['laps'],\n",
    "        'tire_strategy': tire_strategy,\n",
    "        'overtaking_opportunities': overtaking_advice,\n",
    "        'weather_impact': calculate_weather_impact_analysis(weather_conditions),\n",
    "        'key_considerations': generate_key_considerations(weather_conditions, circuit_profile, driver_profile)\n",
    "    }\n",
    "    \n",
    "    return recommendation\n",
    "\n",
    "def calculate_pit_stop_strategy(weather_conditions, circuit_profile):\n",
    "    'CALCULATE OPTIMAL PIT STOP STRATEGY'\n",
    "    base_stops = 1\n",
    "    circuit_corners = circuit_profile.get('corners', 12)\n",
    "    circuit_length = circuit_profile.get('length', 5.0)\n",
    "    \n",
    "    # Adjust for circuit characteristics\n",
    "    \n",
    "    if circuit_corners > 15:                                    # High downforce circuits\n",
    "        base_stops += 0.5\n",
    "    if circuit_length > 6:                                      # Long circuits\n",
    "        base_stops += 0.5\n",
    "    \n",
    "    # Weather adjustments\n",
    "    \n",
    "    rain_prob = weather_conditions.get('rain_probability', 0)\n",
    "    if rain_prob > 0.7:\n",
    "        base_stops += 1                                           # Extra stop for potential rain tires\n",
    "    elif rain_prob > 0.3:\n",
    "        base_stops += 0.5                                        # Possible extra stop\n",
    "    \n",
    "    # Temperature adjustments\n",
    "    \n",
    "    track_temp = weather_conditions.get('estimated_track_temp', 35)\n",
    "    if track_temp > 45:\n",
    "        base_stops += 0.5                                         # Higher degradation\n",
    "    elif track_temp < 25:\n",
    "        base_stops -= 0.5                                          # Lower degradation\n",
    "    \n",
    "    # Determine final strategy\n",
    "    \n",
    "    if base_stops >= 2.5:\n",
    "        stops = 'Three-stop'\n",
    "        laps = [15, 30, 45] if circuit_corners > 15 else [20, 40, 55]\n",
    "    elif base_stops >= 1.5:\n",
    "        stops = 'Two-stop'\n",
    "        laps = [20, 40] if circuit_corners > 15 else [25, 50]\n",
    "    else:\n",
    "        stops = 'One-stop'\n",
    "        laps = [30] if circuit_corners > 15 else [35]\n",
    "    \n",
    "    return {'stops': stops, 'laps': laps}\n",
    "\n",
    "def calculate_tire_strategy(weather_conditions, circuit_profile):\n",
    "    'CALCULATE OPTIMAL TIRE STRATEGY'\n",
    "    rain_prob = weather_conditions.get('rain_probability', 0)\n",
    "    track_temp = weather_conditions.get('estimated_track_temp', 35)\n",
    "    circuit_corners = circuit_profile.get('corners', 12)\n",
    "    \n",
    "    if rain_prob > 0.7:\n",
    "        return 'Start on wet tires, switch to intermediates when track dries, then slicks'\n",
    "    elif rain_prob > 0.3:\n",
    "        return 'Flexible strategy: prepare for wet conditions with intermediate option available'\n",
    "    elif track_temp > 45:\n",
    "        if circuit_corners > 15:\n",
    "            return 'Hard-medium one-stop to manage degradation'\n",
    "        else:\n",
    "            return 'Medium-hard one-stop with focus on tire preservation'\n",
    "    elif track_temp < 25:\n",
    "        return 'Soft-medium aggressive strategy to manage tire warm-up'\n",
    "    else:\n",
    "        if circuit_corners > 15:\n",
    "            return 'Soft-medium-hard two-stop for optimal performance'\n",
    "        else:\n",
    "            return 'Medium-hard one-stop balanced strategy'\n",
    "\n",
    "def calculate_overtaking_opportunities(circuit_profile, predicted_position, qualifying_pos):\n",
    "    'CALCULATE OVERTAKING OPPORTUNITIES'\n",
    "    circuit_corners = circuit_profile.get('corners', 12)\n",
    "    circuit_length = circuit_profile.get('length', 5.0)\n",
    "    position_gain = qualifying_pos - predicted_position\n",
    "    \n",
    "    opportunities = []\n",
    "    \n",
    "    if position_gain > 3:\n",
    "        opportunities.append('Aggressive early overtaking recommended')\n",
    "    \n",
    "    if circuit_corners > 15:\n",
    "        opportunities.append('Focus on corner exit overtaking in sector 3')\n",
    "    else:\n",
    "        opportunities.append('DRS zones and long straights provide best opportunities')\n",
    "    \n",
    "    if circuit_length > 6:\n",
    "        opportunities.append('Strategic tire advantage can be used for late-race overtakes')\n",
    "    \n",
    "    return opportunities if opportunities else ['Conventional overtaking approach recommended']\n",
    "\n",
    "def calculate_weather_impact_analysis(weather_conditions):\n",
    "    'ANALYZE WEATHER IMPACT ON RACE STRATEGY'\n",
    "    impacts = []\n",
    "    \n",
    "    rain_prob = weather_conditions.get('rain_probability', 0)\n",
    "    temperature = weather_conditions.get('temperature_avg', 20)\n",
    "    wind_speed = weather_conditions.get('wind_speed_avg', 3)\n",
    "    \n",
    "    if rain_prob > 0.7:\n",
    "        impacts.append('Heavy rain expected - major strategy implications with multiple tire changes')\n",
    "    elif rain_prob > 0.3:\n",
    "        impacts.append('Chance of rain - flexible strategy required with intermediate tire option')\n",
    "    \n",
    "    if temperature > 35:\n",
    "        impacts.append('High temperatures - increased tire degradation and cooling concerns')\n",
    "    elif temperature < 10:\n",
    "        impacts.append('Low temperatures - tire warm-up challenges and potential graining')\n",
    "    \n",
    "    if wind_speed > 8:\n",
    "        impacts.append('Strong winds - aerodynamic instability and potential safety car period')\n",
    "    \n",
    "    if not impacts:\n",
    "        impacts.append('Stable conditions - conventional strategy optimization')\n",
    "    \n",
    "    return impacts\n",
    "\n",
    "def generate_key_considerations(weather_conditions, circuit_profile, driver_profile):\n",
    "    'GENERATE KEY STRATEGY CONSIDERATIONS'\n",
    "    considerations = []\n",
    "    \n",
    "    rain_prob = weather_conditions.get('rain_probability', 0)\n",
    "    driver_exp = driver_profile.get('experience', 50)\n",
    "    circuit_corners = circuit_profile.get('corners', 12)\n",
    "    \n",
    "    if rain_prob > 0.5 and driver_exp < 50:\n",
    "        considerations.append('Inexperienced driver in wet conditions - conservative approach recommended')\n",
    "    \n",
    "    if circuit_corners > 18:\n",
    "        considerations.append('High-downforce circuit - focus on aerodynamic efficiency and tire management')\n",
    "    \n",
    "    if weather_conditions.get('estimated_track_temp', 35) > 40:\n",
    "        considerations.append('High track temperatures - monitor tire wear closely and consider extra stop')\n",
    "    \n",
    "    return considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab73cb1-2f08-4e6f-92fc-86586c0e375e",
   "metadata": {},
   "source": [
    "# 12: ML Pipeline + Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ebb6c61-c4f7-4702-8f3c-b59c4490f2d3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class EnhancedF1StrategyPredictor:\n",
    "    \"\"\"\n",
    "    ENHANCED F1 STRATEGY PREDICTOR WITH COMPLETE ML PIPELINE INTEGRATION AND CACHING\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cache_enabled = True):\n",
    "        self.models = {}\n",
    "        self.preprocessor = ComprehensiveDataPreprocessor()\n",
    "        self.tuner = ComprehensiveHyperparameterTuner()\n",
    "        self.evaluator = ComprehensiveEvaluator()\n",
    "        self.learning_curves = AdvancedLearningCurves()\n",
    "        self.feature_columns = []\n",
    "        self.is_trained = False\n",
    "        self.best_model = None\n",
    "        self.prediction_cache = {}\n",
    "        self.cache_enabled = cache_enabled\n",
    "        self.cache_hits = 0\n",
    "        self.cache_misses = 0\n",
    "    \n",
    "    def prepare_enhanced_features(self, X, y = None, is_training = True):\n",
    "        'PREPARE ENHANCED FEATURES WITH COMPREHENSIVE PREPROCESSING'\n",
    "        X_processed, y_processed = self.preprocessor.comprehensive_preprocessing_pipeline(\n",
    "            X, y, problem_type = 'regression'\n",
    "        )\n",
    "        \n",
    "        if is_training and y_processed is not None:\n",
    "            self.feature_columns = X_processed.columns.tolist()\n",
    "            \n",
    "        return X_processed, y_processed\n",
    "    \n",
    "    def train_enhanced_models(self, X, y_position, y_pit_stops = None, use_caching = True):\n",
    "        'TRAIN ENHANCED MODELS WITH COMPLETE ML PIPELINE'\n",
    "        print(f'\\n🎯 TRAINING ENHANCED MODELS WITH COMPLETE ML PIPELINE...')\n",
    "        \n",
    "        if X.empty or len(X) < 10:\n",
    "            print('❌ Insufficient data for enhanced training')\n",
    "            return\n",
    "        \n",
    "        # Cache configuration\n",
    "        \n",
    "        self.cache_enabled = use_caching\n",
    "        if not use_caching:\n",
    "            self.clear_prediction_cache()\n",
    "            print('   🚫 Prediction caching disabled for training')\n",
    "        \n",
    "        try:\n",
    "            # STEP 1: Comprehensive Preprocessing\n",
    "            \n",
    "            X_processed, y_processed = self.prepare_enhanced_features(X, y_position, is_training = True)\n",
    "            \n",
    "            # Store feature columns for prediction alignment\n",
    "            \n",
    "            self.feature_columns = X_processed.columns.tolist()\n",
    "            print(f'   Feature columns stored: {len(self.feature_columns)} features')\n",
    "            \n",
    "            # STEP 2: Train-Test Split\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_processed, y_processed, test_size = 0.2, random_state = 42, shuffle = True\n",
    "            )\n",
    "            \n",
    "            print(f'   Training set: {X_train.shape[0]} samples, {X_train.shape[1]} features')\n",
    "            print(f'   Test set: {X_test.shape[0]} samples')\n",
    "            \n",
    "            # STEP 3: Define Models and Parameter Grids\n",
    "            \n",
    "            models = {\n",
    "                'Random Forest': RandomForestRegressor(random_state = 42),\n",
    "                'Gradient Boosting': GradientBoostingRegressor(random_state = 42),\n",
    "                'SVR': SVR(),\n",
    "                'KNN': KNeighborsRegressor(),\n",
    "                'Decision Tree': DecisionTreeRegressor(random_state = 42)\n",
    "            }\n",
    "            \n",
    "            param_grids = {\n",
    "                'Random Forest': {\n",
    "                    'n_estimators': [50, 100, 200],\n",
    "                    'max_depth': [10, 20, None],\n",
    "                    'min_samples_split': [2, 5, 10],\n",
    "                    'min_samples_leaf': [1, 2, 4]\n",
    "                },\n",
    "                'Gradient Boosting': {\n",
    "                    'n_estimators': [50, 100, 200],\n",
    "                    'learning_rate': [0.01, 0.1, 0.2],\n",
    "                    'max_depth': [3, 5, 7]\n",
    "                },\n",
    "                'SVR': {\n",
    "                    'C': [0.1, 1, 10],\n",
    "                    'kernel': ['linear', 'rbf'],\n",
    "                    'gamma': ['scale', 'auto']\n",
    "                },\n",
    "                'KNN': {\n",
    "                    'n_neighbors': [3, 5, 7, 9],\n",
    "                    'weights': ['uniform', 'distance'],\n",
    "                    'metric': ['euclidean', 'manhattan']\n",
    "                },\n",
    "                'Decision Tree': {\n",
    "                    'max_depth': [5, 10, 15, 20, None],\n",
    "                    'min_samples_split': [2, 5, 10],\n",
    "                    'min_samples_leaf': [1, 2, 4]\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # STEP 4: Comprehensive Hyperparameter Tuning\n",
    "            \n",
    "            print('  🔧 Performing comprehensive hyperparameter tuning...')\n",
    "            tuned_models = {}\n",
    "            \n",
    "            for name, model in models.items():\n",
    "                tuned_model = self.tuner.comprehensive_tuning(\n",
    "                    model, param_grids[name], X_train, y_train, \n",
    "                    problem_type = 'regression', tuning_method = 'randomized', n_iter = 20\n",
    "                )\n",
    "                tuned_models[name] = tuned_model\n",
    "            \n",
    "            # STEP 5: Model Comparison\n",
    "            \n",
    "            print('   📊 Comparing model performance...')\n",
    "            model_comparison = self.tuner.compare_models_comprehensive(\n",
    "                tuned_models, X_train, y_train, problem_type = 'regression', cv_folds = 5\n",
    "            )\n",
    "            \n",
    "            # Select best model\n",
    "            \n",
    "            best_model_name = min(model_comparison, key = lambda x: model_comparison[x]['mean_score'])\n",
    "            self.best_model = tuned_models[best_model_name]\n",
    "            \n",
    "            print(f' 🏆 BEST MODEL: {best_model_name} (MAE: {model_comparison[best_model_name]['mean_score']:.4f})')\n",
    "            \n",
    "            # STEP 6: Advanced Learning Curves\n",
    "            \n",
    "            print('  📈 Generating advanced learning curves...')\n",
    "            self.learning_curves.plot_advanced_learning_curves(\n",
    "                self.best_model, X_train, y_train, model_name = best_model_name, cv_folds = 5\n",
    "            )\n",
    "            \n",
    "            # STEP 7: Comprehensive Evaluation\n",
    "            \n",
    "            print(' 📋 Performing comprehensive model evaluation...')\n",
    "            evaluation_results = self.evaluator.comprehensive_regression_evaluation(\n",
    "                self.best_model, X_train, X_test, y_train, y_test, model_name = best_model_name\n",
    "            )\n",
    "            \n",
    "            # STEP 8: Train final model on full data\n",
    "            \n",
    "            self.best_model.fit(X_processed, y_processed)\n",
    "            self.models['position'] = self.best_model\n",
    "            self.is_trained = True\n",
    "            \n",
    "            # STEP 9: Feature Importance Analysis\n",
    "            \n",
    "            self.analyze_feature_importance(self.best_model, X_processed.columns)\n",
    "            \n",
    "            print('✅ Enhanced model training pipeline completed successfully')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'❌ Error in enhanced training pipeline: {e}')\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    def analyze_feature_importance(self, model, feature_names):\n",
    "        'ANALYZE FEATURE IMPORTANCE FOR MODEL INTERPRETABILITY'\n",
    "        try:\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                importances = model.feature_importances_\n",
    "                feature_importance_df = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'importance': importances\n",
    "                }).sort_values('importance', ascending = False)\n",
    "                \n",
    "                print('\\n📊 TOP 10 FEATURE IMPORTANCES:')\n",
    "                for idx, row in feature_importance_df.head(10).iterrows():\n",
    "                    print(f'   {row['feature']}: {row['importance']:.4f}')\n",
    "                \n",
    "                # Plot feature importance\n",
    "                \n",
    "                plt.figure(figsize = (12, 8))\n",
    "                top_features = feature_importance_df.head(15)\n",
    "                plt.barh(range(len(top_features)), top_features['importance'], color = 'skyblue')\n",
    "                plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "                plt.xlabel('Feature Importance')\n",
    "                plt.title('Top 15 Feature Importances', fontweight = 'bold')\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig('feature_importance.png', dpi = 300, bbox_inches = 'tight')\n",
    "                plt.close()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f'⚠️ Could not analyze feature importance: {e}')\n",
    "    \n",
    "    def ensure_feature_alignment(self, X_processed):\n",
    "        'ENSURE FEATURE ALIGNMENT BETWEEN TRAINING AND PREDICTION'\n",
    "        if not hasattr(self, 'feature_columns') or not self.feature_columns:\n",
    "            return X_processed\n",
    "        \n",
    "        # Create a new DataFrame with the correct feature structure\n",
    "        \n",
    "        aligned_data = pd.DataFrame(index = X_processed.index)\n",
    "        \n",
    "        for col in self.feature_columns:\n",
    "            if col in X_processed.columns:\n",
    "                aligned_data[col] = X_processed[col]\n",
    "            else:\n",
    "                # Fill missing features with appropriate defaults\n",
    "                \n",
    "                if 'driver' in col:\n",
    "                    aligned_data[col] = 50.0 if 'experience' in col else 0.05\n",
    "                elif 'constructor' in col:\n",
    "                    aligned_data[col] = 300.0 if 'experience' in col else 0.08\n",
    "                elif 'circuit' in col:\n",
    "                    aligned_data[col] = 5.0 if 'length' in col else 12.0\n",
    "                elif 'temperature' in col:\n",
    "                    aligned_data[col] = 20.0\n",
    "                elif 'rain' in col:\n",
    "                    aligned_data[col] = 0.0\n",
    "                else:\n",
    "                    aligned_data[col] = 0.0\n",
    "        \n",
    "        return aligned_data\n",
    "    \n",
    "    def create_prediction_cache_key(self, X):\n",
    "        'CREATE CACHE KEY FROM INPUT DATA FOR PREDICTION CACHING'\n",
    "        if X.empty:\n",
    "            return 'empty_input'\n",
    "        \n",
    "        # Use hash of important features for cache key\n",
    "        \n",
    "        key_features = ['qualifying_position', 'driver_experience', 'constructor_experience', \n",
    "                       'temperature_avg', 'rain_probability']\n",
    "        \n",
    "        available_features = [f for f in key_features if f in X.columns]\n",
    "        if available_features:\n",
    "        \n",
    "            # Create hash from feature values\n",
    "            \n",
    "            feature_string = ''\n",
    "            for f in available_features:\n",
    "                feature_string += str(X[f].values.tobytes())\n",
    "            return hashlib.md5(feature_string.encode()).hexdigest()\n",
    "        else:\n",
    "            return str(hash(str(X.values.tobytes())))\n",
    "    \n",
    "    def predict_enhanced_position(self, X):\n",
    "        'PREDICT ENHANCED POSITION WITH COMPLETE PIPELINE AND CACHING'\n",
    "        if not self.is_trained or X.empty:\n",
    "            return self.enhanced_fallback_prediction(X)\n",
    "        \n",
    "        try:\n",
    "            # Create cache key\n",
    "            \n",
    "            cache_key = self.create_prediction_cache_key(X)\n",
    "            \n",
    "            if self.cache_enabled and cache_key in self.prediction_cache:\n",
    "                self.cache_hits += 1\n",
    "                if self.cache_hits % 20 == 0:                          # Log every 20 cache hits\n",
    "                    print(f'  💾 Prediction cache: {self.cache_hits} hits, {self.cache_misses} misses')\n",
    "                return self.prediction_cache[cache_key]\n",
    "            \n",
    "            X_processed, _ = self.prepare_enhanced_features(X, is_training = False)\n",
    "            \n",
    "            # Ensure feature alignment with training data\n",
    "            \n",
    "            X_aligned = self.ensure_feature_alignment(X_processed)\n",
    "            \n",
    "            predictions = self.best_model.predict(X_aligned)\n",
    "            predictions = np.clip(predictions, 1, 30)\n",
    "            \n",
    "            # Cache the predictions\n",
    "            \n",
    "            if self.cache_enabled:\n",
    "                self.prediction_cache[cache_key] = predictions\n",
    "                self.cache_misses += 1\n",
    "            \n",
    "            return predictions\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'⚠️ Enhanced prediction error: {e}')\n",
    "            return self.enhanced_fallback_prediction(X)\n",
    "    \n",
    "    def enhanced_fallback_prediction(self, X):\n",
    "        'FALLBACK PREDICTION WITH WEATHER CONSIDERATION'\n",
    "        if X.empty:\n",
    "            return np.array([10])                                           # Default prediction\n",
    "        \n",
    "        try:\n",
    "            if 'qualifying_position' in X.columns:\n",
    "                base_prediction = X['qualifying_position'].values\n",
    "                \n",
    "                # Weather-based adjustments\n",
    "                \n",
    "                weather_adjustment = 0\n",
    "                \n",
    "                if 'rain_probability' in X.columns:\n",
    "                    rain_adjustment = X['rain_probability'].fillna(0) * 2\n",
    "                    weather_adjustment += rain_adjustment\n",
    "                \n",
    "                if 'temperature_avg' in X.columns:\n",
    "                    temp_deviation = abs(X['temperature_avg'].fillna(20) - 20) / 10\n",
    "                    temp_adjustment = temp_deviation * 1.5\n",
    "                    weather_adjustment += temp_adjustment\n",
    "                \n",
    "                final_prediction = base_prediction + weather_adjustment\n",
    "                return np.clip(final_prediction, 1, 30)\n",
    "            else:\n",
    "                return np.array([10] * len(X))\n",
    "        except Exception as e:\n",
    "            print(f'⚠️ Fallback prediction error: {e}')\n",
    "            return np.array([10] * len(X))\n",
    "    \n",
    "    def clear_prediction_cache(self):\n",
    "        'CLEAR PREDICTION CACHE'\n",
    "        self.prediction_cache = {}\n",
    "        self.cache_hits = 0\n",
    "        self.cache_misses = 0\n",
    "        print('🧹 Prediction cache cleared')\n",
    "    \n",
    "    def get_prediction_cache_stats(self):\n",
    "        'GET PREDICTION CACHE STATISTICS'\n",
    "        total_predictions = self.cache_hits + self.cache_misses\n",
    "        hit_rate = (self.cache_hits / total_predictions * 100) if total_predictions > 0 else 0\n",
    "        return {\n",
    "            'hits': self.cache_hits,\n",
    "            'misses': self.cache_misses,\n",
    "            'total': total_predictions,\n",
    "            'hit_rate': hit_rate,\n",
    "            'cached_predictions': len(self.prediction_cache)\n",
    "        }\n",
    "    \n",
    "    def enable_caching(self):\n",
    "        'ENABLE PREDICTION CACHING'\n",
    "        self.cache_enabled = True\n",
    "        print('✅ Prediction caching enabled')\n",
    "    \n",
    "    def disable_caching(self):\n",
    "        'DISABLE PREDICTION CACHING'\n",
    "        self.cache_enabled = False\n",
    "        print('🚫 Prediction caching disabled')\n",
    "    \n",
    "    def save_model(self, filepath = 'f1_strategy_predictor.pkl'):\n",
    "        'SAVE TRAINED MODEL AND CACHE'\n",
    "        try:\n",
    "            model_data = {\n",
    "                'best_model': self.best_model,\n",
    "                'feature_columns': self.feature_columns,\n",
    "                'is_trained': self.is_trained,\n",
    "                'prediction_cache': self.prediction_cache,\n",
    "                'cache_stats': {\n",
    "                    'hits': self.cache_hits,\n",
    "                    'misses': self.cache_misses\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(model_data, f)\n",
    "            \n",
    "            print(f'💾 Model saved to {filepath}')\n",
    "        except Exception as e:\n",
    "            print(f'❌ Error saving model: {e}')\n",
    "    \n",
    "    def load_model(self, filepath = 'f1_strategy_predictor.pkl'):\n",
    "        'LOAD TRAINED MODEL AND CACHE'\n",
    "        try:\n",
    "            with open(filepath, 'rb') as f:\n",
    "                model_data = pickle.load(f)\n",
    "            \n",
    "            self.best_model = model_data['best_model']\n",
    "            self.feature_columns = model_data['feature_columns']\n",
    "            self.is_trained = model_data['is_trained']\n",
    "            self.prediction_cache = model_data.get('prediction_cache', {})\n",
    "            cache_stats = model_data.get('cache_stats', {})\n",
    "            self.cache_hits = cache_stats.get('hits', 0)\n",
    "            self.cache_misses = cache_stats.get('misses', 0)\n",
    "            \n",
    "            print(f'📂 Model loaded from {filepath}')\n",
    "            print(f'   Feature columns: {len(self.feature_columns)}')\n",
    "            print(f'   Cached predictions: {len(self.prediction_cache)}')\n",
    "        except Exception as e:\n",
    "            print(f'❌ Error loading model: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e134ad85-784d-4b12-b538-a08a71870f31",
   "metadata": {},
   "source": [
    "# 13: Complete Main Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccc22962-c770-4b39-ac15-5e455c979978",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 STARTING F1 STRATEGY ML PIPELINE...\n",
      "\n",
      "================================================================================\n",
      "F1 RACE STRATEGY ML SYSTEM - COMPLETE EXECUTION\n",
      "================================================================================\n",
      "\n",
      "📥 STEP 1: LOADING COMPLETE F1 DATA FROM MYSQL DATABASE...\n",
      "🔄 LOADING COMPLETE F1 DATA FROM MYSQL DATABASE...\n",
      "✅ MySQL database connection established successfully\n",
      "✅ Loaded 912 records from driver\n",
      "✅ Loaded 185 records from constructor\n",
      "✅ Loaded 77 records from circuit\n",
      "✅ Loaded 1149 records from race\n",
      "✅ Loaded 183464 records from race_data\n",
      "✅ Loaded 26576 records from qualifying_result\n",
      "✅ Loaded 21866 records from pit_stop\n",
      "✅ Loaded 53 records from grand_prix\n",
      "✅ Loaded 249 records from country\n",
      "✅ Loaded 7 records from continent\n",
      "✅ Loaded 27151 records from race_result\n",
      "✅ Loaded lap times from interactive_lap_statistics_mat\n",
      "✅ Loaded 16716 records from fastest_lap\n",
      "✅ Loaded 25388 records from starting_grid_position\n",
      "📊 Database Cache Stats: 0 hits, 13 misses (0.0% hit rate)\n",
      "✅ MySQL database connection closed\n",
      "🎯 MYSQL DATA LOADING COMPLETE: 15 datasets with 313,808 total records\n",
      "\n",
      "🧹 STEP 2: CLEANING AND PREPARING DATA...\n",
      "\n",
      "🧹 DATA CLEANING REPORT:\n",
      "==================================================\n",
      "📊 DRIVERS         | Rows:  912 → 859  | Cols: 26 → 26 | Removed: 53 rows, 0 cols\n",
      "📊 CONSTRUCTORS    | Rows:  185 → 184  | Cols: 19 → 19 | Removed:  1 rows, 0 cols\n",
      "📊 CIRCUITS        | Rows:   77 → 77   | Cols: 13 → 13 | Removed:  0 rows, 0 cols\n",
      "📊 RACES           | Rows: 1149 → 1149 | Cols: 18 → 18 | Removed:  0 rows, 0 cols\n",
      "📊 COUNTRIES       | Rows:  249 → 249  | Cols:  6 → 6  | Removed:  0 rows, 0 cols\n",
      "📊 CONTINENTS      | Rows:    7 → 7    | Cols:  4 → 4  | Removed:  0 rows, 0 cols\n",
      "📊 GRANDSPRIX      | Rows:   53 → 53   | Cols:  6 → 6  | Removed:  0 rows, 0 cols\n",
      "📊 RESULTS         | Rows: 183464 → 172304 | Cols: 18 → 18 | Removed: 11160 rows, 0 cols\n",
      "📊 QUALIFYING      | Rows: 26576 → 26576 | Cols: 15 → 15 | Removed:  0 rows, 0 cols\n",
      "📊 PITSTOPS        | Rows: 21866 → 21866 | Cols:  6 → 6  | Removed:  0 rows, 0 cols\n",
      "📊 LAPTIMES        | Rows: 10000 → 10000 | Cols:  9 → 9  | Removed:  0 rows, 0 cols\n",
      "📊 FASTESTLAPS     | Rows: 16716 → 16716 | Cols:  5 → 5  | Removed:  0 rows, 0 cols\n",
      "📊 STARTINGGRID    | Rows: 25388 → 25388 | Cols:  3 → 3  | Removed:  0 rows, 0 cols\n",
      "📊 STATUS          | Rows:   15 → 15   | Cols:  2 → 2  | Removed:  0 rows, 0 cols\n",
      "📊 RACE_RESULTS    | Rows: 27151 → 27151 | Cols: 11 → 11 | Removed:  0 rows, 0 cols\n",
      "\n",
      "🔗 STEP 3: BUILDING MERGED DATASET...\n",
      "\n",
      "🔄 BUILDING ENHANCED MERGED DATASET FROM MYSQL...\n",
      "   Base race_results: 27151 records\n",
      "   ✅ Merged races: 27151 records\n",
      "   ✅ Merged circuits: 27151 records\n",
      "   ✅ Merged drivers: 27151 records\n",
      "   ✅ Merged constructors: 27151 records\n",
      "   ✅ Added qualifying data: 27152 records\n",
      "   ✅ Added pit stop data: 27152 records\n",
      "🎯 ENHANCED MERGED DATASET: 27152 records with 89 columns\n",
      "📊 Merged dataset contains 27152 records from 77 circuits\n",
      "\n",
      "🌤️ STEP 4: INTEGRATING REAL WEATHER DATA FOR ALL CIRCUITS...\n",
      "\n",
      "🌤️ INTEGRATING REAL WEATHER DATA INTO DATASET...\n",
      "   📍 Loaded coordinates for Adelaide: (-34.927222, 138.617222)\n",
      "   📍 Loaded coordinates for Aida: (34.915, 134.221111)\n",
      "   📍 Loaded coordinates for Ain-Diab: (33.578611, -7.6875)\n",
      "   📍 Loaded coordinates for Aintree: (53.476944, -2.940556)\n",
      "   📍 Loaded coordinates for Anderstorp Raceway: (57.264167, 13.601389)\n",
      "   📍 Loaded coordinates for Americas: (30.132778, -97.641111)\n",
      "   📍 Loaded coordinates for AVUS: (52.480556, 13.251389)\n",
      "   📍 Loaded coordinates for Bahrain: (26.0325, 50.510556)\n",
      "   📍 Loaded coordinates for Baku: (40.3725, 49.853333)\n",
      "   📍 Loaded coordinates for Brands Hatch: (51.356667, 0.2625)\n",
      "   📍 Loaded coordinates for Bremgarten: (46.95, 7.410833)\n",
      "   📍 Loaded coordinates for Buddh: (28.350556, 77.535)\n",
      "   📍 Loaded coordinates for Juan y Oscar Gálvez: (-34.694272, -58.459347)\n",
      "   📍 Loaded coordinates for Bugatti: (47.937694, 0.225611)\n",
      "   📍 Loaded coordinates for Caesars Palace: (36.116944, -115.175)\n",
      "   📍 Loaded coordinates for Catalunya: (41.57, 2.261111)\n",
      "   📍 Loaded coordinates for Charade: (45.747222, 3.038889)\n",
      "   📍 Loaded coordinates for Fair Park: (32.781944, -96.765556)\n",
      "   📍 Loaded coordinates for Detroit: (42.32975, -83.040111)\n",
      "   📍 Loaded coordinates for Dijon-Prenois: (47.3625, 4.899167)\n",
      "   📍 Loaded coordinates for Donington Park: (52.829806, -1.379556)\n",
      "   📍 Loaded coordinates for Prince George: (-33.048611, 27.873611)\n",
      "   📍 Loaded coordinates for Estoril: (38.750833, -9.394167)\n",
      "   📍 Loaded coordinates for Fuji: (35.371667, 138.926667)\n",
      "   📍 Loaded coordinates for Hockenheimring: (49.327778, 8.565833)\n",
      "   📍 Loaded coordinates for Hungaroring: (47.582222, 19.251111)\n",
      "   📍 Loaded coordinates for Enzo e Dino Ferrari: (44.341111, 11.713333)\n",
      "   📍 Loaded coordinates for Indianapolis: (39.798333, -86.232778)\n",
      "   📍 Loaded coordinates for José Carlos Pace: (-23.701111, -46.697222)\n",
      "   📍 Loaded coordinates for Istanbul Park: (40.951667, 29.405)\n",
      "   📍 Loaded coordinates for Nelson Piquet: (-22.975556, -43.395)\n",
      "   📍 Loaded coordinates for Jarama: (40.617111, -3.585583)\n",
      "   📍 Loaded coordinates for Jeddah: (21.543333, 39.172778)\n",
      "   📍 Loaded coordinates for Jerez: (36.708333, -6.034167)\n",
      "   📍 Loaded coordinates for Kyalami: (-25.998611, 28.068889)\n",
      "   📍 Loaded coordinates for Las Vegas: (36.175, -115.136389)\n",
      "   📍 Loaded coordinates for Long Beach: (33.766389, -118.192778)\n",
      "   📍 Loaded coordinates for Lusail: (25.49, 51.454167)\n",
      "   📍 Loaded coordinates for Magny-Cours: (46.863242, 3.164228)\n",
      "   📍 Loaded coordinates for Marina Bay: (1.291531, 103.86385)\n",
      "   📍 Loaded coordinates for Melbourne: (-37.849722, 144.968333)\n",
      "   📍 Loaded coordinates for Hermanos Rodríguez: (19.404197, -99.088747)\n",
      "   📍 Loaded coordinates for Miami: (25.958056, -80.238889)\n",
      "   📍 Loaded coordinates for Monaco: (43.734722, 7.420556)\n",
      "   📍 Loaded coordinates for Monsanto: (38.719722, -9.203056)\n",
      "   📍 Loaded coordinates for Mont-Tremblant: (46.187707, -74.609936)\n",
      "   📍 Loaded coordinates for Montjuïc: (41.366389, 2.151667)\n",
      "   📍 Loaded coordinates for Gilles Villeneuve: (45.500578, -73.522461)\n",
      "   📍 Loaded coordinates for Monza: (45.620556, 9.289444)\n",
      "   📍 Loaded coordinates for Mosport: (44.05, -78.677778)\n",
      "   📍 Loaded coordinates for Mugello: (43.9975, 11.371944)\n",
      "   📍 Loaded coordinates for Nivelles-Baulers: (50.621111, 4.326944)\n",
      "   📍 Loaded coordinates for Nürburgring: (50.335556, 6.9475)\n",
      "   📍 Loaded coordinates for Paul Ricard: (43.250556, 5.791667)\n",
      "   📍 Loaded coordinates for Pedralbes: (41.390278, 2.116667)\n",
      "   📍 Loaded coordinates for Pescara: (42.475, 14.150833)\n",
      "   📍 Loaded coordinates for Phoenix: (33.447917, -112.074583)\n",
      "   📍 Loaded coordinates for Portimão: (37.221944, -8.629444)\n",
      "   📍 Loaded coordinates for Boavista: (41.170472, -8.67325)\n",
      "   📍 Loaded coordinates for Reims-Gueux: (49.254075, 3.930561)\n",
      "   📍 Loaded coordinates for Riverside: (33.937, -117.272556)\n",
      "   📍 Loaded coordinates for Rouen-Les-Essarts: (49.330639, 1.004583)\n",
      "   📍 Loaded coordinates for Sebring: (27.454741, -81.348267)\n",
      "   📍 Loaded coordinates for Sepang: (2.760556, 101.7375)\n",
      "   📍 Loaded coordinates for Shanghai: (31.338889, 121.219722)\n",
      "   📍 Loaded coordinates for Silverstone: (52.078611, -1.016944)\n",
      "   📍 Loaded coordinates for Sochi: (43.410278, 39.968271)\n",
      "   📍 Loaded coordinates for Spa-Francorchamps: (50.437222, 5.971389)\n",
      "   📍 Loaded coordinates for Red Bull Ring: (47.219722, 14.764722)\n",
      "   📍 Loaded coordinates for Suzuka: (34.843056, 136.540556)\n",
      "   📍 Loaded coordinates for Valencia: (39.458778, -0.325556)\n",
      "   📍 Loaded coordinates for Watkins Glen: (42.336944, -76.927222)\n",
      "   📍 Loaded coordinates for Yas Marina: (24.467222, 54.603056)\n",
      "   📍 Loaded coordinates for Korea: (34.733333, 126.416667)\n",
      "   📍 Loaded coordinates for Zandvoort: (52.388819, 4.540922)\n",
      "   📍 Loaded coordinates for Zeltweg: (47.202222, 14.742222)\n",
      "   📍 Loaded coordinates for Zolder: (50.988889, 5.255556)\n",
      "✅ Loaded coordinates for 77 circuits\n",
      "✅ Loaded weather cache with 1142 valid entries (0 expired)\n",
      "   Processing 1142 unique races for real weather data...\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 45/1142 races...\n",
      "   📦 Using cached weather data for circuit bremgarten\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit reims\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bremgarten\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit reims\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 300/1142 races...\n",
      "   📦 Using cached weather data for circuit pedralbes\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 325/1142 races...\n",
      "   📦 Using cached weather data for circuit bremgarten\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 345/1142 races...\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit rouen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 630/1142 races...\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit reims\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bremgarten\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 765/1142 races...\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 790/1142 races...\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit reims\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 19 real weather features\n",
      "   Processed 965/1142 races...\n",
      "   📦 Using cached weather data for circuit bremgarten\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit pedralbes\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit aintree\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 1180/1142 races...\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit reims\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 1395/1142 races...\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit rouen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit aintree\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 1535/1142 races...\n",
      "   📦 Using cached weather data for circuit pescara\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 1575/1142 races...\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 1595/1142 races...\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 1605/1142 races...\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 1635/1142 races...\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit reims\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit porto\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit ain-diab\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 1860/1142 races...\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit reims\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit aintree\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 1930/1142 races...\n",
      "   📦 Using cached weather data for circuit avus\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 1960/1142 races...\n",
      "   📦 Using cached weather data for circuit monsanto\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit sebring\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 2135/1142 races...\n",
      "   📦 Using cached weather data for circuit reims\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit porto\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit riverside\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 2235/1142 races...\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit reims\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit aintree\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 2350/1142 races...\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit rouen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit aintree\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit east-london\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 2660/1142 races...\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit reims\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 2760/1142 races...\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 2835/1142 races...\n",
      "   📦 Using cached weather data for circuit east-london\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit rouen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit brands-hatch\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zeltweg\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit east-london\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit clermont-ferrand\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 3195/1142 races...\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 3275/1142 races...\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit reims\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 3330/1142 races...\n",
      "   📦 Using cached weather data for circuit brands-hatch\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 3530/1142 races...\n",
      "   📦 Using cached weather data for circuit bugatti\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mosport\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 3610/1142 races...\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 3665/1142 races...\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jarama\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit rouen\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit brands-hatch\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 19 real weather features\n",
      "   Processed 3835/1142 races...\n",
      "   📦 Using cached weather data for circuit mont-tremblant\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montjuic\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 3955/1142 races...\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit clermont-ferrand\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit mosport\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jarama\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit clermont-ferrand\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit brands-hatch\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit mont-tremblant\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 4345/1142 races...\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 4365/1142 races...\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 4410/1142 races...\n",
      "   📦 Using cached weather data for circuit montjuic\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 4435/1142 races...\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 4480/1142 races...\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 4505/1142 races...\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mosport\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 4650/1142 races...\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jarama\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nivelles\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit clermont-ferrand\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit brands-hatch\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mosport\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 5020/1142 races...\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 5040/1142 races...\n",
      "   📦 Using cached weather data for circuit montjuic\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 5065/1142 races...\n",
      "   📦 Using cached weather data for circuit zolder\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 5110/1142 races...\n",
      "   📦 Using cached weather data for circuit anderstorp\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mosport\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 5335/1142 races...\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jarama\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nivelles\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit anderstorp\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit dijon\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit brands-hatch\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit mosport\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montjuic\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zolder\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit anderstorp\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 6030/1142 races...\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit long-beach\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jarama\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 6240/1142 races...\n",
      "   📦 Using cached weather data for circuit zolder\n",
      "   ✅ Processed 19 real weather features\n",
      "   Processed 6270/1142 races...\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit anderstorp\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit brands-hatch\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 6440/1142 races...\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 6465/1142 races...\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit mosport\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit fuji\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 6575/1142 races...\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 6645/1142 races...\n",
      "   📦 Using cached weather data for circuit long-beach\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jarama\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 6690/1142 races...\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zolder\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit anderstorp\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit dijon\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 6810/1142 races...\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 6840/1142 races...\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 6970/1142 races...\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit mosport\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit fuji\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jacarepagua\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit long-beach\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zolder\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jarama\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit anderstorp\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit brands-hatch\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 7580/1142 races...\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit long-beach\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jarama\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zolder\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 7685/1142 races...\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit dijon\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 7765/1142 races...\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit long-beach\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 8040/1142 races...\n",
      "   📦 Using cached weather data for circuit zolder\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit brands-hatch\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 8175/1142 races...\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit watkins-glen\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit long-beach\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jacarepagua\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zolder\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jarama\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 8520/1142 races...\n",
      "   📦 Using cached weather data for circuit dijon\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 8550/1142 races...\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit caesars-palace\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jacarepagua\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit long-beach\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zolder\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 8925/1142 races...\n",
      "   📦 Using cached weather data for circuit detroit\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 8985/1142 races...\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit brands-hatch\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 9045/1142 races...\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 9075/1142 races...\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 9105/1142 races...\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 9135/1142 races...\n",
      "   📦 Using cached weather data for circuit dijon\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit caesars-palace\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jacarepagua\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit long-beach\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit detroit\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 9535/1142 races...\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit brands-hatch\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jacarepagua\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zolder\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit dijon\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 9840/1142 races...\n",
      "   📦 Using cached weather data for circuit detroit\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit dallas\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit brands-hatch\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit estoril\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jacarepagua\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit estoril\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit detroit\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 10290/1142 races...\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 10370/1142 races...\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit brands-hatch\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 10475/1142 races...\n",
      "   📦 Using cached weather data for circuit adelaide\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jacarepagua\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jerez\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit detroit\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit brands-hatch\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 10725/1142 races...\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit estoril\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit adelaide\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jacarepagua\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 10935/1142 races...\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 10985/1142 races...\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit detroit\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 11115/1142 races...\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit estoril\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jerez\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit adelaide\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 11330/1142 races...\n",
      "   📦 Using cached weather data for circuit jacarepagua\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 11450/1142 races...\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit detroit\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 11605/1142 races...\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit estoril\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jerez\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 11760/1142 races...\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit adelaide\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jacarepagua\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 11930/1142 races...\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit phoenix\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 12085/1142 races...\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 12280/1142 races...\n",
      "   📦 Using cached weather data for circuit estoril\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jerez\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit adelaide\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 12435/1142 races...\n",
      "   📦 Using cached weather data for circuit phoenix\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit estoril\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 12890/1142 races...\n",
      "   📦 Using cached weather data for circuit jerez\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit adelaide\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit phoenix\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 13050/1142 races...\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 13220/1142 races...\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 13390/1142 races...\n",
      "   📦 Using cached weather data for circuit estoril\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit adelaide\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 13555/1142 races...\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 13680/1142 races...\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 13775/1142 races...\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 13805/1142 races...\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 13900/1142 races...\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 13930/1142 races...\n",
      "   📦 Using cached weather data for circuit estoril\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit adelaide\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 14010/1142 races...\n",
      "   📦 Using cached weather data for circuit kyalami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit donington\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 14140/1142 races...\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 14270/1142 races...\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit estoril\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 14400/1142 races...\n",
      "   📦 Using cached weather data for circuit adelaide\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit aida\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 14585/1142 races...\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 14640/1142 races...\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit estoril\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 14780/1142 races...\n",
      "   📦 Using cached weather data for circuit jerez\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit adelaide\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 14970/1142 races...\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 19 real weather features\n",
      "   Processed 15070/1142 races...\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit estoril\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 15190/1142 races...\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit aida\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit adelaide\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 15310/1142 races...\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 15420/1142 races...\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 15530/1142 races...\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 15550/1142 races...\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 15570/1142 races...\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 15590/1142 races...\n",
      "   📦 Using cached weather data for circuit estoril\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 15610/1142 races...\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 15630/1142 races...\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 15650/1142 races...\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 15740/1142 races...\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 15850/1142 races...\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 15960/1142 races...\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jerez\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit buenos-aires\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 16070/1142 races...\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 16180/1142 races...\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 16290/1142 races...\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 16400/1142 races...\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 16510/1142 races...\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 16620/1142 races...\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 16730/1142 races...\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 16840/1142 races...\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 16950/1142 races...\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 17060/1142 races...\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 19 real weather features\n",
      "   Processed 17170/1142 races...\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 17280/1142 races...\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 17390/1142 races...\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 17500/1142 races...\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 17610/1142 races...\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 17720/1142 races...\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 18620/1142 races...\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit istanbul\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 19 real weather features\n",
      "   Processed 18920/1142 races...\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 19030/1142 races...\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 19140/1142 races...\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit istanbul\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 19250/1142 races...\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 19360/1142 races...\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit indianapolis\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 19470/1142 races...\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit istanbul\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 19580/1142 races...\n",
      "   📦 Using cached weather data for circuit fuji\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 19690/1142 races...\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit istanbul\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit magny-cours\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit valencia\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit marina-bay\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit fuji\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit istanbul\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit valencia\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit marina-bay\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 20400/1142 races...\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit istanbul\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 20520/1142 races...\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit valencia\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 20640/1142 races...\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit marina-bay\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yeongam\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 20760/1142 races...\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit istanbul\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 20950/1142 races...\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit valencia\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 21070/1142 races...\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit marina-bay\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yeongam\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 21190/1142 races...\n",
      "   📦 Using cached weather data for circuit buddh\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 21310/1142 races...\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 21430/1142 races...\n",
      "   📦 Using cached weather data for circuit valencia\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 21550/1142 races...\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit marina-bay\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yeongam\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit buddh\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 21670/1142 races...\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit austin\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 21810/1142 races...\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 21920/1142 races...\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit marina-bay\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 22030/1142 races...\n",
      "   📦 Using cached weather data for circuit yeongam\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit buddh\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit austin\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 22140/1142 races...\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 22250/1142 races...\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 22360/1142 races...\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit marina-bay\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 22470/1142 races...\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sochi\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit austin\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 22535/1142 races...\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit marina-bay\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sochi\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit austin\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 23015/1142 races...\n",
      "   📦 Using cached weather data for circuit sochi\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit baku\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 23125/1142 races...\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 23235/1142 races...\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit marina-bay\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit austin\n",
      "   ✅ Processed 22 real weather features\n",
      "   Processed 23345/1142 races...\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sochi\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit baku\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit marina-bay\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sepang\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit austin\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit baku\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit marina-bay\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sochi\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit austin\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit baku\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hockenheimring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit marina-bay\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sochi\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit austin\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ⚠️ No race day weather data, using weekend averages\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ⚠️ No race day weather data, using weekend averages\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mugello\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sochi\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit nurburgring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit portimao\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit istanbul\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ⚠️ No race day weather data, using weekend averages\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit portimao\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit baku\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ⚠️ No race day weather data, using weekend averages\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit sochi\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit istanbul\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit austin\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit lusail\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jeddah\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jeddah\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit miami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit baku\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit paul-ricard\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit marina-bay\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit austin\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jeddah\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit baku\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit miami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit marina-bay\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit lusail\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit austin\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit las-vegas\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jeddah\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit miami\n",
      "   ✅ Processed 19 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit baku\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit marina-bay\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit austin\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit mexico-city\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit interlagos\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit las-vegas\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit lusail\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit yas-marina\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit melbourne\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit shanghai\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit suzuka\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit bahrain\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit jeddah\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit miami\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit imola\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monaco\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit catalunya\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit montreal\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spielberg\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit silverstone\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit spa-francorchamps\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit hungaroring\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit zandvoort\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit monza\n",
      "   ✅ Processed 22 real weather features\n",
      "   📦 Using cached weather data for circuit baku\n",
      "   ✅ Processed 22 real weather features\n",
      "   ✅ Real weather data integrated for 1142 races\n",
      "   📊 Added 22 weather features\n",
      "\n",
      "🔧 STEP 5: ENGINEERING STRATEGY FEATURES WITH REAL WEATHER...\n",
      "⚠️ Could not load feature cache: Ran out of input\n",
      "\n",
      "🔄 CREATING ENHANCED STRATEGY FEATURES WITH REAL WEATHER...\n",
      "   Processed 100 records...\n",
      "   Processed 200 records...\n",
      "   Processed 300 records...\n",
      "   Processed 400 records...\n",
      "   Processed 500 records...\n",
      "   Processed 600 records...\n",
      "   Processed 700 records...\n",
      "   Processed 800 records...\n",
      "   Processed 900 records...\n",
      "   Processed 1000 records...\n",
      "   Processed 1100 records...\n",
      "   Processed 1200 records...\n",
      "   Processed 1300 records...\n",
      "   Processed 1400 records...\n",
      "   Processed 1500 records...\n",
      "   Processed 1600 records...\n",
      "   Processed 1700 records...\n",
      "   Processed 1800 records...\n",
      "   Processed 1900 records...\n",
      "   Processed 2000 records...\n",
      "   Processed 2100 records...\n",
      "   Processed 2200 records...\n",
      "   Processed 2300 records...\n",
      "   Processed 2400 records...\n",
      "   Processed 2500 records...\n",
      "   Processed 2600 records...\n",
      "   Processed 2700 records...\n",
      "   Processed 2800 records...\n",
      "   Processed 2900 records...\n",
      "   Processed 3000 records...\n",
      "   Processed 3100 records...\n",
      "   Processed 3200 records...\n",
      "   Processed 3300 records...\n",
      "   Processed 3400 records...\n",
      "   Processed 3500 records...\n",
      "   Processed 3600 records...\n",
      "   Processed 3700 records...\n",
      "   Processed 3800 records...\n",
      "   Processed 3900 records...\n",
      "   Processed 4000 records...\n",
      "   Processed 4100 records...\n",
      "   Processed 4200 records...\n",
      "   Processed 4300 records...\n",
      "   Processed 4400 records...\n",
      "   Processed 4500 records...\n",
      "   Processed 4600 records...\n",
      "   Processed 4700 records...\n",
      "   Processed 4800 records...\n",
      "   Processed 4900 records...\n",
      "   Processed 5000 records...\n",
      "   Processed 5100 records...\n",
      "   Processed 5200 records...\n",
      "   Processed 5300 records...\n",
      "   Processed 5400 records...\n",
      "   Processed 5500 records...\n",
      "   Processed 5600 records...\n",
      "   Processed 5700 records...\n",
      "   Processed 5800 records...\n",
      "   Processed 5900 records...\n",
      "   Processed 6000 records...\n",
      "   Processed 6100 records...\n",
      "   Processed 6200 records...\n",
      "   Processed 6300 records...\n",
      "   Processed 6400 records...\n",
      "   Processed 6500 records...\n",
      "   Processed 6600 records...\n",
      "   Processed 6700 records...\n",
      "   Processed 6800 records...\n",
      "   Processed 6900 records...\n",
      "   Processed 7000 records...\n",
      "   Processed 7100 records...\n",
      "   Processed 7200 records...\n",
      "   Processed 7300 records...\n",
      "   Processed 7400 records...\n",
      "   Processed 7500 records...\n",
      "   Processed 7600 records...\n",
      "   Processed 7700 records...\n",
      "   Processed 7800 records...\n",
      "   Processed 7900 records...\n",
      "   Processed 8000 records...\n",
      "   Processed 8100 records...\n",
      "   Processed 8200 records...\n",
      "   Processed 8300 records...\n",
      "   Processed 8400 records...\n",
      "   Processed 8500 records...\n",
      "   Processed 8600 records...\n",
      "   Processed 8700 records...\n",
      "   Processed 8800 records...\n",
      "   Processed 8900 records...\n",
      "   Processed 9000 records...\n",
      "   Processed 9100 records...\n",
      "   Processed 9200 records...\n",
      "   Processed 9300 records...\n",
      "   Processed 9400 records...\n",
      "   Processed 9500 records...\n",
      "   Processed 9600 records...\n",
      "   Processed 9700 records...\n",
      "   Processed 9800 records...\n",
      "   Processed 9900 records...\n",
      "   Processed 10000 records...\n",
      "   Processed 10100 records...\n",
      "   Processed 10200 records...\n",
      "   Processed 10300 records...\n",
      "   Processed 10400 records...\n",
      "   Processed 10500 records...\n",
      "   Processed 10600 records...\n",
      "   Processed 10700 records...\n",
      "   Processed 10800 records...\n",
      "   Processed 10900 records...\n",
      "   Processed 11000 records...\n",
      "   Processed 11100 records...\n",
      "   Processed 11200 records...\n",
      "   Processed 11300 records...\n",
      "   Processed 11400 records...\n",
      "   Processed 11500 records...\n",
      "   Processed 11600 records...\n",
      "   Processed 11700 records...\n",
      "   Processed 11800 records...\n",
      "   Processed 11900 records...\n",
      "   Processed 12000 records...\n",
      "   Processed 12100 records...\n",
      "   Processed 12200 records...\n",
      "   Processed 12300 records...\n",
      "   Processed 12400 records...\n",
      "   Processed 12500 records...\n",
      "   Processed 12600 records...\n",
      "   Processed 12700 records...\n",
      "   Processed 12800 records...\n",
      "   Processed 12900 records...\n",
      "   Processed 13000 records...\n",
      "   Processed 13100 records...\n",
      "   Processed 13200 records...\n",
      "   Processed 13300 records...\n",
      "   Processed 13400 records...\n",
      "   Processed 13500 records...\n",
      "   Processed 13600 records...\n",
      "   Processed 13700 records...\n",
      "   Processed 13800 records...\n",
      "   Processed 13900 records...\n",
      "   Processed 14000 records...\n",
      "   Processed 14100 records...\n",
      "   Processed 14200 records...\n",
      "   Processed 14300 records...\n",
      "   Processed 14400 records...\n",
      "   Processed 14500 records...\n",
      "   Processed 14600 records...\n",
      "   Processed 14700 records...\n",
      "   Processed 14800 records...\n",
      "   Processed 14900 records...\n",
      "   Processed 15000 records...\n",
      "   Processed 15100 records...\n",
      "   Processed 15200 records...\n",
      "   Processed 15300 records...\n",
      "   Processed 15400 records...\n",
      "   Processed 15500 records...\n",
      "   Processed 15600 records...\n",
      "   Processed 15700 records...\n",
      "   Processed 15800 records...\n",
      "   Processed 15900 records...\n",
      "   Processed 16000 records...\n",
      "   Processed 16100 records...\n",
      "   Processed 16200 records...\n",
      "   Processed 16300 records...\n",
      "   Processed 16400 records...\n",
      "   Processed 16500 records...\n",
      "   Processed 16600 records...\n",
      "   Processed 16700 records...\n",
      "   Processed 16800 records...\n",
      "   Processed 16900 records...\n",
      "   Processed 17000 records...\n",
      "   Processed 17100 records...\n",
      "   Processed 17200 records...\n",
      "   Processed 17300 records...\n",
      "   Processed 17400 records...\n",
      "   Processed 17500 records...\n",
      "   Processed 17600 records...\n",
      "   Processed 17700 records...\n",
      "   Processed 17800 records...\n",
      "   Processed 17900 records...\n",
      "   Processed 18000 records...\n",
      "   Processed 18100 records...\n",
      "   Processed 18200 records...\n",
      "   Processed 18300 records...\n",
      "   Processed 18400 records...\n",
      "   Processed 18500 records...\n",
      "   Processed 18600 records...\n",
      "   Processed 18700 records...\n",
      "   Processed 18800 records...\n",
      "   Processed 18900 records...\n",
      "   Processed 19000 records...\n",
      "   Processed 19100 records...\n",
      "   Processed 19200 records...\n",
      "   Processed 19300 records...\n",
      "   Processed 19400 records...\n",
      "   Processed 19500 records...\n",
      "   Processed 19600 records...\n",
      "   Processed 19700 records...\n",
      "   Processed 19800 records...\n",
      "   Processed 19900 records...\n",
      "   Processed 20000 records...\n",
      "   Processed 20100 records...\n",
      "   Processed 20200 records...\n",
      "   Processed 20300 records...\n",
      "   Processed 20400 records...\n",
      "   Processed 20500 records...\n",
      "   Processed 20600 records...\n",
      "   Processed 20700 records...\n",
      "   Processed 20800 records...\n",
      "   Processed 20900 records...\n",
      "   Processed 21000 records...\n",
      "   Processed 21100 records...\n",
      "   Processed 21200 records...\n",
      "   Processed 21300 records...\n",
      "   Processed 21400 records...\n",
      "   Processed 21500 records...\n",
      "   Processed 21600 records...\n",
      "   Processed 21700 records...\n",
      "   Processed 21800 records...\n",
      "   Processed 21900 records...\n",
      "   Processed 22000 records...\n",
      "   Processed 22100 records...\n",
      "   Processed 22200 records...\n",
      "   Processed 22300 records...\n",
      "   Processed 22400 records...\n",
      "   Processed 22500 records...\n",
      "   Processed 22600 records...\n",
      "   Processed 22700 records...\n",
      "   Processed 22800 records...\n",
      "   Processed 22900 records...\n",
      "   Processed 23000 records...\n",
      "   Processed 23100 records...\n",
      "   Processed 23200 records...\n",
      "   Processed 23300 records...\n",
      "   Processed 23400 records...\n",
      "   Processed 23500 records...\n",
      "   Processed 23600 records...\n",
      "   Processed 23700 records...\n",
      "   Processed 23800 records...\n",
      "   Processed 23900 records...\n",
      "   Processed 24000 records...\n",
      "   Processed 24100 records...\n",
      "   Processed 24200 records...\n",
      "   Processed 24300 records...\n",
      "   Processed 24400 records...\n",
      "   Processed 24500 records...\n",
      "   Processed 24600 records...\n",
      "   Processed 24700 records...\n",
      "   Processed 24800 records...\n",
      "   Processed 24900 records...\n",
      "   Processed 25000 records...\n",
      "   Processed 25100 records...\n",
      "   Processed 25200 records...\n",
      "   Processed 25300 records...\n",
      "   Processed 25400 records...\n",
      "   Processed 25500 records...\n",
      "   Processed 25600 records...\n",
      "   Processed 25700 records...\n",
      "   Processed 25800 records...\n",
      "   Processed 25900 records...\n",
      "   Processed 26000 records...\n",
      "   Processed 26100 records...\n",
      "   Processed 26200 records...\n",
      "   Processed 26300 records...\n",
      "   Processed 26400 records...\n",
      "   Processed 26500 records...\n",
      "   Processed 26600 records...\n",
      "   Processed 26700 records...\n",
      "   Processed 26800 records...\n",
      "   Processed 26900 records...\n",
      "   Processed 27000 records...\n",
      "   Processed 27100 records...\n",
      "⚠️ Could not cache features: Ran out of input\n",
      "✅ ENHANCED FEATURE ENGINEERING COMPLETE: 27152 records\n",
      "📊 Total features created: 48\n",
      "\n",
      "📊 STEP 6: PERFORMING COMPREHENSIVE EDA...\n",
      "\n",
      "📊 PERFORMING COMPREHENSIVE EDA ON 27152 RECORDS...\n",
      "   1. 📈 UNIVARIATE ANALYSIS...\n",
      "   2. 📊 BIVARIATE ANALYSIS...\n",
      "   3. 🔍 MULTIVARIATE ANALYSIS...\n",
      "   4. 📋 STATISTICAL ANALYSIS...\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE EDA SUMMARY\n",
      "================================================================================\n",
      "📁 DATASET OVERVIEW:\n",
      "   Shape: 27,152 rows × 48 columns\n",
      "   Memory Usage: 17.56 MB\n",
      "   Numeric Features: 42\n",
      "   Categorical Features: 6\n",
      "   Missing Values: 0 (0.00%)\n",
      "   Duplicates: 12\n",
      "\n",
      "📊 STATISTICAL SUMMARY (Sample):\n",
      "   race_id:\n",
      "     Mean: 547.32, Std: 318.50\n",
      "     Skewness: 0.13, Kurtosis: -1.09\n",
      "   final_position:\n",
      "     Mean: 12.93, Std: 7.01\n",
      "     Skewness: -0.25, Kurtosis: -1.41\n",
      "   points_scored:\n",
      "     Mean: 2.02, Std: 4.41\n",
      "     Skewness: 3.01, Kurtosis: 10.41\n",
      "\n",
      "📋 NORMALITY TESTS:\n",
      "   race_id: Shapiro p = 0.000, NormalTest p = 0.000\n",
      "     Normally Distributed: No\n",
      "   final_position: Shapiro p = 0.000, NormalTest p = 0.000\n",
      "     Normally Distributed: No\n",
      "   points_scored: Shapiro p = 0.000, NormalTest p = 0.000\n",
      "     Normally Distributed: No\n",
      "   qualifying_position: Shapiro p = 0.000, NormalTest p = 0.000\n",
      "     Normally Distributed: No\n",
      "   finished: Shapiro p = 0.000, NormalTest p = 0.000\n",
      "     Normally Distributed: No\n",
      "\n",
      "💾 EDA CACHE STATS: 0 hits, 1 misses (0.0% hit rate)\n",
      "💾 EDA results cached: 0fbcc6070e481f4bbf450666e5b5f0b4\n",
      "\n",
      "🤖 STEP 7: TRAINING ENHANCED ML MODELS...\n",
      "\n",
      "🎯 TRAINING ENHANCED MODELS WITH COMPLETE ML PIPELINE...\n",
      "🔧 COMPREHENSIVE PREPROCESSING PIPELINE: 43 features\n",
      "   🧹 Handling missing values...\n",
      "  Applied KNN imputation for numeric features\n",
      "  Applied mode imputation for categorical features\n",
      "   📊 Detecting and handling outliers...\n",
      "  Handled outliers in 29 features\n",
      "     points_scored: IQR = 3992, Z = 658, ModZ = 8342\n",
      "     qualifying_position: IQR = 0, Z = 3, ModZ = 0\n",
      "     position_gain: IQR = 2785, Z = 497, ModZ = 10890\n",
      "     driver_win_rate: IQR = 2577, Z = 1182, ModZ = 6171\n",
      "     driver_podium_rate: IQR = 971, Z = 97, ModZ = 68\n",
      " 🔬 Advanced feature engineering...\n",
      "  🔠 Advanced feature encoding...\n",
      "   ⚖️ Advanced robust scaling...\n",
      "  🎯 Comprehensive feature selection...\n",
      "     Selected 30 features using statistical tests\n",
      "✅ COMPREHENSIVE PREPROCESSING COMPLETE: 30 features\n",
      "   Feature columns stored: 30 features\n",
      "   Training set: 21721 samples, 30 features\n",
      "   Test set: 5431 samples\n",
      "  🔧 Performing comprehensive hyperparameter tuning...\n",
      " 🎯 Comprehensive hyperparameter tuning (randomized)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "  ✅ Tuning completed for RandomForestRegressor\n",
      "  Best Score: -0.3057\n",
      "  Best Parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n",
      " 🎯 Comprehensive hyperparameter tuning (randomized)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "  ✅ Tuning completed for GradientBoostingRegressor\n",
      "  Best Score: -0.3453\n",
      "  Best Parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.1}\n",
      " 🎯 Comprehensive hyperparameter tuning (randomized)...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "  ✅ Tuning completed for SVR\n",
      "  Best Score: -0.5062\n",
      "  Best Parameters: {'kernel': 'rbf', 'gamma': 'auto', 'C': 10}\n",
      " 🎯 Comprehensive hyperparameter tuning (randomized)...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "  ✅ Tuning completed for KNeighborsRegressor\n",
      "  Best Score: -1.3690\n",
      "  Best Parameters: {'weights': 'distance', 'n_neighbors': 3, 'metric': 'euclidean'}\n",
      " 🎯 Comprehensive hyperparameter tuning (randomized)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "  ✅ Tuning completed for DecisionTreeRegressor\n",
      "  Best Score: -0.3451\n",
      "  Best Parameters: {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 15}\n",
      "   📊 Comparing model performance...\n",
      "  🔄 Comprehensive model comparison...\n",
      "    Random Forest: 0.3057 ± 0.0160\n",
      "    Gradient Boosting: 0.3453 ± 0.0158\n",
      "    SVR: 0.5062 ± 0.0124\n",
      "    KNN: 1.3690 ± 0.0162\n",
      "    Decision Tree: 0.3451 ± 0.0196\n",
      " 🏆 BEST MODEL: Random Forest (MAE: 0.3057)\n",
      "  📈 Generating advanced learning curves...\n",
      "  📈 Generating advanced learning curves for Random Forest...\n",
      "   ✅ Advanced learning curves saved for Random Forest\n",
      "   📊 Bias-Variance Analysis for Random Forest:\n",
      "   Final Training MAE: 0.114\n",
      "   Final CV MAE: 0.306\n",
      "   Gap (Train - CV): -0.192\n",
      "  ⚠️  HIGH BIAS DETECTED - Model is underfitting\n",
      "     Recommendations: Increase model complexity, add more features, reduce regularization\n",
      " 📋 Performing comprehensive model evaluation...\n",
      "   📊 Comprehensive regression evaluation for Random Forest...\n",
      "\n",
      "     🎯 REGRESSION EVALUATION - Random Forest\n",
      "     ==================================================\n",
      "     Metric           |   Train   |   Test    |  Difference\n",
      "     --------------------------------------------------\n",
      "     MAE             |   0.1101  |   0.2785  |    +0.1684\n",
      "     RMSE            |   0.3901  |   0.9530  |    +0.5629\n",
      "     R2              |   0.9969  |   0.9819  |    -0.0150\n",
      "     MAPE            |   0.0125  |   0.0330  |    +0.0206\n",
      "     --------------------------------------------------\n",
      "     Within 1 position:  91.1%\n",
      "     Within 3 positions: 97.9%\n",
      "     Within 5 positions: 99.3%\n",
      "     ⚠️  SIGNIFICANT OVERFITTING DETECTED\n",
      "\n",
      "📊 TOP 10 FEATURE IMPORTANCES:\n",
      "   finished: 0.6753\n",
      "   points_scored: 0.2115\n",
      "   position_gain: 0.0264\n",
      "   driver_age: 0.0257\n",
      "   constructor_experience: 0.0159\n",
      "   qualifying_gap_to_pole: 0.0151\n",
      "   qualifying_position: 0.0115\n",
      "   constructor_points_per_race: 0.0036\n",
      "   feature_std: 0.0018\n",
      "   feature_skew: 0.0015\n",
      "✅ Enhanced model training pipeline completed successfully\n",
      "\n",
      "🎯 STEP 8: TESTING STRATEGY OPTIMIZATION ENGINE...\n",
      "   🧪 Testing strategy optimization with sample scenarios...\n",
      "\n",
      "   📋 Test Scenario 1:\n",
      "      Qualifying Position: P3\n",
      "      Weather: 28.0°C, Rain: 10.0%\n",
      "🔧 COMPREHENSIVE PREPROCESSING PIPELINE: 15 features\n",
      "   🧹 Handling missing values...\n",
      "  Applied KNN imputation for numeric features\n",
      "   📊 Detecting and handling outliers...\n",
      " 🔬 Advanced feature engineering...\n",
      "  🔠 Advanced feature encoding...\n",
      "   ⚖️ Advanced robust scaling...\n",
      "✅ COMPREHENSIVE PREPROCESSING COMPLETE: 18 features\n",
      "      🎯 Predicted Finish: P14\n",
      "      📈 Position Gain: +0\n",
      "      🛑 Recommended Stops: Two-stop\n",
      "      🔧 Tire Strategy: Soft-medium-hard two-stop for optimal performance\n",
      "      ⚠️ Risk Level: Low\n",
      "\n",
      "   📋 Test Scenario 2:\n",
      "      Qualifying Position: P15\n",
      "      Weather: 18.0°C, Rain: 60.0%\n",
      "🔧 COMPREHENSIVE PREPROCESSING PIPELINE: 15 features\n",
      "   🧹 Handling missing values...\n",
      "  Applied KNN imputation for numeric features\n",
      "   📊 Detecting and handling outliers...\n",
      " 🔬 Advanced feature engineering...\n",
      "  🔠 Advanced feature encoding...\n",
      "   ⚖️ Advanced robust scaling...\n",
      "✅ COMPREHENSIVE PREPROCESSING COMPLETE: 18 features\n",
      "      🎯 Predicted Finish: P14\n",
      "      📈 Position Gain: +1.4499999999999993\n",
      "      🛑 Recommended Stops: Two-stop\n",
      "      🔧 Tire Strategy: Flexible strategy: prepare for wet conditions with intermediate option available\n",
      "      ⚠️ Risk Level: Medium\n",
      "\n",
      "💾 STEP 9: SAVING TRAINED MODEL...\n",
      "💾 Model saved to f1_strategy_predictor_final.pkl\n",
      "\n",
      "✅ PIPELINE EXECUTION COMPLETED SUCCESSFULLY!\n",
      "\n",
      "📊 CACHE PERFORMANCE STATISTICS:\n",
      "--------------------------------------------------\n",
      "💾 Database Tables Loaded: 15\n",
      "📈 EDA Cache: 0 hits, 1 misses (0.0% hit rate)\n",
      "🤖 Prediction Cache: 0 hits, 2 misses (0.0% hit rate)\n"
     ]
    }
   ],
   "source": [
    "def execute_complete_f1_strategy_pipeline(use_caching = True, use_weather = True):\n",
    "    \"\"\"\n",
    "    EXECUTE COMPLETE F1 STRATEGY ML PIPELINE\n",
    "    \"\"\"\n",
    "    print('\\n' + '=' * 80)\n",
    "    print('F1 RACE STRATEGY ML SYSTEM - COMPLETE EXECUTION')\n",
    "    print('=' * 80)\n",
    "    \n",
    "    try:\n",
    "        # STEP 1: Load MySQL Data\n",
    "        \n",
    "        print('\\n📥 STEP 1: LOADING COMPLETE F1 DATA FROM MYSQL DATABASE...')\n",
    "        dataframes = load_enhanced_mysql_data(use_caching = use_caching)\n",
    "        \n",
    "        # STEP 2: Data Cleaning\n",
    "        \n",
    "        print('\\n🧹 STEP 2: CLEANING AND PREPARING DATA...')\n",
    "        cleaner = AdvancedDataCleaner()\n",
    "        cleaned_dataframes = {}\n",
    "        \n",
    "        for key, df in dataframes.items():\n",
    "            if not df.empty:\n",
    "                cleaned_dataframes[key] = cleaner.comprehensive_clean(df, key)\n",
    "        \n",
    "        cleaner.print_cleaning_report()\n",
    "        \n",
    "        # STEP 3: Build Merged Dataset\n",
    "        \n",
    "        print('\\n🔗 STEP 3: BUILDING MERGED DATASET...')\n",
    "        merged_df = build_enhanced_merged_dataset(\n",
    "            cleaned_dataframes.get('results', pd.DataFrame()),\n",
    "            cleaned_dataframes.get('races', pd.DataFrame()),\n",
    "            cleaned_dataframes.get('circuits', pd.DataFrame()),\n",
    "            cleaned_dataframes.get('drivers', pd.DataFrame()),\n",
    "            cleaned_dataframes.get('constructors', pd.DataFrame()),\n",
    "            cleaned_dataframes.get('qualifying', pd.DataFrame()),\n",
    "            cleaned_dataframes.get('pitStops', pd.DataFrame()),\n",
    "            cleaned_dataframes.get('race_results', pd.DataFrame())\n",
    "        )\n",
    "        \n",
    "        if merged_df.empty:\n",
    "            print('❌ Failed to build merged dataset')\n",
    "            return None\n",
    "            \n",
    "        print(f'📊 Merged dataset contains {len(merged_df)} records from {merged_df['circuit_id'].nunique()} circuits')\n",
    "        \n",
    "        # STEP 4: Weather Integration\n",
    "        \n",
    "        if use_weather:\n",
    "            print('\\n🌤️ STEP 4: INTEGRATING REAL WEATHER DATA FOR ALL CIRCUITS...')\n",
    "            merged_df = integrate_real_weather_data(\n",
    "                merged_df, \n",
    "                cleaned_dataframes.get('circuits', pd.DataFrame()),\n",
    "                use_caching = use_caching\n",
    "            )\n",
    "        else:\n",
    "            print('\\n⏭️ STEP 4: SKIPPING WEATHER INTEGRATION (disabled)')\n",
    "        \n",
    "        # STEP 5: Feature Engineering\n",
    "        \n",
    "        print('\\n🔧 STEP 5: ENGINEERING STRATEGY FEATURES WITH REAL WEATHER...')\n",
    "        features_df = create_enhanced_strategy_features_with_weather(\n",
    "            merged_df,\n",
    "            cleaned_dataframes.get('drivers', pd.DataFrame()),\n",
    "            cleaned_dataframes.get('constructors', pd.DataFrame()),\n",
    "            cleaned_dataframes.get('circuits', pd.DataFrame()),\n",
    "            use_caching = use_caching\n",
    "        )\n",
    "        \n",
    "        if features_df.empty:\n",
    "            print('❌ Feature engineering failed')\n",
    "            return None\n",
    "            \n",
    "        # STEP 6: EDA Analysis\n",
    "        \n",
    "        print('\\n📊 STEP 6: PERFORMING COMPREHENSIVE EDA...')\n",
    "        eda = ComprehensiveEDA()\n",
    "        eda.perform_comprehensive_eda(features_df, target_column = 'final_position', use_cache = use_caching)\n",
    "        \n",
    "        # STEP 7: Train ML Models\n",
    "        \n",
    "        print('\\n🤖 STEP 7: TRAINING ENHANCED ML MODELS...')\n",
    "        \n",
    "        # Prepare features and target\n",
    "        \n",
    "        feature_columns = [col for col in features_df.columns if col not in \n",
    "                          ['race_id', 'driver_id', 'constructor_id', 'circuit_id', 'final_position']]\n",
    "        \n",
    "        X = features_df[feature_columns]\n",
    "        y = features_df['final_position']\n",
    "        \n",
    "        # Initialize and train predictor\n",
    "        \n",
    "        predictor = EnhancedF1StrategyPredictor(cache_enabled = use_caching)\n",
    "        predictor.train_enhanced_models(X, y, use_caching = use_caching)\n",
    "        \n",
    "        # STEP 8: Test Strategy Optimization\n",
    "        print('\\n🎯 STEP 8: TESTING STRATEGY OPTIMIZATION ENGINE...')\n",
    "        test_strategy_optimization(predictor, cleaned_dataframes)\n",
    "        \n",
    "        # STEP 9: Save Model\n",
    "        \n",
    "        print('\\n💾 STEP 9: SAVING TRAINED MODEL...')\n",
    "        predictor.save_model('f1_strategy_predictor_final.pkl')\n",
    "        \n",
    "        # Print final statistics\n",
    "        \n",
    "        print('\\n✅ PIPELINE EXECUTION COMPLETED SUCCESSFULLY!')\n",
    "        print_cache_statistics(cleaned_dataframes, predictor, eda)\n",
    "        \n",
    "        return predictor, features_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'❌ Pipeline execution failed: {e}')\n",
    "        \n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def test_strategy_optimization(predictor, dataframes):\n",
    "    \"\"\"\n",
    "    TEST THE STRATEGY OPTIMIZATION ENGINE WITH SAMPLE DATA\n",
    "    \"\"\"\n",
    "    print('   🧪 Testing strategy optimization with sample scenarios...')\n",
    "    \n",
    "    # Sample test scenarios\n",
    "    \n",
    "    test_scenarios = [\n",
    "        {\n",
    "            'driver_profile': {\n",
    "                'experience': 80,\n",
    "                'win_rate': 0.15,\n",
    "                'podium_rate': 0.35,\n",
    "                'points_per_race': 12.5,\n",
    "                'age': 26\n",
    "            },\n",
    "            'constructor_profile': {\n",
    "                'experience': 450,\n",
    "                'win_rate': 0.12,\n",
    "                'reliability': 0.92,\n",
    "                'points_per_race': 15.0\n",
    "            },\n",
    "            'circuit_profile': {\n",
    "                'length': 5.8,\n",
    "                'corners': 16,\n",
    "                'altitude': 200,\n",
    "                'type': 'permanent'\n",
    "            },\n",
    "            'qualifying_pos': 3,\n",
    "            'weather_conditions': {\n",
    "                'temperature_avg': 28.0,\n",
    "                'rain_probability': 0.1,\n",
    "                'wind_speed_avg': 4.5,\n",
    "                'estimated_track_temp': 45.0,\n",
    "                'tire_degradation_factor': 1.2\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'driver_profile': {\n",
    "                'experience': 25,\n",
    "                'win_rate': 0.02,\n",
    "                'podium_rate': 0.08,\n",
    "                'points_per_race': 3.5,\n",
    "                'age': 22\n",
    "            },\n",
    "            'constructor_profile': {\n",
    "                'experience': 150,\n",
    "                'win_rate': 0.03,\n",
    "                'reliability': 0.78,\n",
    "                'points_per_race': 4.0\n",
    "            },\n",
    "            'circuit_profile': {\n",
    "                'length': 4.3,\n",
    "                'corners': 12,\n",
    "                'altitude': 50,\n",
    "                'type': 'street'\n",
    "            },\n",
    "            'qualifying_pos': 15,\n",
    "            'weather_conditions': {\n",
    "                'temperature_avg': 18.0,\n",
    "                'rain_probability': 0.6,\n",
    "                'wind_speed_avg': 8.0,\n",
    "                'estimated_track_temp': 30.0,\n",
    "                'tire_degradation_factor': 0.9\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, scenario in enumerate(test_scenarios, 1):\n",
    "        print(f'\\n   📋 Test Scenario {i}:')\n",
    "        print(f'      Qualifying Position: P{scenario['qualifying_pos']}')\n",
    "        print(f'      Weather: {scenario['weather_conditions']['temperature_avg']}°C, '\n",
    "              f'Rain: {scenario['weather_conditions']['rain_probability']*100}%')\n",
    "        \n",
    "        try:\n",
    "            strategy = optimize_complete_race_strategy(\n",
    "                predictor,\n",
    "                scenario['driver_profile'],\n",
    "                scenario['constructor_profile'], \n",
    "                scenario['circuit_profile'],\n",
    "                scenario['qualifying_pos'],\n",
    "                scenario['weather_conditions']\n",
    "            )\n",
    "            \n",
    "            print(f'      🎯 Predicted Finish: P{strategy['predicted_finish']}')\n",
    "            print(f'      📈 Position Gain: +{strategy['qualifying_gain']}')\n",
    "            print(f'      🛑 Recommended Stops: {strategy['recommended_pit_stops']}')\n",
    "            print(f'      🔧 Tire Strategy: {strategy['tire_strategy']}')\n",
    "            print(f'      ⚠️ Risk Level: {strategy['risk_level']}')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'      ❌ Strategy optimization failed: {e}')\n",
    "\n",
    "def print_cache_statistics(dataframes, predictor, eda):\n",
    "    \"\"\"\n",
    "    PRINT COMPREHENSIVE CACHE STATISTICS\n",
    "    \"\"\"\n",
    "    print('\\n📊 CACHE PERFORMANCE STATISTICS:')\n",
    "    print('-' * 50)\n",
    "    \n",
    "    # Database cache stats\n",
    "    \n",
    "    db_cache_hits = sum(1 for df in dataframes.values() if not df.empty)\n",
    "    print(f'💾 Database Tables Loaded: {db_cache_hits}')\n",
    "    \n",
    "    # EDA cache stats\n",
    "    \n",
    "    eda_stats = eda.get_cache_stats()\n",
    "    print(f'📈 EDA Cache: {eda_stats['hits']} hits, {eda_stats['misses']} misses '\n",
    "          f'({eda_stats['hit_rate']:.1f}% hit rate)')\n",
    "    \n",
    "    # Prediction cache stats\n",
    "    \n",
    "    pred_stats = predictor.get_prediction_cache_stats()\n",
    "    print(f'🤖 Prediction Cache: {pred_stats['hits']} hits, {pred_stats['misses']} misses '\n",
    "          f'({pred_stats['hit_rate']:.1f}% hit rate)')\n",
    "\n",
    "# Clear caches if needed\n",
    "\n",
    "def clear_all_caches():\n",
    "    \"\"\"\n",
    "    CLEAR ALL CACHES FOR FRESH START\n",
    "    \"\"\"\n",
    "    print('🧹 CLEARING ALL CACHES...')\n",
    "    \n",
    "    # Clear feature cache\n",
    "    \n",
    "    clear_feature_cache()\n",
    "    \n",
    "    # Clear EDA cache\n",
    "    \n",
    "    eda = ComprehensiveEDA()\n",
    "    eda.clear_cache()\n",
    "    \n",
    "    # Clear weather cache\n",
    "    \n",
    "    weather_integrator = RealWeatherDataIntegrator(pd.DataFrame())\n",
    "    weather_integrator.clear_cache()\n",
    "    \n",
    "    print('✅ All caches cleared successfully')\n",
    "\n",
    "# Main execution block\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Run with caching \n",
    "    \n",
    "    print('🚀 STARTING F1 STRATEGY ML PIPELINE...')\n",
    "    predictor, features = execute_complete_f1_strategy_pipeline(use_caching = True, use_weather = True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccc6e8b-de7c-4736-9a26-cbbc532a05fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
